{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from six.moves import cPickle\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "# from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from prednet import PredNet\n",
    "# from data_utils import SequenceGenerator\n",
    "from kitti_settings import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "raw_RAD_id_list = os.listdir('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/')\n",
    "print(len(raw_RAD_id_list))\n",
    "RAD_id_list = raw_RAD_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RAD_id(RAD_id):\n",
    "    mean_list = []\n",
    "    for k in range(61):\n",
    "        mean_list.append(np.array(PIL.Image.open('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png'\n",
    "                         % (RAD_id, RAD_id,\n",
    "                        k))).astype(np.int8).ravel().mean())\n",
    "    mean_list = np.array(mean_list)\n",
    "    if i % 100 == 0:\n",
    "        print(time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "        print(i, mean_list[:6])\n",
    "    if mean_list.mean() < 0:\n",
    "        return False\n",
    "    for k in range(59):\n",
    "        if abs(mean_list[k] + mean_list[k + 2] - 2 * mean_list[k + 1]) > 2:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2018-08-29 00:45:59\n",
      "00:00:00\n",
      "0 [-0.87143478 -0.88864586 -0.87570966 -0.87651842 -0.85615197 -0.85808025]\n",
      "00:00:04\n",
      "100 [0.93458592 0.94748228 0.91407206 0.97729093 0.9896096  0.95768941]\n",
      "00:00:08\n",
      "200 [0.63846758 0.81406847 0.84174963 1.11912702 1.17828216 1.40408206]\n",
      "00:00:12\n",
      "300 [-0.70275019 -0.60799758 -0.57519691 -0.53383054 -0.47055191 -0.42185489]\n",
      "00:00:16\n",
      "400 [3.6213282  3.81463022 3.72164653 3.65255517 3.61006928 3.63974646]\n",
      "00:00:21\n",
      "500 [-0.82312819 -0.84708427 -0.86941088 -0.86395672 -0.89204425 -0.87515588]\n",
      "00:00:25\n",
      "600 [-0.64371855 -0.6432564  -0.65860295 -0.65442369 -0.6496747  -0.67613276]\n",
      "00:00:29\n",
      "700 [7.77424791 0.75098904 0.68460683 0.60291393 0.59950757 0.56755551]\n",
      "00:00:34\n",
      "800 [-0.27642121 -0.20599918 -0.12073259 -0.05030657  0.04815519  0.06030653]\n",
      "00:00:38\n",
      "900 [-0.85298067 -0.84477751 -0.82603655 -0.79839523 -0.76492524 -0.77512042]\n",
      "00:00:43\n",
      "1000 [5.48567137 5.721778   5.83030745 5.96880889 6.05623882 6.2163099 ]\n",
      "00:00:47\n",
      "1100 [-0.58297377 -0.59010522 -0.59204943 -0.59812909 -0.59858327 -0.6052446 ]\n",
      "00:00:51\n",
      "1200 [0.42858793 0.48936458 0.41439277 0.3598392  0.45380297 0.40323345]\n",
      "00:00:56\n",
      "1300 [ 0.06405154  0.09507532  0.06442205  0.02217919 -0.0027211  -0.01908757]\n",
      "00:01:00\n",
      "1400 [-0.32966403 -0.35466393 -0.31747284 -0.34166796 -0.37782718 -0.42793455]\n",
      "00:01:04\n",
      "1500 [-0.96092047 -0.96500014 -0.96528301 -0.97731882 -0.98631878 -0.98718332]\n",
      "00:01:09\n",
      "1600 [-0.87486106 -0.84252652 -0.84663806 -0.85465397 -0.87227143 -0.87990884]\n",
      "00:01:13\n",
      "1700 [-0.97920327 -0.98887255 -0.98874905 -0.98923112 -0.98806778 -0.98720722]\n",
      "00:01:18\n",
      "1800 [8.39836495 8.46852801 8.67002123 8.73830383 8.69142752 9.0027968 ]\n",
      "00:01:22\n",
      "1900 [9.28255664 9.30374779 9.15307509 9.15582806 9.44860379 9.87953036]\n",
      "00:01:27\n",
      "2000 [2.37185908 2.32926164 2.1861148  1.99493628 1.85708423 1.76163043]\n",
      "00:01:31\n",
      "2100 [-0.6050693  -0.60800156 -0.63057916 -0.65034801 -0.59922072 -0.58346381]\n",
      "00:01:35\n",
      "2200 [1.02266126 0.92343457 1.17511086 1.25001494 1.41167565 1.49428488]\n",
      "00:01:40\n",
      "2300 [3.45725714 3.26094318 3.18685981 3.1327166  3.06002367 3.01368122]\n",
      "00:01:44\n",
      "2400 [1.80475377 1.72050311 1.68978211 1.71500114 1.71623221 1.62416883]\n",
      "00:01:48\n",
      "2500 [-0.99665738 -0.99291238 -0.96902403 -0.95223525 -0.93763371 -0.93333094]\n",
      "00:01:53\n",
      "2600 [-0.92111984 -0.9211039  -0.93453413 -0.94756595 -0.94448229 -0.95432289]\n",
      "00:01:57\n",
      "2700 [-0.9333668  -0.90306015 -0.85693284 -0.81372186 -0.79135541 -0.79403269]\n",
      "00:02:02\n",
      "2800 [0.77980566 0.7820686  0.71937164 0.6921088  0.72464253 0.72469831]\n",
      "00:02:06\n",
      "2900 [-0.72061067 -0.72677798 -0.7312441  -0.74291337 -0.7379612  -0.74380979]\n",
      "00:02:11\n",
      "3000 [0.66552324 0.71081789 0.64151936 0.63567077 0.54696196 0.52708157]\n",
      "00:02:15\n",
      "3100 [-0.98477695 -0.9811435  -0.98080087 -0.98307975 -0.98462954 -0.98310764]\n",
      "00:02:19\n",
      "3200 [-0.46704196 -0.48071123 -0.51794614 -0.534715   -0.54831654 -0.53630464]\n",
      "00:02:24\n",
      "3300 [-0.58501759 -0.61354736 -0.64145561 -0.67955905 -0.68113274 -0.72576603]\n",
      "00:02:28\n",
      "3400 [-0.21243342 -0.15978024 -0.12658515 -0.10064103 -0.04991215 -0.11142585]\n",
      "00:02:33\n",
      "3500 [-0.8639607  -0.8814945  -0.87833515 -0.89853427 -0.91809993 -0.93093255]\n",
      "00:02:37\n",
      "3600 [-0.94266158 -0.97183278 -0.94333489 -0.95773722 -0.97736662 -0.97465349]\n",
      "00:02:41\n",
      "3700 [1.43359588 1.42980705 1.38237696 1.37839291 1.40085896 1.45308983]\n",
      "00:02:46\n",
      "3800 [-0.12037004 -0.13444568 -0.20023825 -0.16200732 -0.24362851 -0.18511878]\n",
      "00:02:50\n",
      "3900 [-0.45425715 -0.45510576 -0.49094227 -0.50434062 -0.55810136 -0.52308955]\n",
      "00:02:54\n",
      "4000 [3.65832009 3.62530428 3.54214525 3.4125123  3.25208266 3.08153752]\n",
      "00:02:58\n",
      "4100 [0.85241493 0.86492484 0.85322768 0.93217557 0.79598886 0.81779754]\n",
      "00:03:03\n",
      "4200 [1.59465899 1.54518508 1.40510596 1.43759188 1.29453269 0.74052295]\n",
      "00:03:07\n",
      "4300 [-0.59453548 -0.6147346  -0.61390194 -0.63458313 -0.61271867 -0.61903737]\n",
      "00:03:11\n",
      "4400 [2.44722929 2.45256393 2.53084251 2.56603759 2.60199362 2.67280608]\n",
      "00:03:16\n",
      "4500 [-0.85701252 -0.87313596 -0.84759822 -0.86017187 -0.87541085 -0.86239895]\n",
      "00:03:20\n",
      "4600 [4.24455281 4.47076306 4.45807786 4.45191055 4.45616153 4.36108223]\n",
      "00:03:25\n",
      "4700 [ 0.00552189 -0.03015127 -0.09921076 -0.19921833 -0.19156099 -0.26742921]\n",
      "00:03:29\n",
      "4800 [0.88839487 0.94976912 0.96963359 0.99081677 0.96220732 0.92523137]\n",
      "00:03:34\n",
      "4900 [-0.99856973 -0.99517532 -0.99419923 -0.99698806 -0.99388847 -0.99717133]\n",
      "end time: 2018-08-29 00:49:37\n",
      "00:03:38\n",
      "1895\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "RAD_id_list = []\n",
    "for (i, RAD_id) in enumerate(raw_RAD_id_list):\n",
    "    if check_RAD_id(RAD_id):\n",
    "        RAD_id_list.append(RAD_id)\n",
    "print(time.strftime('end time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(len(RAD_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, nt, image_size, image_scalar, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.nt = nt\n",
    "        self.image_size = image_size\n",
    "        self.image_scalar = image_scalar\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = np.empty((self.batch_size, self.nt, self.image_size, self.image_size, 1))\n",
    "        y = np.empty((self.batch_size, self.image_size, self.image_size, 1))\n",
    "        # Generate data\n",
    "#         print(list_IDs_temp)\n",
    "        for i, RAD_id in enumerate(list_IDs_temp):\n",
    "            for j in range(self.nt):\n",
    "                X[i][j] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * 5)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "            y[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, (self.nt) * 5)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build time: 2018-08-29 02:05:45\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "save_model = True  # if weights will be saved\n",
    "weights_file = os.path.join(WEIGHTS_DIR, 'prednet_kitti_weights.hdf5')  # where weights will be saved\n",
    "json_file = os.path.join(WEIGHTS_DIR, 'prednet_kitti_model.json')\n",
    "\n",
    "# # Data files\n",
    "# train_file = os.path.join(DATA_DIR, 'X_train.hkl')\n",
    "# train_sources = os.path.join(DATA_DIR, 'sources_train.hkl')\n",
    "# val_file = os.path.join(DATA_DIR, 'X_val.hkl')\n",
    "# val_sources = os.path.join(DATA_DIR, 'sources_val.hkl')\n",
    "\n",
    "# Training parameters\n",
    "nb_epoch = 15\n",
    "batch_size = 4\n",
    "samples_per_epoch = 50  # 500\n",
    "N_seq_val = None  # 100  number of sequences to use for validation\n",
    "\n",
    "# Model parameters\n",
    "image_size = 256\n",
    "nt = 3  # number of timesteps used for sequences in training\n",
    "image_scalar = 80\n",
    "n_channels, im_height, im_width = (1, image_size, image_size)  # (3, 128, 160)\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96)  # (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (2, 2)\n",
    "Ahat_filt_sizes = (2, 2, 2)\n",
    "R_filt_sizes = (2, 2, 2)\n",
    "layer_loss_weights = np.array([1., 0., 0.])  # weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "time_loss_weights = 1./ (nt - 1) * np.ones((nt,1))  # equally weight all timesteps except the first\n",
    "time_loss_weights[0] = 0\n",
    "\n",
    "\n",
    "prednet = PredNet(stack_sizes, R_stack_sizes,\n",
    "                  A_filt_sizes, Ahat_filt_sizes, R_filt_sizes, A_activation='relu',\n",
    "                  error_activation='relu', LSTM_inner_activation='sigmoid',\n",
    "                  output_mode='prediction', return_sequences=False)\n",
    "\n",
    "inputs = Input(shape=(nt,) + input_shape)\n",
    "outputs = prednet(inputs)\n",
    "# outputs = np.empty(shape=(nt,) + input_shape)\n",
    "# for i in range(nt):\n",
    "#     temp_outputs = prednet(inputs)\n",
    "#     outputs[i] = temp_outputs\n",
    "#     for j in range(nt - 1):\n",
    "#         inputs[j] = inputs[j + 1]\n",
    "#     inputs[-1] = temp_outputs\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    w = tf.add(y_true, tf.constant(0.8))\n",
    "    w = tf.add(y_pred, w)\n",
    "    loss = tf.losses.mean_squared_error(y_true, y_pred, weights=w)\n",
    "#     loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = tf.multiply(loss, tf.constant(100000.0))\n",
    "    return loss\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=my_loss, optimizer=keras.optimizers.Adam())\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 3, 256, 256, 1)    0         \n",
      "_________________________________________________________________\n",
      "pred_net_15 (PredNet)        (None, 256, 256, 1)       711705    \n",
      "=================================================================\n",
      "Total params: 711,705\n",
      "Trainable params: 711,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to use tensorboard\n",
    "```bash\n",
    "python3 /usr/local/lib/python3.5/dist-packages/tensorboard/main.py --logdir='/home/hadoop/Documents/Neutrino/tensorboard_logs' --host=192.168.1.115\n",
    "rm -rf /home/hadoop/Documents/Neutrino/tensorboard_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda epoch: 0.003 if epoch < 75 else 0.001    # start with lr of 0.001 and then drop to 0.0001 after 75 epochs\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='/home/hadoop/Documents/Neutrino/tensorboard_logs', histogram_freq=0)\n",
    "callbacks = [LearningRateScheduler(lr_schedule), tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2018-08-29 02:04:04\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 5s 172ms/step - loss: 94.2856 - val_loss: 976.4751\n",
      "\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 115.3667 - val_loss: 955.8048\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 88.4641 - val_loss: 979.2525\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 79.6739 - val_loss: 977.9559\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 74.3949 - val_loss: 1003.9558\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 73.3928 - val_loss: 999.7294\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 5s 171ms/step - loss: 69.2056 - val_loss: 1011.8057\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 67.4276 - val_loss: 1022.8732\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 66.3134 - val_loss: 1036.9595\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 63.7699 - val_loss: 1041.0248\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_generator = myGenerator(list_IDs=RAD_id_list[:10], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=10)\n",
    "valid_generator = myGenerator(list_IDs=RAD_id_list[-10:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=1, shuffle=False)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=30, epochs=1000, validation_data=valid_generator, validation_steps=2 ,use_multiprocessing=True, max_queue_size=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "10/10 [==============================] - 17s 2s/step - loss: 1002.7437 - val_loss: 775.9602\n",
      "Epoch 2/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 720.9127 - val_loss: 723.4323\n",
      "Epoch 3/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 777.9669 - val_loss: 691.5756\n",
      "Epoch 4/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 740.9449 - val_loss: 703.2819\n",
      "Epoch 5/5000\n",
      "10/10 [==============================] - 15s 1s/step - loss: 643.2498 - val_loss: 665.5648\n",
      "Epoch 6/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 647.9467 - val_loss: 662.0715\n",
      "Epoch 7/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 641.4453 - val_loss: 696.7500\n",
      "Epoch 8/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 545.7647 - val_loss: 687.7179\n",
      "Epoch 9/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 687.4979 - val_loss: 669.6724\n",
      "Epoch 10/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 642.3770 - val_loss: 653.3883\n",
      "Epoch 11/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.7710 - val_loss: 685.5347\n",
      "Epoch 12/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 591.2401 - val_loss: 677.3705\n",
      "Epoch 13/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 662.9603 - val_loss: 687.6722\n",
      "Epoch 14/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 568.8059 - val_loss: 661.0766\n",
      "Epoch 15/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 672.4127 - val_loss: 670.6795\n",
      "Epoch 16/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 632.7998 - val_loss: 665.7721\n",
      "Epoch 17/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 571.8233 - val_loss: 666.7761\n",
      "Epoch 18/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 676.0592 - val_loss: 637.5544\n",
      "Epoch 19/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 691.7699 - val_loss: 623.4883\n",
      "Epoch 20/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 663.6926 - val_loss: 666.1923\n",
      "Epoch 21/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 602.5422 - val_loss: 654.1852\n",
      "Epoch 22/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.5921 - val_loss: 671.5657\n",
      "Epoch 23/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 633.1347 - val_loss: 662.8248\n",
      "Epoch 24/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.9010 - val_loss: 652.4284\n",
      "Epoch 25/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.6777 - val_loss: 655.4182\n",
      "Epoch 26/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 591.2376 - val_loss: 648.4524\n",
      "Epoch 27/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 590.8231 - val_loss: 642.4871\n",
      "Epoch 28/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 641.7106 - val_loss: 653.3353\n",
      "Epoch 29/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 690.8969 - val_loss: 622.5616\n",
      "Epoch 30/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 673.3553 - val_loss: 644.1255\n",
      "Epoch 31/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 668.8817 - val_loss: 631.1949\n",
      "Epoch 32/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 678.9909 - val_loss: 646.5761\n",
      "Epoch 33/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 681.1379 - val_loss: 643.3079\n",
      "Epoch 34/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 689.8322 - val_loss: 640.9860\n",
      "Epoch 35/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 601.9844 - val_loss: 641.8948\n",
      "Epoch 36/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 707.7670 - val_loss: 659.1600\n",
      "Epoch 37/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.4544 - val_loss: 635.0966\n",
      "Epoch 38/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 618.9125 - val_loss: 633.1649\n",
      "Epoch 39/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 636.5413 - val_loss: 681.9866\n",
      "Epoch 40/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 671.5770 - val_loss: 641.5363\n",
      "Epoch 41/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.5219 - val_loss: 618.9726\n",
      "Epoch 42/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.0825 - val_loss: 654.9975\n",
      "Epoch 43/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 645.9410 - val_loss: 640.2714\n",
      "Epoch 44/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 649.8623 - val_loss: 650.8641\n",
      "Epoch 45/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.9501 - val_loss: 648.2609\n",
      "Epoch 46/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 566.3594 - val_loss: 645.9379\n",
      "Epoch 47/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 659.9519 - val_loss: 612.7384\n",
      "Epoch 48/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.9960 - val_loss: 641.2790\n",
      "Epoch 49/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 641.6947 - val_loss: 669.5640\n",
      "Epoch 50/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 629.9841 - val_loss: 665.3319\n",
      "Epoch 51/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 645.2006 - val_loss: 679.0716\n",
      "Epoch 52/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 659.1838 - val_loss: 618.2606\n",
      "Epoch 53/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 572.9773 - val_loss: 665.6756\n",
      "Epoch 54/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 629.5771 - val_loss: 658.5780\n",
      "Epoch 55/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.1798 - val_loss: 641.7231\n",
      "Epoch 56/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 654.7607 - val_loss: 644.2720\n",
      "Epoch 57/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.2181 - val_loss: 645.9959\n",
      "Epoch 58/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 554.5348 - val_loss: 621.3447\n",
      "Epoch 59/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 617.2780 - val_loss: 628.2570\n",
      "Epoch 60/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 595.4129 - val_loss: 626.2439\n",
      "Epoch 61/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.9431 - val_loss: 617.4087\n",
      "Epoch 62/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 603.1255 - val_loss: 641.1491\n",
      "Epoch 63/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.1340 - val_loss: 654.1408\n",
      "Epoch 64/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 680.4852 - val_loss: 631.4616\n",
      "Epoch 65/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 657.4854 - val_loss: 673.0814\n",
      "Epoch 66/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.7585 - val_loss: 629.3262\n",
      "Epoch 67/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 641.1278 - val_loss: 631.1391\n",
      "Epoch 68/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.4948 - val_loss: 630.0345\n",
      "Epoch 69/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 695.6670 - val_loss: 629.1685\n",
      "Epoch 70/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.7889 - val_loss: 631.3716\n",
      "Epoch 71/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.5474 - val_loss: 645.1755\n",
      "Epoch 72/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.3541 - val_loss: 657.3703\n",
      "Epoch 73/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 492.1511 - val_loss: 644.1085\n",
      "Epoch 74/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 654.6048 - val_loss: 641.1665\n",
      "Epoch 75/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 667.2569 - val_loss: 589.1804\n",
      "Epoch 76/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.9774 - val_loss: 634.2252\n",
      "Epoch 77/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 651.5504 - val_loss: 640.6591\n",
      "Epoch 78/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 561.4588 - val_loss: 621.2819\n",
      "Epoch 79/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 677.8571 - val_loss: 635.1544\n",
      "Epoch 80/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.4716 - val_loss: 634.5561\n",
      "Epoch 81/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 645.7894 - val_loss: 653.9715\n",
      "Epoch 82/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.7162 - val_loss: 640.2870\n",
      "Epoch 83/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 656.4865 - val_loss: 646.1831\n",
      "Epoch 84/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.1596 - val_loss: 611.5552\n",
      "Epoch 85/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 536.2078 - val_loss: 620.4868\n",
      "Epoch 86/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.8042 - val_loss: 604.5515\n",
      "Epoch 87/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 617.8954 - val_loss: 629.0743\n",
      "Epoch 88/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 788.4954 - val_loss: 614.4905\n",
      "Epoch 89/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 651.8886 - val_loss: 629.7353\n",
      "Epoch 90/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 603.5080 - val_loss: 642.7185\n",
      "Epoch 91/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 514.6286 - val_loss: 622.3527\n",
      "Epoch 92/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 669.9337 - val_loss: 639.6917\n",
      "Epoch 93/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.2242 - val_loss: 617.1746\n",
      "Epoch 94/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.8007 - val_loss: 648.7852\n",
      "Epoch 95/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 604.4190 - val_loss: 630.3424\n",
      "Epoch 96/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 545.2835 - val_loss: 637.0612\n",
      "Epoch 97/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 578.7769 - val_loss: 635.2966\n",
      "Epoch 98/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 694.9986 - val_loss: 653.7009\n",
      "Epoch 99/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 670.9259 - val_loss: 644.4187\n",
      "Epoch 100/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.4861 - val_loss: 638.8746\n",
      "Epoch 101/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.2889 - val_loss: 642.4886\n",
      "Epoch 102/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 575.2462 - val_loss: 651.7712\n",
      "Epoch 103/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 555.0424 - val_loss: 616.2186\n",
      "Epoch 104/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 686.1869 - val_loss: 622.0988\n",
      "Epoch 105/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 711.3511 - val_loss: 638.8878\n",
      "Epoch 106/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.0862 - val_loss: 642.8777\n",
      "Epoch 107/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 766.6045 - val_loss: 632.0790\n",
      "Epoch 108/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.3916 - val_loss: 658.4959\n",
      "Epoch 109/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.2811 - val_loss: 654.5904\n",
      "Epoch 110/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.2214 - val_loss: 608.6810\n",
      "Epoch 111/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 590.3938 - val_loss: 618.8763\n",
      "Epoch 112/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.5789 - val_loss: 650.2686\n",
      "Epoch 113/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.6876 - val_loss: 657.2694\n",
      "Epoch 114/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 572.9888 - val_loss: 630.1435\n",
      "Epoch 115/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 683.1210 - val_loss: 632.1381\n",
      "Epoch 116/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 590.2799 - val_loss: 639.4147\n",
      "Epoch 117/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.1947 - val_loss: 632.0863\n",
      "Epoch 118/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.4579 - val_loss: 642.2044\n",
      "Epoch 119/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 584.7368 - val_loss: 639.4046\n",
      "Epoch 120/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 760.8737 - val_loss: 614.0368\n",
      "Epoch 121/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 735.3917 - val_loss: 654.1059\n",
      "Epoch 122/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 635.7895 - val_loss: 645.4588\n",
      "Epoch 123/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 536.5850 - val_loss: 651.7367\n",
      "Epoch 124/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 593.8930 - val_loss: 625.3437\n",
      "Epoch 125/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.9336 - val_loss: 622.0307\n",
      "Epoch 126/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.4575 - val_loss: 635.9093\n",
      "Epoch 127/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.0244 - val_loss: 640.7665\n",
      "Epoch 128/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 588.7680 - val_loss: 623.8997\n",
      "Epoch 129/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 611.0281 - val_loss: 610.5378\n",
      "Epoch 130/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 657.7000 - val_loss: 622.3552\n",
      "Epoch 131/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.4966 - val_loss: 626.8633\n",
      "Epoch 132/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 684.2834 - val_loss: 619.6090\n",
      "Epoch 133/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.5595 - val_loss: 648.9319\n",
      "Epoch 134/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 646.3891 - val_loss: 625.9204\n",
      "Epoch 135/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 568.8696 - val_loss: 633.1843\n",
      "Epoch 136/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 665.2074 - val_loss: 627.0482\n",
      "Epoch 137/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 610.2525 - val_loss: 639.0094\n",
      "Epoch 138/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 677.7012 - val_loss: 643.9211\n",
      "Epoch 139/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 571.9314 - val_loss: 643.0817\n",
      "Epoch 140/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.4662 - val_loss: 641.7322\n",
      "Epoch 141/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 564.0317 - val_loss: 649.1395\n",
      "Epoch 142/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.0693 - val_loss: 611.4771\n",
      "Epoch 143/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 681.4729 - val_loss: 634.9861\n",
      "Epoch 144/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 507.8157 - val_loss: 632.6433\n",
      "Epoch 145/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.1416 - val_loss: 643.0609\n",
      "Epoch 146/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 638.4911 - val_loss: 631.3385\n",
      "Epoch 147/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 643.2810 - val_loss: 637.0116\n",
      "Epoch 148/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 550.9399 - val_loss: 643.3794\n",
      "Epoch 149/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.2843 - val_loss: 625.1182\n",
      "Epoch 150/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 638.3470 - val_loss: 619.2769\n",
      "Epoch 151/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 718.2388 - val_loss: 640.6891\n",
      "Epoch 152/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 544.9149 - val_loss: 616.2912\n",
      "Epoch 153/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 632.5483 - val_loss: 638.6812\n",
      "Epoch 154/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.2637 - val_loss: 599.7225\n",
      "Epoch 155/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 541.9668 - val_loss: 651.4932\n",
      "Epoch 156/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 607.3135 - val_loss: 640.4911\n",
      "Epoch 157/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.2274 - val_loss: 633.2678\n",
      "Epoch 158/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 514.6698 - val_loss: 609.4354\n",
      "Epoch 159/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 507.4757 - val_loss: 642.6152\n",
      "Epoch 160/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 712.5425 - val_loss: 623.7401\n",
      "Epoch 161/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.8833 - val_loss: 617.5887\n",
      "Epoch 162/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.9025 - val_loss: 632.1305\n",
      "Epoch 163/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 627.9055 - val_loss: 640.0383\n",
      "Epoch 164/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.0950 - val_loss: 635.6685\n",
      "Epoch 165/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.9391 - val_loss: 645.8638\n",
      "Epoch 166/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 668.4443 - val_loss: 635.6371\n",
      "Epoch 167/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 595.0286 - val_loss: 658.8971\n",
      "Epoch 168/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 723.4695 - val_loss: 640.5045\n",
      "Epoch 169/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 618.6939 - val_loss: 615.6620\n",
      "Epoch 170/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 504.8988 - val_loss: 632.0826\n",
      "Epoch 171/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 577.2730 - val_loss: 653.1379\n",
      "Epoch 172/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 593.5753 - val_loss: 645.0606\n",
      "Epoch 173/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 620.9779 - val_loss: 637.1756\n",
      "Epoch 174/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 622.4644 - val_loss: 646.3028\n",
      "Epoch 175/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.1366 - val_loss: 636.6319\n",
      "Epoch 176/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 691.1265 - val_loss: 639.7698\n",
      "Epoch 177/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.6919 - val_loss: 654.3251\n",
      "Epoch 178/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 536.7303 - val_loss: 631.4392\n",
      "Epoch 179/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 661.4205 - val_loss: 623.1859\n",
      "Epoch 180/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 588.5490 - val_loss: 626.9671\n",
      "Epoch 181/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.0449 - val_loss: 634.7450\n",
      "Epoch 182/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.3831 - val_loss: 616.9541\n",
      "Epoch 183/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.8150 - val_loss: 606.0813\n",
      "Epoch 184/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 684.9319 - val_loss: 654.9610\n",
      "Epoch 185/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 622.8120 - val_loss: 652.5077\n",
      "Epoch 186/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 730.7838 - val_loss: 651.2921\n",
      "Epoch 187/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 554.3804 - val_loss: 614.2050\n",
      "Epoch 188/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 631.6589 - val_loss: 630.6636\n",
      "Epoch 189/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 647.0774 - val_loss: 649.4150\n",
      "Epoch 190/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 639.2584 - val_loss: 640.9823\n",
      "Epoch 191/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.3115 - val_loss: 630.8254\n",
      "Epoch 192/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 629.8744 - val_loss: 657.3433\n",
      "Epoch 193/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 599.4324 - val_loss: 609.4514\n",
      "Epoch 194/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 609.7100 - val_loss: 632.5193\n",
      "Epoch 195/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 614.4340 - val_loss: 644.1474\n",
      "Epoch 196/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.3986 - val_loss: 627.0177\n",
      "Epoch 197/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.9348 - val_loss: 646.3961\n",
      "Epoch 198/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.5159 - val_loss: 646.0742\n",
      "Epoch 199/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 617.2222 - val_loss: 650.8580\n",
      "Epoch 200/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.4184 - val_loss: 626.8474\n",
      "Epoch 201/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 614.3241 - val_loss: 635.4452\n",
      "Epoch 202/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 704.0724 - val_loss: 625.2923\n",
      "Epoch 203/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 601.7508 - val_loss: 647.8699\n",
      "Epoch 204/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 683.6311 - val_loss: 632.7333\n",
      "Epoch 205/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.0645 - val_loss: 638.9267\n",
      "Epoch 206/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 588.7724 - val_loss: 619.3823\n",
      "Epoch 207/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.9778 - val_loss: 629.7698\n",
      "Epoch 208/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.3099 - val_loss: 597.7378\n",
      "Epoch 209/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.6072 - val_loss: 645.0283\n",
      "Epoch 210/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.1238 - val_loss: 633.8652\n",
      "Epoch 211/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 651.7266 - val_loss: 602.4513\n",
      "Epoch 212/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.2623 - val_loss: 636.8794\n",
      "Epoch 213/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 661.6921 - val_loss: 633.6114\n",
      "Epoch 214/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 631.1144 - val_loss: 636.6838\n",
      "Epoch 215/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 538.4170 - val_loss: 618.1748\n",
      "Epoch 216/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.7884 - val_loss: 625.3479\n",
      "Epoch 217/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 628.9947 - val_loss: 647.0854\n",
      "Epoch 218/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 670.7204 - val_loss: 630.4571\n",
      "Epoch 219/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.0674 - val_loss: 612.2031\n",
      "Epoch 220/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 660.1185 - val_loss: 647.6610\n",
      "Epoch 221/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 536.3984 - val_loss: 638.3942\n",
      "Epoch 222/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 513.9680 - val_loss: 654.1463\n",
      "Epoch 223/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.8754 - val_loss: 641.0932\n",
      "Epoch 224/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.0721 - val_loss: 624.8946\n",
      "Epoch 225/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.4628 - val_loss: 616.3718\n",
      "Epoch 226/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 639.7067 - val_loss: 626.4552\n",
      "Epoch 227/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 569.1819 - val_loss: 647.5092\n",
      "Epoch 228/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 645.1664 - val_loss: 640.5672\n",
      "Epoch 229/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 599.7585 - val_loss: 655.6010\n",
      "Epoch 230/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.5127 - val_loss: 644.2696\n",
      "Epoch 231/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 666.1685 - val_loss: 618.0630\n",
      "Epoch 232/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 639.6108 - val_loss: 639.6061\n",
      "Epoch 233/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 647.2569 - val_loss: 628.9758\n",
      "Epoch 234/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.0728 - val_loss: 606.6293\n",
      "Epoch 235/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.2264 - val_loss: 643.2215\n",
      "Epoch 236/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.8482 - val_loss: 628.0054\n",
      "Epoch 237/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 610.1383 - val_loss: 642.2676\n",
      "Epoch 238/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 599.9129 - val_loss: 647.2378\n",
      "Epoch 239/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 618.3322 - val_loss: 644.6895\n",
      "Epoch 240/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 660.6268 - val_loss: 649.2701\n",
      "Epoch 241/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 522.0296 - val_loss: 644.0255\n",
      "Epoch 242/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 575.5154 - val_loss: 618.9253\n",
      "Epoch 243/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.7451 - val_loss: 627.5879\n",
      "Epoch 244/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 595.2220 - val_loss: 635.0356\n",
      "Epoch 245/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 617.5588 - val_loss: 636.6142\n",
      "Epoch 246/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 670.1381 - val_loss: 636.3128\n",
      "Epoch 247/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.3830 - val_loss: 643.6521\n",
      "Epoch 248/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 658.3787 - val_loss: 621.4595\n",
      "Epoch 249/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 695.2474 - val_loss: 617.9079\n",
      "Epoch 250/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.3421 - val_loss: 649.3825\n",
      "Epoch 251/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 653.7083 - val_loss: 647.9082\n",
      "Epoch 252/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.2456 - val_loss: 620.7874\n",
      "Epoch 253/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 575.8393 - val_loss: 626.1850\n",
      "Epoch 254/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.7284 - val_loss: 648.8682\n",
      "Epoch 255/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.3494 - val_loss: 645.1316\n",
      "Epoch 256/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.8483 - val_loss: 623.5165\n",
      "Epoch 257/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 578.2174 - val_loss: 629.7864\n",
      "Epoch 258/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 533.2159 - val_loss: 624.7964\n",
      "Epoch 259/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 584.5903 - val_loss: 636.2069\n",
      "Epoch 260/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.5403 - val_loss: 629.9252\n",
      "Epoch 261/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 694.3321 - val_loss: 640.4511\n",
      "Epoch 262/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 550.4520 - val_loss: 620.2431\n",
      "Epoch 263/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 685.8216 - val_loss: 640.1675\n",
      "Epoch 264/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 743.6907 - val_loss: 638.6148\n",
      "Epoch 265/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.5322 - val_loss: 631.0142\n",
      "Epoch 266/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.4962 - val_loss: 640.5618\n",
      "Epoch 267/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 659.6111 - val_loss: 641.6656\n",
      "Epoch 268/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.3821 - val_loss: 653.6547\n",
      "Epoch 269/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.7626 - val_loss: 610.8341\n",
      "Epoch 270/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.7244 - val_loss: 653.7033\n",
      "Epoch 271/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 666.4338 - val_loss: 639.5259\n",
      "Epoch 272/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 663.9737 - val_loss: 622.2377\n",
      "Epoch 273/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.1295 - val_loss: 644.0929\n",
      "Epoch 274/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 671.6194 - val_loss: 632.5672\n",
      "Epoch 275/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.0508 - val_loss: 637.5019\n",
      "Epoch 276/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.8806 - val_loss: 633.9490\n",
      "Epoch 277/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 723.5918 - val_loss: 578.8857\n",
      "Epoch 278/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.3755 - val_loss: 610.1787\n",
      "Epoch 279/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 674.7641 - val_loss: 638.5457\n",
      "Epoch 280/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 593.0872 - val_loss: 619.9998\n",
      "Epoch 281/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.5343 - val_loss: 622.8988\n",
      "Epoch 282/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 636.5741 - val_loss: 633.4666\n",
      "Epoch 283/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 551.5660 - val_loss: 637.1465\n",
      "Epoch 284/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 693.5295 - val_loss: 629.6251\n",
      "Epoch 285/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 546.9362 - val_loss: 628.2786\n",
      "Epoch 286/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.9589 - val_loss: 634.7916\n",
      "Epoch 287/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 523.4839 - val_loss: 625.6052\n",
      "Epoch 288/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 584.9663 - val_loss: 636.3417\n",
      "Epoch 289/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 544.7964 - val_loss: 645.5192\n",
      "Epoch 290/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 622.9976 - val_loss: 611.2664\n",
      "Epoch 291/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.8349 - val_loss: 616.4462\n",
      "Epoch 292/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 654.0885 - val_loss: 643.7106\n",
      "Epoch 293/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.1158 - val_loss: 622.5785\n",
      "Epoch 294/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 611.1091 - val_loss: 633.8476\n",
      "Epoch 295/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 682.7848 - val_loss: 626.0248\n",
      "Epoch 296/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.3949 - val_loss: 633.7594\n",
      "Epoch 297/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 693.3789 - val_loss: 625.6766\n",
      "Epoch 298/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 625.9386 - val_loss: 632.1442\n",
      "Epoch 299/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.2087 - val_loss: 622.8866\n",
      "Epoch 300/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.3820 - val_loss: 631.3708\n",
      "Epoch 301/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 585.3593 - val_loss: 626.7074\n",
      "Epoch 302/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.5383 - val_loss: 623.8728\n",
      "Epoch 303/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.7650 - val_loss: 640.3421\n",
      "Epoch 304/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 567.9231 - val_loss: 625.6865\n",
      "Epoch 305/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 687.1036 - val_loss: 590.3917\n",
      "Epoch 306/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 620.5537 - val_loss: 616.1295\n",
      "Epoch 307/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 638.9125 - val_loss: 629.6114\n",
      "Epoch 308/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 585.0002 - val_loss: 610.5055\n",
      "Epoch 309/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.0930 - val_loss: 609.6144\n",
      "Epoch 310/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 591.1877 - val_loss: 624.6750\n",
      "Epoch 311/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.0802 - val_loss: 612.8614\n",
      "Epoch 312/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.0120 - val_loss: 650.2646\n",
      "Epoch 313/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.6208 - val_loss: 627.7852\n",
      "Epoch 314/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.3153 - val_loss: 624.0245\n",
      "Epoch 315/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 618.8463 - val_loss: 623.1082\n",
      "Epoch 316/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 625.9478 - val_loss: 632.2542\n",
      "Epoch 317/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 591.9778 - val_loss: 634.2529\n",
      "Epoch 318/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.4302 - val_loss: 633.6798\n",
      "Epoch 319/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.1372 - val_loss: 623.1610\n",
      "Epoch 320/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.3109 - val_loss: 628.0852\n",
      "Epoch 321/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 514.7500 - val_loss: 632.7221\n",
      "Epoch 322/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 662.3801 - val_loss: 629.5802\n",
      "Epoch 323/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.3942 - val_loss: 619.8625\n",
      "Epoch 324/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.3508 - val_loss: 656.3076\n",
      "Epoch 325/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 626.7121 - val_loss: 643.3597\n",
      "Epoch 326/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.4727 - val_loss: 637.1106\n",
      "Epoch 327/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 560.3655 - val_loss: 610.8914\n",
      "Epoch 328/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 631.9350 - val_loss: 619.2104\n",
      "Epoch 329/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.7204 - val_loss: 625.1744\n",
      "Epoch 330/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 668.0453 - val_loss: 638.3499\n",
      "Epoch 331/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.5560 - val_loss: 604.2499\n",
      "Epoch 332/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 519.9259 - val_loss: 628.3975\n",
      "Epoch 333/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 675.6672 - val_loss: 634.9660\n",
      "Epoch 334/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 686.1461 - val_loss: 615.5980\n",
      "Epoch 335/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 623.0772 - val_loss: 623.4074\n",
      "Epoch 336/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 570.4208 - val_loss: 631.6792\n",
      "Epoch 337/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.0010 - val_loss: 644.7825\n",
      "Epoch 338/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.7347 - val_loss: 643.3140\n",
      "Epoch 339/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.9476 - val_loss: 643.6704\n",
      "Epoch 340/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 651.7896 - val_loss: 633.7255\n",
      "Epoch 341/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.4449 - val_loss: 653.3684\n",
      "Epoch 342/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 621.1146 - val_loss: 624.6194\n",
      "Epoch 343/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.5913 - val_loss: 624.7702\n",
      "Epoch 344/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.2248 - val_loss: 603.0799\n",
      "Epoch 345/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 678.9003 - val_loss: 608.8100\n",
      "Epoch 346/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.2429 - val_loss: 628.9965\n",
      "Epoch 347/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 608.6675 - val_loss: 637.5338\n",
      "Epoch 348/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.9433 - val_loss: 633.3933\n",
      "Epoch 349/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 641.7723 - val_loss: 592.2987\n",
      "Epoch 350/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 537.3110 - val_loss: 608.8969\n",
      "Epoch 351/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 577.1571 - val_loss: 622.1838\n",
      "Epoch 352/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 709.6982 - val_loss: 625.2917\n",
      "Epoch 353/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 649.5098 - val_loss: 604.7972\n",
      "Epoch 354/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 576.1294 - val_loss: 635.9573\n",
      "Epoch 355/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.2560 - val_loss: 620.9054\n",
      "Epoch 356/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 580.6033 - val_loss: 613.2119\n",
      "Epoch 357/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.7560 - val_loss: 642.5784\n",
      "Epoch 358/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 663.9134 - val_loss: 621.4334\n",
      "Epoch 359/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 553.3431 - val_loss: 610.0229\n",
      "Epoch 360/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 490.8414 - val_loss: 638.5832\n",
      "Epoch 361/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.0404 - val_loss: 616.7913\n",
      "Epoch 362/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.2834 - val_loss: 646.5336\n",
      "Epoch 363/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 621.0405 - val_loss: 635.8199\n",
      "Epoch 364/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 675.0683 - val_loss: 645.4335\n",
      "Epoch 365/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.1838 - val_loss: 612.6032\n",
      "Epoch 366/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 515.4378 - val_loss: 619.8588\n",
      "Epoch 367/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 619.5812 - val_loss: 625.2097\n",
      "Epoch 368/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 641.2164 - val_loss: 620.4413\n",
      "Epoch 369/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.1310 - val_loss: 598.9077\n",
      "Epoch 370/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 585.6243 - val_loss: 638.5749\n",
      "Epoch 371/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.0331 - val_loss: 616.7434\n",
      "Epoch 372/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.7728 - val_loss: 639.1141\n",
      "Epoch 373/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.4179 - val_loss: 619.8886\n",
      "Epoch 374/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 605.1652 - val_loss: 600.7629\n",
      "Epoch 375/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.8090 - val_loss: 645.8396\n",
      "Epoch 376/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 607.5263 - val_loss: 624.1073\n",
      "Epoch 377/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.5512 - val_loss: 635.1526\n",
      "Epoch 378/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 729.5132 - val_loss: 648.5785\n",
      "Epoch 379/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 596.2882 - val_loss: 593.0259\n",
      "Epoch 380/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.9581 - val_loss: 632.6860\n",
      "Epoch 381/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 668.6000 - val_loss: 638.5170\n",
      "Epoch 382/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 564.3575 - val_loss: 611.3921\n",
      "Epoch 383/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.8831 - val_loss: 620.4002\n",
      "Epoch 384/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.9780 - val_loss: 638.5798\n",
      "Epoch 385/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 660.8917 - val_loss: 625.2847\n",
      "Epoch 386/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 664.3965 - val_loss: 615.3245\n",
      "Epoch 387/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 553.5534 - val_loss: 643.8387\n",
      "Epoch 388/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.9094 - val_loss: 619.1786\n",
      "Epoch 389/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 536.2786 - val_loss: 631.0362\n",
      "Epoch 390/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.4311 - val_loss: 606.9605\n",
      "Epoch 391/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 656.3744 - val_loss: 607.6864\n",
      "Epoch 392/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.1863 - val_loss: 647.0802\n",
      "Epoch 393/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.9664 - val_loss: 615.6144\n",
      "Epoch 394/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 605.9416 - val_loss: 611.8713\n",
      "Epoch 395/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.0375 - val_loss: 652.7160\n",
      "Epoch 396/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.7687 - val_loss: 631.6076\n",
      "Epoch 397/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.5003 - val_loss: 631.8540\n",
      "Epoch 398/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.4796 - val_loss: 614.1496\n",
      "Epoch 399/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.7320 - val_loss: 614.5226\n",
      "Epoch 400/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 613.8212 - val_loss: 630.3053\n",
      "Epoch 401/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.0667 - val_loss: 655.8670\n",
      "Epoch 402/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 663.4494 - val_loss: 633.4170\n",
      "Epoch 403/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 732.9894 - val_loss: 637.1536\n",
      "Epoch 404/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 551.1837 - val_loss: 607.2447\n",
      "Epoch 405/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 555.6780 - val_loss: 646.9182\n",
      "Epoch 406/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 575.7475 - val_loss: 633.5654\n",
      "Epoch 407/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.9892 - val_loss: 630.6887\n",
      "Epoch 408/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 499.5364 - val_loss: 626.3805\n",
      "Epoch 409/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.5507 - val_loss: 649.6229\n",
      "Epoch 410/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.0858 - val_loss: 629.8167\n",
      "Epoch 411/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 728.3265 - val_loss: 638.9025\n",
      "Epoch 412/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 654.1248 - val_loss: 632.3307\n",
      "Epoch 413/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.5440 - val_loss: 630.7733\n",
      "Epoch 414/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.7142 - val_loss: 610.6139\n",
      "Epoch 415/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.5173 - val_loss: 612.9468\n",
      "Epoch 416/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.9188 - val_loss: 627.9410\n",
      "Epoch 417/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.1773 - val_loss: 656.1348\n",
      "Epoch 418/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 640.6828 - val_loss: 642.5049\n",
      "Epoch 419/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.2623 - val_loss: 601.9636\n",
      "Epoch 420/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.1789 - val_loss: 645.0328\n",
      "Epoch 421/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.7971 - val_loss: 602.4867\n",
      "Epoch 422/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 635.8655 - val_loss: 627.7249\n",
      "Epoch 423/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 661.4551 - val_loss: 629.3687\n",
      "Epoch 424/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.8165 - val_loss: 617.5133\n",
      "Epoch 425/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.3534 - val_loss: 623.7542\n",
      "Epoch 426/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.9030 - val_loss: 650.6467\n",
      "Epoch 427/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 486.0974 - val_loss: 626.8296\n",
      "Epoch 428/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 687.2653 - val_loss: 643.3651\n",
      "Epoch 429/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 682.6791 - val_loss: 630.3841\n",
      "Epoch 430/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.5000 - val_loss: 642.0104\n",
      "Epoch 431/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 635.4031 - val_loss: 638.3341\n",
      "Epoch 432/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 658.5374 - val_loss: 640.5688\n",
      "Epoch 433/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 643.1440 - val_loss: 638.0105\n",
      "Epoch 434/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 606.8381 - val_loss: 650.5779\n",
      "Epoch 435/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 654.6821 - val_loss: 626.6268\n",
      "Epoch 436/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 569.5514 - val_loss: 610.6772\n",
      "Epoch 437/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.4982 - val_loss: 625.1885\n",
      "Epoch 438/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.5048 - val_loss: 645.8339\n",
      "Epoch 439/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.8212 - val_loss: 618.4102\n",
      "Epoch 440/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.1305 - val_loss: 638.3658\n",
      "Epoch 441/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 593.1533 - val_loss: 646.7183\n",
      "Epoch 442/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 687.4964 - val_loss: 612.9830\n",
      "Epoch 443/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 630.6252 - val_loss: 627.6483\n",
      "Epoch 444/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.9046 - val_loss: 631.4255\n",
      "Epoch 445/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.0215 - val_loss: 623.2538\n",
      "Epoch 446/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.0013 - val_loss: 614.2646\n",
      "Epoch 447/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.8931 - val_loss: 615.5454\n",
      "Epoch 448/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 628.6853 - val_loss: 645.0651\n",
      "Epoch 449/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 586.3184 - val_loss: 605.7954\n",
      "Epoch 450/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.8967 - val_loss: 613.5131\n",
      "Epoch 451/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.4911 - val_loss: 594.1408\n",
      "Epoch 452/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 588.1756 - val_loss: 638.1456\n",
      "Epoch 453/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 640.1569 - val_loss: 600.2691\n",
      "Epoch 454/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 642.8847 - val_loss: 598.4278\n",
      "Epoch 455/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.1529 - val_loss: 611.3508\n",
      "Epoch 456/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 520.7825 - val_loss: 624.9428\n",
      "Epoch 457/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.5656 - val_loss: 649.9917\n",
      "Epoch 458/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.7925 - val_loss: 595.4762\n",
      "Epoch 459/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 576.3774 - val_loss: 637.2105\n",
      "Epoch 460/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 637.9171 - val_loss: 633.4334\n",
      "Epoch 461/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 483.6479 - val_loss: 626.3367\n",
      "Epoch 462/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 685.2440 - val_loss: 652.7972\n",
      "Epoch 463/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 593.0886 - val_loss: 640.9864\n",
      "Epoch 464/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 640.1485 - val_loss: 625.1832\n",
      "Epoch 465/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.7985 - val_loss: 628.0192\n",
      "Epoch 466/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.6653 - val_loss: 633.8278\n",
      "Epoch 467/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 645.8518 - val_loss: 605.3573\n",
      "Epoch 468/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 652.3264 - val_loss: 647.0922\n",
      "Epoch 469/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 578.3010 - val_loss: 620.0659\n",
      "Epoch 470/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 577.1273 - val_loss: 626.1052\n",
      "Epoch 471/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.0068 - val_loss: 592.0263\n",
      "Epoch 472/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.5111 - val_loss: 634.2484\n",
      "Epoch 473/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 510.8969 - val_loss: 634.6204\n",
      "Epoch 474/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.7633 - val_loss: 623.7572\n",
      "Epoch 475/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.4136 - val_loss: 610.5343\n",
      "Epoch 476/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 651.5639 - val_loss: 596.9530\n",
      "Epoch 477/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 595.9708 - val_loss: 638.5044\n",
      "Epoch 478/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.9085 - val_loss: 617.1482\n",
      "Epoch 479/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 631.7409 - val_loss: 649.4871\n",
      "Epoch 480/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 577.0482 - val_loss: 619.0178\n",
      "Epoch 481/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 570.8458 - val_loss: 641.7477\n",
      "Epoch 482/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 607.3963 - val_loss: 650.9618\n",
      "Epoch 483/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 465.4632 - val_loss: 645.8144\n",
      "Epoch 484/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 703.5527 - val_loss: 639.6124\n",
      "Epoch 485/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 635.2152 - val_loss: 648.5641\n",
      "Epoch 486/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 664.1650 - val_loss: 620.5290\n",
      "Epoch 487/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 593.3024 - val_loss: 628.6215\n",
      "Epoch 488/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 501.7830 - val_loss: 640.7002\n",
      "Epoch 489/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 607.7950 - val_loss: 643.0491\n",
      "Epoch 490/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 663.5868 - val_loss: 637.0739\n",
      "Epoch 491/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 720.0320 - val_loss: 620.8547\n",
      "Epoch 492/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 488.3356 - val_loss: 612.8639\n",
      "Epoch 493/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 524.3760 - val_loss: 650.7655\n",
      "Epoch 494/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.2976 - val_loss: 607.2186\n",
      "Epoch 495/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.9792 - val_loss: 599.3679\n",
      "Epoch 496/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 566.2726 - val_loss: 617.9818\n",
      "Epoch 497/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.5095 - val_loss: 625.6935\n",
      "Epoch 498/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.7487 - val_loss: 650.0712\n",
      "Epoch 499/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 667.2155 - val_loss: 639.7728\n",
      "Epoch 500/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.4611 - val_loss: 592.1393\n",
      "Epoch 501/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 504.2758 - val_loss: 634.2897\n",
      "Epoch 502/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 546.8066 - val_loss: 632.3708\n",
      "Epoch 503/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.7047 - val_loss: 640.7236\n",
      "Epoch 504/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 602.0537 - val_loss: 645.4431\n",
      "Epoch 505/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 615.3110 - val_loss: 625.9936\n",
      "Epoch 506/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 627.1376 - val_loss: 616.7855\n",
      "Epoch 507/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.1145 - val_loss: 634.1525\n",
      "Epoch 508/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 591.0427 - val_loss: 611.9976\n",
      "Epoch 509/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 601.9306 - val_loss: 642.2830\n",
      "Epoch 510/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 614.0169 - val_loss: 610.6356\n",
      "Epoch 511/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 546.1958 - val_loss: 629.6609\n",
      "Epoch 512/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.0218 - val_loss: 640.5015\n",
      "Epoch 513/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 623.5394 - val_loss: 635.7471\n",
      "Epoch 514/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.5244 - val_loss: 619.4236\n",
      "Epoch 515/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 560.4243 - val_loss: 628.2128\n",
      "Epoch 516/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.5014 - val_loss: 633.6367\n",
      "Epoch 517/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 640.3001 - val_loss: 608.9426\n",
      "Epoch 518/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 678.1996 - val_loss: 632.1805\n",
      "Epoch 519/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 660.2070 - val_loss: 612.7158\n",
      "Epoch 520/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 560.6883 - val_loss: 632.2104\n",
      "Epoch 521/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 521.5717 - val_loss: 646.8913\n",
      "Epoch 522/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 564.4829 - val_loss: 651.8001\n",
      "Epoch 523/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 507.0316 - val_loss: 618.6666\n",
      "Epoch 524/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 607.9986 - val_loss: 619.8907\n",
      "Epoch 525/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 603.4978 - val_loss: 650.5783\n",
      "Epoch 526/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.6215 - val_loss: 621.5331\n",
      "Epoch 527/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 575.1412 - val_loss: 621.8709\n",
      "Epoch 528/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 495.6672 - val_loss: 622.3299\n",
      "Epoch 529/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.0291 - val_loss: 622.4673\n",
      "Epoch 530/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.4941 - val_loss: 636.8513\n",
      "Epoch 531/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 501.3239 - val_loss: 616.6946\n",
      "Epoch 532/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 590.9678 - val_loss: 643.2229\n",
      "Epoch 533/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 668.9044 - val_loss: 616.6724\n",
      "Epoch 534/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 669.2581 - val_loss: 623.3305\n",
      "Epoch 535/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.7720 - val_loss: 609.3127\n",
      "Epoch 536/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 577.9897 - val_loss: 645.4993\n",
      "Epoch 537/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.4959 - val_loss: 646.8183\n",
      "Epoch 538/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.7988 - val_loss: 646.8366\n",
      "Epoch 539/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.0127 - val_loss: 646.3762\n",
      "Epoch 540/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 641.6687 - val_loss: 656.6245\n",
      "Epoch 541/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 644.2438 - val_loss: 620.2892\n",
      "Epoch 542/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.4593 - val_loss: 639.3918\n",
      "Epoch 543/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 637.0290 - val_loss: 621.0719\n",
      "Epoch 544/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.0666 - val_loss: 636.9405\n",
      "Epoch 545/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.6953 - val_loss: 622.4446\n",
      "Epoch 546/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.4876 - val_loss: 652.0910\n",
      "Epoch 547/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.2250 - val_loss: 651.1499\n",
      "Epoch 548/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 648.1556 - val_loss: 650.0319\n",
      "Epoch 549/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 567.8586 - val_loss: 646.6832\n",
      "Epoch 550/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.5233 - val_loss: 657.3732\n",
      "Epoch 551/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 601.7963 - val_loss: 635.1822\n",
      "Epoch 552/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.6033 - val_loss: 613.8209\n",
      "Epoch 553/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.4238 - val_loss: 627.1570\n",
      "Epoch 554/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 560.6495 - val_loss: 641.2012\n",
      "Epoch 555/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 590.6639 - val_loss: 627.8022\n",
      "Epoch 556/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 637.4468 - val_loss: 627.9063\n",
      "Epoch 557/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 630.1811 - val_loss: 643.5711\n",
      "Epoch 558/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.4227 - val_loss: 635.4243\n",
      "Epoch 559/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 487.8606 - val_loss: 648.0353\n",
      "Epoch 560/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.4838 - val_loss: 655.0283\n",
      "Epoch 561/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 606.3124 - val_loss: 618.7055\n",
      "Epoch 562/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.8512 - val_loss: 643.3584\n",
      "Epoch 563/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.4624 - val_loss: 622.6425\n",
      "Epoch 564/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.2683 - val_loss: 616.3240\n",
      "Epoch 565/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 546.0967 - val_loss: 616.1067\n",
      "Epoch 566/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 703.8325 - val_loss: 634.6422\n",
      "Epoch 567/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.5681 - val_loss: 645.6118\n",
      "Epoch 568/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 576.9048 - val_loss: 624.2653\n",
      "Epoch 569/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.6159 - val_loss: 625.3933\n",
      "Epoch 570/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 555.6923 - val_loss: 632.7834\n",
      "Epoch 571/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 654.9744 - val_loss: 634.4640\n",
      "Epoch 572/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 555.6178 - val_loss: 632.5950\n",
      "Epoch 573/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.1960 - val_loss: 650.1152\n",
      "Epoch 574/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 599.5011 - val_loss: 611.9577\n",
      "Epoch 575/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.9468 - val_loss: 609.1836\n",
      "Epoch 576/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 647.1000 - val_loss: 645.5858\n",
      "Epoch 577/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.7185 - val_loss: 639.0054\n",
      "Epoch 578/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 544.1064 - val_loss: 643.2787\n",
      "Epoch 579/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 599.9306 - val_loss: 644.8597\n",
      "Epoch 580/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 655.2329 - val_loss: 644.5555\n",
      "Epoch 581/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 580.4540 - val_loss: 616.5787\n",
      "Epoch 582/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 596.4260 - val_loss: 627.9181\n",
      "Epoch 583/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 601.0702 - val_loss: 632.1994\n",
      "Epoch 584/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 544.9170 - val_loss: 617.7754\n",
      "Epoch 585/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.0740 - val_loss: 627.6233\n",
      "Epoch 586/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 494.8186 - val_loss: 641.1534\n",
      "Epoch 587/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.7219 - val_loss: 602.5138\n",
      "Epoch 588/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.1678 - val_loss: 655.8118\n",
      "Epoch 589/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.5218 - val_loss: 613.9992\n",
      "Epoch 590/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 613.0445 - val_loss: 643.1608\n",
      "Epoch 591/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 601.8553 - val_loss: 649.1618\n",
      "Epoch 592/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.3508 - val_loss: 642.4381\n",
      "Epoch 593/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 498.4821 - val_loss: 648.0425\n",
      "Epoch 594/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.0494 - val_loss: 624.5002\n",
      "Epoch 595/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 666.3381 - val_loss: 606.3809\n",
      "Epoch 596/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.9623 - val_loss: 634.1622\n",
      "Epoch 597/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.2171 - val_loss: 645.1013\n",
      "Epoch 598/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 535.4845 - val_loss: 642.4583\n",
      "Epoch 599/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.5025 - val_loss: 632.3661\n",
      "Epoch 600/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 598.4060 - val_loss: 640.4701\n",
      "Epoch 601/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 553.2899 - val_loss: 620.6797\n",
      "Epoch 602/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.5061 - val_loss: 630.3091\n",
      "Epoch 603/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 523.8586 - val_loss: 651.1524\n",
      "Epoch 604/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.9213 - val_loss: 622.4801\n",
      "Epoch 605/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 603.2557 - val_loss: 645.8164\n",
      "Epoch 606/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.6574 - val_loss: 650.5266\n",
      "Epoch 607/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 604.5453 - val_loss: 629.5723\n",
      "Epoch 608/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.5018 - val_loss: 647.7282\n",
      "Epoch 609/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.7688 - val_loss: 626.9576\n",
      "Epoch 610/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.3042 - val_loss: 631.6511\n",
      "Epoch 611/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 641.5361 - val_loss: 641.6783\n",
      "Epoch 612/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 607.3639 - val_loss: 636.8756\n",
      "Epoch 613/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.3076 - val_loss: 615.1995\n",
      "Epoch 614/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.3513 - val_loss: 633.5739\n",
      "Epoch 615/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 524.9402 - val_loss: 644.0075\n",
      "Epoch 616/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 541.1257 - val_loss: 608.3712\n",
      "Epoch 617/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 530.0260 - val_loss: 621.4210\n",
      "Epoch 618/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 497.3735 - val_loss: 644.9748\n",
      "Epoch 619/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.5321 - val_loss: 617.2626\n",
      "Epoch 620/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 585.4627 - val_loss: 652.8121\n",
      "Epoch 621/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.2700 - val_loss: 625.4793\n",
      "Epoch 622/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 624.9519 - val_loss: 629.6973\n",
      "Epoch 623/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.8071 - val_loss: 617.7837\n",
      "Epoch 624/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 498.6801 - val_loss: 613.6967\n",
      "Epoch 625/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.7952 - val_loss: 645.2916\n",
      "Epoch 626/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.0135 - val_loss: 655.7810\n",
      "Epoch 627/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 533.5922 - val_loss: 653.7861\n",
      "Epoch 628/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 587.6923 - val_loss: 649.0470\n",
      "Epoch 629/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 511.3598 - val_loss: 650.5859\n",
      "Epoch 630/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 637.5166 - val_loss: 644.9671\n",
      "Epoch 631/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.6199 - val_loss: 633.5350\n",
      "Epoch 632/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 545.9559 - val_loss: 604.7495\n",
      "Epoch 633/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.4404 - val_loss: 611.4626\n",
      "Epoch 634/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 505.3922 - val_loss: 653.8190\n",
      "Epoch 635/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.4147 - val_loss: 640.7122\n",
      "Epoch 636/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 572.3580 - val_loss: 618.1067\n",
      "Epoch 637/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 501.2773 - val_loss: 657.0441\n",
      "Epoch 638/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 634.2125 - val_loss: 636.2080\n",
      "Epoch 639/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 603.2661 - val_loss: 655.7080\n",
      "Epoch 640/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.1366 - val_loss: 636.0635\n",
      "Epoch 641/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 515.8758 - val_loss: 640.7547\n",
      "Epoch 642/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.1251 - val_loss: 616.3592\n",
      "Epoch 643/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 512.2305 - val_loss: 643.5278\n",
      "Epoch 644/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 603.6256 - val_loss: 650.0552\n",
      "Epoch 645/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.6265 - val_loss: 673.6750\n",
      "Epoch 646/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 489.2098 - val_loss: 652.0425\n",
      "Epoch 647/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 533.2197 - val_loss: 648.7219\n",
      "Epoch 648/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.0121 - val_loss: 652.6286\n",
      "Epoch 649/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.3050 - val_loss: 632.4313\n",
      "Epoch 650/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.0995 - val_loss: 641.8419\n",
      "Epoch 651/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 529.1203 - val_loss: 636.3514\n",
      "Epoch 652/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.3432 - val_loss: 652.5708\n",
      "Epoch 653/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 722.2898 - val_loss: 655.1403\n",
      "Epoch 654/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.1064 - val_loss: 657.1168\n",
      "Epoch 655/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.8412 - val_loss: 653.6269\n",
      "Epoch 656/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.8195 - val_loss: 624.2652\n",
      "Epoch 657/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 597.7084 - val_loss: 635.1697\n",
      "Epoch 658/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.2838 - val_loss: 638.8873\n",
      "Epoch 659/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.9725 - val_loss: 644.8399\n",
      "Epoch 660/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 570.7059 - val_loss: 645.2605\n",
      "Epoch 661/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 454.8999 - val_loss: 630.2578\n",
      "Epoch 662/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.7756 - val_loss: 614.0015\n",
      "Epoch 663/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 480.8497 - val_loss: 650.6435\n",
      "Epoch 664/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.3115 - val_loss: 630.4859\n",
      "Epoch 665/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 582.4085 - val_loss: 651.2614\n",
      "Epoch 666/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 569.5187 - val_loss: 631.3565\n",
      "Epoch 667/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 612.8469 - val_loss: 619.2485\n",
      "Epoch 668/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 597.3947 - val_loss: 621.7920\n",
      "Epoch 669/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 574.5326 - val_loss: 630.0662\n",
      "Epoch 670/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 604.0398 - val_loss: 624.3751\n",
      "Epoch 671/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 578.9788 - val_loss: 643.5573\n",
      "Epoch 672/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 553.6965 - val_loss: 654.0066\n",
      "Epoch 673/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 555.6357 - val_loss: 643.8812\n",
      "Epoch 674/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.4452 - val_loss: 631.9493\n",
      "Epoch 675/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 542.9081 - val_loss: 650.2962\n",
      "Epoch 676/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.4189 - val_loss: 669.0190\n",
      "Epoch 677/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.6619 - val_loss: 637.9616\n",
      "Epoch 678/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 635.3944 - val_loss: 618.1643\n",
      "Epoch 679/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 519.5583 - val_loss: 639.3850\n",
      "Epoch 680/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 608.9310 - val_loss: 624.9215\n",
      "Epoch 681/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.9721 - val_loss: 648.9648\n",
      "Epoch 682/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.2626 - val_loss: 647.2159\n",
      "Epoch 683/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 480.5568 - val_loss: 643.3854\n",
      "Epoch 684/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.8404 - val_loss: 645.2879\n",
      "Epoch 685/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.8160 - val_loss: 644.1875\n",
      "Epoch 686/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.7595 - val_loss: 663.4434\n",
      "Epoch 687/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 539.7937 - val_loss: 635.1736\n",
      "Epoch 688/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.3174 - val_loss: 647.5940\n",
      "Epoch 689/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.5302 - val_loss: 658.5226\n",
      "Epoch 690/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.4838 - val_loss: 644.3383\n",
      "Epoch 691/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.4448 - val_loss: 641.7062\n",
      "Epoch 692/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.5631 - val_loss: 630.5108\n",
      "Epoch 693/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.6984 - val_loss: 648.3445\n",
      "Epoch 694/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 609.7147 - val_loss: 655.7151\n",
      "Epoch 695/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 605.6322 - val_loss: 636.0861\n",
      "Epoch 696/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.0055 - val_loss: 640.3203\n",
      "Epoch 697/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 608.5567 - val_loss: 635.8187\n",
      "Epoch 698/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.3209 - val_loss: 618.2358\n",
      "Epoch 699/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 551.1090 - val_loss: 658.7667\n",
      "Epoch 700/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.2490 - val_loss: 633.0775\n",
      "Epoch 701/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 632.4458 - val_loss: 663.3438\n",
      "Epoch 702/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 512.4320 - val_loss: 633.3326\n",
      "Epoch 703/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.4678 - val_loss: 649.6350\n",
      "Epoch 704/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 534.7724 - val_loss: 644.6930\n",
      "Epoch 705/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.6046 - val_loss: 651.6957\n",
      "Epoch 706/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 544.4232 - val_loss: 646.5667\n",
      "Epoch 707/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 530.3351 - val_loss: 635.1099\n",
      "Epoch 708/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.0190 - val_loss: 622.7656\n",
      "Epoch 709/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 505.5506 - val_loss: 629.6072\n",
      "Epoch 710/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 654.4447 - val_loss: 647.2227\n",
      "Epoch 711/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.2735 - val_loss: 641.0913\n",
      "Epoch 712/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.4763 - val_loss: 638.1157\n",
      "Epoch 713/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.1064 - val_loss: 642.2921\n",
      "Epoch 714/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 559.9637 - val_loss: 626.3144\n",
      "Epoch 715/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.4614 - val_loss: 640.0153\n",
      "Epoch 716/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 630.4798 - val_loss: 623.5678\n",
      "Epoch 717/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.5705 - val_loss: 641.0807\n",
      "Epoch 718/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.9231 - val_loss: 670.8073\n",
      "Epoch 719/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.3135 - val_loss: 644.6463\n",
      "Epoch 720/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 484.6120 - val_loss: 645.8882\n",
      "Epoch 721/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 524.7856 - val_loss: 641.1219\n",
      "Epoch 722/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 530.0611 - val_loss: 647.1122\n",
      "Epoch 723/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.6967 - val_loss: 634.5747\n",
      "Epoch 724/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 503.7113 - val_loss: 630.9335\n",
      "Epoch 725/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.0522 - val_loss: 642.6991\n",
      "Epoch 726/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 569.8349 - val_loss: 626.2540\n",
      "Epoch 727/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.6208 - val_loss: 647.3794\n",
      "Epoch 728/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 614.5296 - val_loss: 669.2560\n",
      "Epoch 729/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.7508 - val_loss: 655.0424\n",
      "Epoch 730/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.1233 - val_loss: 634.4232\n",
      "Epoch 731/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.0028 - val_loss: 658.5886\n",
      "Epoch 732/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.5918 - val_loss: 657.9653\n",
      "Epoch 733/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.5307 - val_loss: 614.9201\n",
      "Epoch 734/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 573.9821 - val_loss: 648.3436\n",
      "Epoch 735/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.0566 - val_loss: 630.8067\n",
      "Epoch 736/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.1392 - val_loss: 687.9700\n",
      "Epoch 737/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 567.9168 - val_loss: 643.9943\n",
      "Epoch 738/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.3919 - val_loss: 629.6922\n",
      "Epoch 739/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 515.6903 - val_loss: 657.6276\n",
      "Epoch 740/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 536.0158 - val_loss: 626.3385\n",
      "Epoch 741/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.6513 - val_loss: 646.0706\n",
      "Epoch 742/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.7364 - val_loss: 627.0285\n",
      "Epoch 743/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 519.9651 - val_loss: 651.0870\n",
      "Epoch 744/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 600.1896 - val_loss: 627.9844\n",
      "Epoch 745/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 558.8526 - val_loss: 645.6258\n",
      "Epoch 746/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.1119 - val_loss: 655.5151\n",
      "Epoch 747/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.3490 - val_loss: 638.7919\n",
      "Epoch 748/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.2318 - val_loss: 641.1729\n",
      "Epoch 749/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 604.7518 - val_loss: 638.7170\n",
      "Epoch 750/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.5468 - val_loss: 662.4170\n",
      "Epoch 751/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 566.0413 - val_loss: 639.0978\n",
      "Epoch 752/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.0573 - val_loss: 651.2505\n",
      "Epoch 753/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 488.7506 - val_loss: 624.9087\n",
      "Epoch 754/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 541.2865 - val_loss: 641.0794\n",
      "Epoch 755/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.7649 - val_loss: 680.0466\n",
      "Epoch 756/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 542.0565 - val_loss: 659.4754\n",
      "Epoch 757/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 554.5480 - val_loss: 652.7232\n",
      "Epoch 758/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.9866 - val_loss: 628.4641\n",
      "Epoch 759/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 640.5470 - val_loss: 657.3038\n",
      "Epoch 760/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 513.4508 - val_loss: 662.2311\n",
      "Epoch 761/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.0758 - val_loss: 628.0162\n",
      "Epoch 762/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.1960 - val_loss: 664.0992\n",
      "Epoch 763/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 537.9726 - val_loss: 645.9036\n",
      "Epoch 764/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.3396 - val_loss: 611.8269\n",
      "Epoch 765/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.0880 - val_loss: 658.8476\n",
      "Epoch 766/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 604.8618 - val_loss: 628.2796\n",
      "Epoch 767/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.5176 - val_loss: 627.3262\n",
      "Epoch 768/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.5081 - val_loss: 639.8491\n",
      "Epoch 769/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 551.0126 - val_loss: 647.9074\n",
      "Epoch 770/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 565.7034 - val_loss: 666.4314\n",
      "Epoch 771/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 545.8092 - val_loss: 663.7814\n",
      "Epoch 772/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 433.4712 - val_loss: 643.8553\n",
      "Epoch 773/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.2592 - val_loss: 658.2374\n",
      "Epoch 774/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 570.1883 - val_loss: 650.5848\n",
      "Epoch 775/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.4633 - val_loss: 626.5875\n",
      "Epoch 776/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 537.6985 - val_loss: 655.1469\n",
      "Epoch 777/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.7206 - val_loss: 619.6018\n",
      "Epoch 778/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 492.0810 - val_loss: 653.4857\n",
      "Epoch 779/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 571.8768 - val_loss: 660.7533\n",
      "Epoch 780/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 530.1518 - val_loss: 644.0907\n",
      "Epoch 781/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.4297 - val_loss: 609.7863\n",
      "Epoch 782/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 620.3360 - val_loss: 631.9056\n",
      "Epoch 783/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.6807 - val_loss: 639.8317\n",
      "Epoch 784/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 545.0073 - val_loss: 647.9573\n",
      "Epoch 785/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.3442 - val_loss: 632.7920\n",
      "Epoch 786/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 414.4219 - val_loss: 634.4962\n",
      "Epoch 787/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.2080 - val_loss: 657.8722\n",
      "Epoch 788/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.1430 - val_loss: 663.0451\n",
      "Epoch 789/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 605.4756 - val_loss: 655.5292\n",
      "Epoch 790/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.2786 - val_loss: 644.7825\n",
      "Epoch 791/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 672.2033 - val_loss: 632.7716\n",
      "Epoch 792/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 498.0607 - val_loss: 651.6295\n",
      "Epoch 793/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 527.4175 - val_loss: 624.4758\n",
      "Epoch 794/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 529.1009 - val_loss: 639.7391\n",
      "Epoch 795/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.9032 - val_loss: 641.7351\n",
      "Epoch 796/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 490.3699 - val_loss: 655.9839\n",
      "Epoch 797/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 594.1043 - val_loss: 635.0953\n",
      "Epoch 798/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 464.5121 - val_loss: 663.3772\n",
      "Epoch 799/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 530.5946 - val_loss: 636.3978\n",
      "Epoch 800/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.2688 - val_loss: 645.7443\n",
      "Epoch 801/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 589.5057 - val_loss: 646.0029\n",
      "Epoch 802/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 500.0157 - val_loss: 657.7593\n",
      "Epoch 803/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.5458 - val_loss: 688.1562\n",
      "Epoch 804/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 515.1561 - val_loss: 651.7619\n",
      "Epoch 805/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.0937 - val_loss: 653.0892\n",
      "Epoch 806/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 566.5584 - val_loss: 651.9184\n",
      "Epoch 807/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 524.4666 - val_loss: 617.2011\n",
      "Epoch 808/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.3230 - val_loss: 624.2735\n",
      "Epoch 809/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 460.5815 - val_loss: 664.6887\n",
      "Epoch 810/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.4478 - val_loss: 641.6849\n",
      "Epoch 811/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 515.4533 - val_loss: 610.2271\n",
      "Epoch 812/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.5271 - val_loss: 663.5013\n",
      "Epoch 813/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 494.2885 - val_loss: 654.5499\n",
      "Epoch 814/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 501.6856 - val_loss: 626.0666\n",
      "Epoch 815/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 547.6229 - val_loss: 667.2634\n",
      "Epoch 816/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 512.2422 - val_loss: 656.6694\n",
      "Epoch 817/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 564.1300 - val_loss: 632.8615\n",
      "Epoch 818/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 483.3037 - val_loss: 645.5032\n",
      "Epoch 819/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.0621 - val_loss: 629.1092\n",
      "Epoch 820/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.3026 - val_loss: 632.9372\n",
      "Epoch 821/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.2110 - val_loss: 613.3102\n",
      "Epoch 822/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 570.9229 - val_loss: 640.7052\n",
      "Epoch 823/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 438.6114 - val_loss: 645.4614\n",
      "Epoch 824/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 519.6470 - val_loss: 632.4793\n",
      "Epoch 825/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.0455 - val_loss: 656.7265\n",
      "Epoch 826/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.5767 - val_loss: 628.0955\n",
      "Epoch 827/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 520.6488 - val_loss: 645.9717\n",
      "Epoch 828/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 583.7977 - val_loss: 638.6233\n",
      "Epoch 829/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 560.7796 - val_loss: 670.2490\n",
      "Epoch 830/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 520.2525 - val_loss: 666.8455\n",
      "Epoch 831/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 602.2810 - val_loss: 651.5382\n",
      "Epoch 832/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.9313 - val_loss: 670.1654\n",
      "Epoch 833/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.9160 - val_loss: 640.5812\n",
      "Epoch 834/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 581.3277 - val_loss: 642.5850\n",
      "Epoch 835/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.9103 - val_loss: 678.3394\n",
      "Epoch 836/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 541.0289 - val_loss: 654.6811\n",
      "Epoch 837/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 480.8970 - val_loss: 649.9120\n",
      "Epoch 838/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.5069 - val_loss: 639.3852\n",
      "Epoch 839/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 483.6479 - val_loss: 669.5002\n",
      "Epoch 840/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.8467 - val_loss: 671.4335\n",
      "Epoch 841/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 505.1112 - val_loss: 666.5270\n",
      "Epoch 842/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 557.3383 - val_loss: 661.2738\n",
      "Epoch 843/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 592.5566 - val_loss: 667.2656\n",
      "Epoch 844/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 542.1493 - val_loss: 647.3417\n",
      "Epoch 845/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 487.1669 - val_loss: 649.0283\n",
      "Epoch 846/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.1715 - val_loss: 677.8492\n",
      "Epoch 847/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.4598 - val_loss: 657.2641\n",
      "Epoch 848/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 517.9246 - val_loss: 653.3388\n",
      "Epoch 849/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 477.7711 - val_loss: 642.0458\n",
      "Epoch 850/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 542.1924 - val_loss: 657.0239\n",
      "Epoch 851/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.0605 - val_loss: 652.8598\n",
      "Epoch 852/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 553.5309 - val_loss: 661.2320\n",
      "Epoch 853/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.0909 - val_loss: 651.5119\n",
      "Epoch 854/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 432.0456 - val_loss: 642.9376\n",
      "Epoch 855/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 445.7079 - val_loss: 654.9277\n",
      "Epoch 856/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.7664 - val_loss: 672.6983\n",
      "Epoch 857/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 533.8034 - val_loss: 667.4686\n",
      "Epoch 858/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.9329 - val_loss: 631.3410\n",
      "Epoch 859/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.1411 - val_loss: 681.4775\n",
      "Epoch 860/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.2868 - val_loss: 617.6828\n",
      "Epoch 861/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.8193 - val_loss: 640.4424\n",
      "Epoch 862/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 616.6719 - val_loss: 655.6431\n",
      "Epoch 863/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 504.7591 - val_loss: 651.6508\n",
      "Epoch 864/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 458.0262 - val_loss: 635.4846\n",
      "Epoch 865/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 510.0956 - val_loss: 661.3572\n",
      "Epoch 866/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 563.4111 - val_loss: 613.3313\n",
      "Epoch 867/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 499.1063 - val_loss: 651.1226\n",
      "Epoch 868/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.2519 - val_loss: 626.3154\n",
      "Epoch 869/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 454.7993 - val_loss: 633.2115\n",
      "Epoch 870/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 525.1447 - val_loss: 664.0623\n",
      "Epoch 871/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 504.6824 - val_loss: 630.9853\n",
      "Epoch 872/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.8652 - val_loss: 655.8905\n",
      "Epoch 873/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 464.7814 - val_loss: 658.7886\n",
      "Epoch 874/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 537.4665 - val_loss: 656.7380\n",
      "Epoch 875/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.9458 - val_loss: 603.3517\n",
      "Epoch 876/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.5371 - val_loss: 647.9578\n",
      "Epoch 877/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 571.3544 - val_loss: 648.4596\n",
      "Epoch 878/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.1271 - val_loss: 640.1383\n",
      "Epoch 879/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 524.1844 - val_loss: 681.2647\n",
      "Epoch 880/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 483.1821 - val_loss: 659.8320\n",
      "Epoch 881/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 484.7656 - val_loss: 668.7228\n",
      "Epoch 882/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 487.5011 - val_loss: 659.0185\n",
      "Epoch 883/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.3092 - val_loss: 651.5026\n",
      "Epoch 884/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 568.8551 - val_loss: 662.9179\n",
      "Epoch 885/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.4995 - val_loss: 650.1848\n",
      "Epoch 886/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 443.1710 - val_loss: 647.9441\n",
      "Epoch 887/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.3647 - val_loss: 667.9999\n",
      "Epoch 888/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 552.8832 - val_loss: 648.3378\n",
      "Epoch 889/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 439.1103 - val_loss: 642.8449\n",
      "Epoch 890/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.1019 - val_loss: 630.8069\n",
      "Epoch 891/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 584.6744 - val_loss: 652.7136\n",
      "Epoch 892/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.8048 - val_loss: 647.9669\n",
      "Epoch 893/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 535.3438 - val_loss: 643.3679\n",
      "Epoch 894/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 537.8263 - val_loss: 653.2949\n",
      "Epoch 895/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.5541 - val_loss: 658.2239\n",
      "Epoch 896/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.6338 - val_loss: 665.7749\n",
      "Epoch 897/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.7327 - val_loss: 640.1752\n",
      "Epoch 898/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.8406 - val_loss: 641.8450\n",
      "Epoch 899/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 519.9338 - val_loss: 631.9386\n",
      "Epoch 900/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 474.0840 - val_loss: 638.0154\n",
      "Epoch 901/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.0577 - val_loss: 672.8213\n",
      "Epoch 902/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.4220 - val_loss: 654.0970\n",
      "Epoch 903/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 513.7249 - val_loss: 636.0978\n",
      "Epoch 904/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 529.6355 - val_loss: 674.5311\n",
      "Epoch 905/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.5764 - val_loss: 639.6793\n",
      "Epoch 906/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 507.2101 - val_loss: 670.4407\n",
      "Epoch 907/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.2520 - val_loss: 672.1325\n",
      "Epoch 908/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 523.0737 - val_loss: 644.1079\n",
      "Epoch 909/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 579.8264 - val_loss: 632.0354\n",
      "Epoch 910/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 504.2078 - val_loss: 672.8492\n",
      "Epoch 911/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 409.8536 - val_loss: 662.2343\n",
      "Epoch 912/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.0332 - val_loss: 673.7211\n",
      "Epoch 913/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.3818 - val_loss: 661.6200\n",
      "Epoch 914/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.1754 - val_loss: 673.6868\n",
      "Epoch 915/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.2948 - val_loss: 675.3600\n",
      "Epoch 916/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 500.0960 - val_loss: 662.2608\n",
      "Epoch 917/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.7606 - val_loss: 679.0889\n",
      "Epoch 918/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.1021 - val_loss: 670.6758\n",
      "Epoch 919/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.7732 - val_loss: 648.9822\n",
      "Epoch 920/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 508.7541 - val_loss: 679.3810\n",
      "Epoch 921/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 459.7958 - val_loss: 646.8225\n",
      "Epoch 922/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 616.0582 - val_loss: 643.9451\n",
      "Epoch 923/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.2713 - val_loss: 649.9312\n",
      "Epoch 924/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.0892 - val_loss: 644.3589\n",
      "Epoch 925/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 514.7572 - val_loss: 672.3535\n",
      "Epoch 926/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 498.0009 - val_loss: 673.9957\n",
      "Epoch 927/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 513.7029 - val_loss: 616.6398\n",
      "Epoch 928/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.7317 - val_loss: 654.4103\n",
      "Epoch 929/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 545.3673 - val_loss: 661.5835\n",
      "Epoch 930/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 467.7043 - val_loss: 665.5679\n",
      "Epoch 931/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 454.9919 - val_loss: 651.5174\n",
      "Epoch 932/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.1951 - val_loss: 659.7477\n",
      "Epoch 933/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 569.9035 - val_loss: 641.6681\n",
      "Epoch 934/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.8873 - val_loss: 664.3964\n",
      "Epoch 935/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 454.3402 - val_loss: 651.5865\n",
      "Epoch 936/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 452.9994 - val_loss: 654.4140\n",
      "Epoch 937/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.1751 - val_loss: 674.3757\n",
      "Epoch 938/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 472.1571 - val_loss: 654.7555\n",
      "Epoch 939/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 580.9311 - val_loss: 630.2361\n",
      "Epoch 940/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.5394 - val_loss: 640.0789\n",
      "Epoch 941/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 495.1583 - val_loss: 659.6655\n",
      "Epoch 942/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.5470 - val_loss: 662.7881\n",
      "Epoch 943/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 424.3389 - val_loss: 640.5278\n",
      "Epoch 944/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 505.8105 - val_loss: 652.0180\n",
      "Epoch 945/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 532.4625 - val_loss: 681.3745\n",
      "Epoch 946/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.3072 - val_loss: 652.7866\n",
      "Epoch 947/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 484.3181 - val_loss: 663.8755\n",
      "Epoch 948/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 495.5407 - val_loss: 673.5039\n",
      "Epoch 949/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.8403 - val_loss: 675.8525\n",
      "Epoch 950/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.6562 - val_loss: 680.2137\n",
      "Epoch 951/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.1942 - val_loss: 685.5036\n",
      "Epoch 952/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.2501 - val_loss: 623.2565\n",
      "Epoch 953/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 556.3680 - val_loss: 653.3129\n",
      "Epoch 954/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.3148 - val_loss: 691.1729\n",
      "Epoch 955/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 463.0816 - val_loss: 672.7089\n",
      "Epoch 956/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.6466 - val_loss: 668.4784\n",
      "Epoch 957/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.4103 - val_loss: 673.1355\n",
      "Epoch 958/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.3578 - val_loss: 668.1264\n",
      "Epoch 959/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 608.9619 - val_loss: 659.5744\n",
      "Epoch 960/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.0416 - val_loss: 672.0895\n",
      "Epoch 961/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.4357 - val_loss: 681.7276\n",
      "Epoch 962/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 523.1755 - val_loss: 652.5894\n",
      "Epoch 963/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 513.7773 - val_loss: 643.7834\n",
      "Epoch 964/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 512.0429 - val_loss: 654.9425\n",
      "Epoch 965/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.1357 - val_loss: 686.6982\n",
      "Epoch 966/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.9636 - val_loss: 679.0375\n",
      "Epoch 967/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 490.1177 - val_loss: 655.4401\n",
      "Epoch 968/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.1590 - val_loss: 676.9339\n",
      "Epoch 969/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 486.9867 - val_loss: 670.7732\n",
      "Epoch 970/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 495.8354 - val_loss: 673.5708\n",
      "Epoch 971/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 465.6724 - val_loss: 624.8263\n",
      "Epoch 972/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.9829 - val_loss: 667.3975\n",
      "Epoch 973/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.9623 - val_loss: 670.3282\n",
      "Epoch 974/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 562.8700 - val_loss: 675.8955\n",
      "Epoch 975/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 443.3217 - val_loss: 671.4826\n",
      "Epoch 976/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.7953 - val_loss: 660.3293\n",
      "Epoch 977/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.7821 - val_loss: 692.4613\n",
      "Epoch 978/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 424.1689 - val_loss: 686.8913\n",
      "Epoch 979/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 501.6579 - val_loss: 675.7851\n",
      "Epoch 980/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 514.4113 - val_loss: 651.0732\n",
      "Epoch 981/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 516.3962 - val_loss: 637.9979\n",
      "Epoch 982/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.8761 - val_loss: 694.7600\n",
      "Epoch 983/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.2831 - val_loss: 681.6968\n",
      "Epoch 984/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.0784 - val_loss: 680.5685\n",
      "Epoch 985/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 448.9073 - val_loss: 637.8126\n",
      "Epoch 986/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.4861 - val_loss: 655.8215\n",
      "Epoch 987/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.8655 - val_loss: 676.4663\n",
      "Epoch 988/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 553.1803 - val_loss: 637.4309\n",
      "Epoch 989/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 492.6203 - val_loss: 655.4534\n",
      "Epoch 990/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.2272 - val_loss: 691.0288\n",
      "Epoch 991/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.5498 - val_loss: 664.2748\n",
      "Epoch 992/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 543.3095 - val_loss: 675.6613\n",
      "Epoch 993/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.6558 - val_loss: 653.6295\n",
      "Epoch 994/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.6134 - val_loss: 688.0765\n",
      "Epoch 995/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 480.1447 - val_loss: 674.5886\n",
      "Epoch 996/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.4671 - val_loss: 690.7002\n",
      "Epoch 997/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 490.6737 - val_loss: 658.8632\n",
      "Epoch 998/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.2934 - val_loss: 653.9220\n",
      "Epoch 999/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.1988 - val_loss: 691.7955\n",
      "Epoch 1000/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 549.2602 - val_loss: 651.1674\n",
      "Epoch 1001/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.4571 - val_loss: 667.4754\n",
      "Epoch 1002/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 495.0617 - val_loss: 650.4249\n",
      "Epoch 1003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 442.7830 - val_loss: 670.7921\n",
      "Epoch 1004/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 564.8233 - val_loss: 654.9999\n",
      "Epoch 1005/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.8702 - val_loss: 663.5310\n",
      "Epoch 1006/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.4914 - val_loss: 651.8276\n",
      "Epoch 1007/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 457.9091 - val_loss: 647.5410\n",
      "Epoch 1008/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.2866 - val_loss: 648.5857\n",
      "Epoch 1009/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.3565 - val_loss: 640.1421\n",
      "Epoch 1010/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 432.1271 - val_loss: 684.2436\n",
      "Epoch 1011/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.7658 - val_loss: 688.9109\n",
      "Epoch 1012/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 486.9726 - val_loss: 677.9597\n",
      "Epoch 1013/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.0731 - val_loss: 655.6191\n",
      "Epoch 1014/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 450.5706 - val_loss: 647.6643\n",
      "Epoch 1015/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 528.4070 - val_loss: 670.8841\n",
      "Epoch 1016/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 451.0923 - val_loss: 671.6454\n",
      "Epoch 1017/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 478.8497 - val_loss: 677.9605\n",
      "Epoch 1018/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.8549 - val_loss: 656.0226\n",
      "Epoch 1019/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 494.9812 - val_loss: 651.7413\n",
      "Epoch 1020/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.0655 - val_loss: 693.3426\n",
      "Epoch 1021/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.9534 - val_loss: 676.2399\n",
      "Epoch 1022/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.9336 - val_loss: 676.7535\n",
      "Epoch 1023/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 425.5466 - val_loss: 665.9736\n",
      "Epoch 1024/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 533.4339 - val_loss: 663.4882\n",
      "Epoch 1025/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.8859 - val_loss: 675.0696\n",
      "Epoch 1026/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.7923 - val_loss: 690.4829\n",
      "Epoch 1027/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.9377 - val_loss: 652.2349\n",
      "Epoch 1028/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 385.4602 - val_loss: 671.6376\n",
      "Epoch 1029/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.5810 - val_loss: 646.3917\n",
      "Epoch 1030/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 526.8665 - val_loss: 664.3055\n",
      "Epoch 1031/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 529.1958 - val_loss: 665.4853\n",
      "Epoch 1032/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 503.1164 - val_loss: 650.9363\n",
      "Epoch 1033/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.9227 - val_loss: 683.7602\n",
      "Epoch 1034/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.0722 - val_loss: 670.0335\n",
      "Epoch 1035/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.2186 - val_loss: 679.0339\n",
      "Epoch 1036/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.3065 - val_loss: 683.0834\n",
      "Epoch 1037/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 443.5329 - val_loss: 678.5699\n",
      "Epoch 1038/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.8636 - val_loss: 643.0217\n",
      "Epoch 1039/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.8450 - val_loss: 676.8594\n",
      "Epoch 1040/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.7090 - val_loss: 676.4225\n",
      "Epoch 1041/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 518.3936 - val_loss: 680.8438\n",
      "Epoch 1042/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.6931 - val_loss: 629.8443\n",
      "Epoch 1043/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.8366 - val_loss: 673.7858\n",
      "Epoch 1044/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 511.4764 - val_loss: 655.7518\n",
      "Epoch 1045/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 458.0534 - val_loss: 655.2360\n",
      "Epoch 1046/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 478.3216 - val_loss: 665.9822\n",
      "Epoch 1047/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 445.9076 - val_loss: 653.6628\n",
      "Epoch 1048/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 483.3541 - val_loss: 652.0095\n",
      "Epoch 1049/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 429.9067 - val_loss: 660.4817\n",
      "Epoch 1050/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 450.6285 - val_loss: 694.6564\n",
      "Epoch 1051/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.1253 - val_loss: 672.8649\n",
      "Epoch 1052/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.0032 - val_loss: 668.6445\n",
      "Epoch 1053/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.4389 - val_loss: 688.0539\n",
      "Epoch 1054/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.3794 - val_loss: 663.3135\n",
      "Epoch 1055/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 548.4704 - val_loss: 691.9999\n",
      "Epoch 1056/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.9331 - val_loss: 691.8374\n",
      "Epoch 1057/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 495.3561 - val_loss: 671.1442\n",
      "Epoch 1058/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.9785 - val_loss: 672.3275\n",
      "Epoch 1059/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.8076 - val_loss: 683.1538\n",
      "Epoch 1060/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 472.6541 - val_loss: 670.5675\n",
      "Epoch 1061/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.2217 - val_loss: 686.3063\n",
      "Epoch 1062/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.4891 - val_loss: 682.3101\n",
      "Epoch 1063/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 480.3387 - val_loss: 653.5818\n",
      "Epoch 1064/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.6644 - val_loss: 686.4169\n",
      "Epoch 1065/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 496.5308 - val_loss: 661.8734\n",
      "Epoch 1066/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 521.8799 - val_loss: 689.0166\n",
      "Epoch 1067/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 397.3851 - val_loss: 692.5947\n",
      "Epoch 1068/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.3804 - val_loss: 688.3090\n",
      "Epoch 1069/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 475.0477 - val_loss: 631.2099\n",
      "Epoch 1070/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.4927 - val_loss: 674.8702\n",
      "Epoch 1071/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.6033 - val_loss: 694.0740\n",
      "Epoch 1072/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.7593 - val_loss: 672.8039\n",
      "Epoch 1073/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 454.6173 - val_loss: 693.2620\n",
      "Epoch 1074/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.4352 - val_loss: 673.3102\n",
      "Epoch 1075/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 484.7442 - val_loss: 675.7388\n",
      "Epoch 1076/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.3032 - val_loss: 689.8127\n",
      "Epoch 1077/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.3122 - val_loss: 667.4538\n",
      "Epoch 1078/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 527.2298 - val_loss: 689.3163\n",
      "Epoch 1079/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 432.8676 - val_loss: 687.0224\n",
      "Epoch 1080/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 465.8278 - val_loss: 694.4932\n",
      "Epoch 1081/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.3400 - val_loss: 681.2852\n",
      "Epoch 1082/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.7752 - val_loss: 673.9095\n",
      "Epoch 1083/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.4709 - val_loss: 671.0297\n",
      "Epoch 1084/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 464.6650 - val_loss: 667.4533\n",
      "Epoch 1085/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 502.6079 - val_loss: 685.2406\n",
      "Epoch 1086/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 429.6075 - val_loss: 675.9565\n",
      "Epoch 1087/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 487.5714 - val_loss: 671.6184\n",
      "Epoch 1088/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 461.9239 - val_loss: 648.1136\n",
      "Epoch 1089/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.7531 - val_loss: 681.3099\n",
      "Epoch 1090/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 428.3660 - val_loss: 688.3947\n",
      "Epoch 1091/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.3964 - val_loss: 662.4063\n",
      "Epoch 1092/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 531.5564 - val_loss: 679.2259\n",
      "Epoch 1093/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 473.6404 - val_loss: 679.7269\n",
      "Epoch 1094/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.7377 - val_loss: 680.2721\n",
      "Epoch 1095/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.9298 - val_loss: 684.1750\n",
      "Epoch 1096/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.9377 - val_loss: 637.2730\n",
      "Epoch 1097/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.9023 - val_loss: 639.8207\n",
      "Epoch 1098/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 516.3508 - val_loss: 679.4122\n",
      "Epoch 1099/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 425.7965 - val_loss: 695.9212\n",
      "Epoch 1100/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 479.5895 - val_loss: 678.4426\n",
      "Epoch 1101/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 458.2432 - val_loss: 698.5606\n",
      "Epoch 1102/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.8865 - val_loss: 683.0389\n",
      "Epoch 1103/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.6700 - val_loss: 684.4427\n",
      "Epoch 1104/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 448.5148 - val_loss: 678.2293\n",
      "Epoch 1105/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.1350 - val_loss: 671.7475\n",
      "Epoch 1106/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.0924 - val_loss: 698.4048\n",
      "Epoch 1107/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 484.0165 - val_loss: 686.0386\n",
      "Epoch 1108/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.5870 - val_loss: 651.9083\n",
      "Epoch 1109/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 490.8412 - val_loss: 695.6749\n",
      "Epoch 1110/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 493.7937 - val_loss: 663.3918\n",
      "Epoch 1111/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.7772 - val_loss: 664.9641\n",
      "Epoch 1112/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.9814 - val_loss: 680.4393\n",
      "Epoch 1113/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.3547 - val_loss: 651.7499\n",
      "Epoch 1114/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.8579 - val_loss: 632.6066\n",
      "Epoch 1115/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 450.8271 - val_loss: 662.9531\n",
      "Epoch 1116/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.5331 - val_loss: 652.7212\n",
      "Epoch 1117/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.6011 - val_loss: 651.6913\n",
      "Epoch 1118/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.0340 - val_loss: 695.3153\n",
      "Epoch 1119/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 439.8454 - val_loss: 655.1791\n",
      "Epoch 1120/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.4392 - val_loss: 694.7912\n",
      "Epoch 1121/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.3162 - val_loss: 693.0556\n",
      "Epoch 1122/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 486.2551 - val_loss: 674.0302\n",
      "Epoch 1123/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.7968 - val_loss: 695.1106\n",
      "Epoch 1124/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.8664 - val_loss: 695.5488\n",
      "Epoch 1125/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.6997 - val_loss: 649.3192\n",
      "Epoch 1126/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 473.8668 - val_loss: 692.1425\n",
      "Epoch 1127/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 448.4307 - val_loss: 678.2590\n",
      "Epoch 1128/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.7895 - val_loss: 670.9736\n",
      "Epoch 1129/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.5094 - val_loss: 685.1019\n",
      "Epoch 1130/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.8902 - val_loss: 660.2717\n",
      "Epoch 1131/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.4194 - val_loss: 691.7363\n",
      "Epoch 1132/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.4657 - val_loss: 680.7722\n",
      "Epoch 1133/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 540.7352 - val_loss: 667.6109\n",
      "Epoch 1134/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.5234 - val_loss: 683.2492\n",
      "Epoch 1135/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.4133 - val_loss: 637.3605\n",
      "Epoch 1136/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 472.4178 - val_loss: 669.6526\n",
      "Epoch 1137/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 424.5275 - val_loss: 698.4689\n",
      "Epoch 1138/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.8443 - val_loss: 638.4707\n",
      "Epoch 1139/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 448.9984 - val_loss: 643.6836\n",
      "Epoch 1140/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 449.4808 - val_loss: 682.9730\n",
      "Epoch 1141/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.8886 - val_loss: 681.0085\n",
      "Epoch 1142/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.9542 - val_loss: 685.1462\n",
      "Epoch 1143/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 522.0474 - val_loss: 661.9257\n",
      "Epoch 1144/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 439.7639 - val_loss: 668.5911\n",
      "Epoch 1145/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.2932 - val_loss: 693.0439\n",
      "Epoch 1146/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 472.9429 - val_loss: 706.0740\n",
      "Epoch 1147/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 484.6249 - val_loss: 676.4093\n",
      "Epoch 1148/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.3757 - val_loss: 698.6595\n",
      "Epoch 1149/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 432.5767 - val_loss: 650.6472\n",
      "Epoch 1150/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 401.8618 - val_loss: 621.3039\n",
      "Epoch 1151/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 455.2511 - val_loss: 701.9700\n",
      "Epoch 1152/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.1836 - val_loss: 659.3344\n",
      "Epoch 1153/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.8510 - val_loss: 690.1398\n",
      "Epoch 1154/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 506.1255 - val_loss: 674.2001\n",
      "Epoch 1155/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 445.0555 - val_loss: 651.8135\n",
      "Epoch 1156/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.1232 - val_loss: 638.4473\n",
      "Epoch 1157/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 443.7492 - val_loss: 682.9836\n",
      "Epoch 1158/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.6176 - val_loss: 671.4937\n",
      "Epoch 1159/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 450.7305 - val_loss: 684.3512\n",
      "Epoch 1160/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 509.5716 - val_loss: 645.7426\n",
      "Epoch 1161/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.4421 - val_loss: 633.1442\n",
      "Epoch 1162/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 458.9759 - val_loss: 683.6020\n",
      "Epoch 1163/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.6961 - val_loss: 652.9617\n",
      "Epoch 1164/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 498.5587 - val_loss: 669.0683\n",
      "Epoch 1165/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 417.4389 - val_loss: 663.9948\n",
      "Epoch 1166/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.4311 - val_loss: 671.0463\n",
      "Epoch 1167/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.1406 - val_loss: 662.1094\n",
      "Epoch 1168/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 467.0828 - val_loss: 708.6323\n",
      "Epoch 1169/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.8683 - val_loss: 675.8134\n",
      "Epoch 1170/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 482.4251 - val_loss: 660.7342\n",
      "Epoch 1171/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.7395 - val_loss: 696.0534\n",
      "Epoch 1172/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.3486 - val_loss: 665.3511\n",
      "Epoch 1173/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.0404 - val_loss: 665.1524\n",
      "Epoch 1174/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.5086 - val_loss: 674.5697\n",
      "Epoch 1175/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.3309 - val_loss: 689.0609\n",
      "Epoch 1176/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.7179 - val_loss: 676.3491\n",
      "Epoch 1177/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 475.3606 - val_loss: 679.5097\n",
      "Epoch 1178/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.0856 - val_loss: 685.0641\n",
      "Epoch 1179/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.9846 - val_loss: 668.7123\n",
      "Epoch 1180/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 467.1498 - val_loss: 674.8785\n",
      "Epoch 1181/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.7090 - val_loss: 665.7673\n",
      "Epoch 1182/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.0508 - val_loss: 668.6869\n",
      "Epoch 1183/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 458.1806 - val_loss: 671.8196\n",
      "Epoch 1184/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 471.7822 - val_loss: 657.1840\n",
      "Epoch 1185/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.7046 - val_loss: 638.6105\n",
      "Epoch 1186/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.3832 - val_loss: 679.8744\n",
      "Epoch 1187/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.2564 - val_loss: 631.8295\n",
      "Epoch 1188/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.1749 - val_loss: 671.6186\n",
      "Epoch 1189/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 455.0637 - val_loss: 684.6491\n",
      "Epoch 1190/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.7734 - val_loss: 693.3776\n",
      "Epoch 1191/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.3399 - val_loss: 677.1980\n",
      "Epoch 1192/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.0217 - val_loss: 692.5447\n",
      "Epoch 1193/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.0836 - val_loss: 672.1335\n",
      "Epoch 1194/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.9729 - val_loss: 674.8923\n",
      "Epoch 1195/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 529.7727 - val_loss: 676.6336\n",
      "Epoch 1196/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.9600 - val_loss: 682.0861\n",
      "Epoch 1197/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 455.3048 - val_loss: 657.6794\n",
      "Epoch 1198/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.1587 - val_loss: 663.3913\n",
      "Epoch 1199/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 467.2036 - val_loss: 682.5831\n",
      "Epoch 1200/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.0529 - val_loss: 671.5725\n",
      "Epoch 1201/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.9340 - val_loss: 704.1205\n",
      "Epoch 1202/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 536.0022 - val_loss: 631.7167\n",
      "Epoch 1203/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.7114 - val_loss: 647.0058\n",
      "Epoch 1204/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 475.9504 - val_loss: 691.7867\n",
      "Epoch 1205/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 443.3992 - val_loss: 675.1845\n",
      "Epoch 1206/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.6305 - val_loss: 693.8909\n",
      "Epoch 1207/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.0914 - val_loss: 683.3610\n",
      "Epoch 1208/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.6671 - val_loss: 695.9453\n",
      "Epoch 1209/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 396.3851 - val_loss: 672.1148\n",
      "Epoch 1210/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 436.9607 - val_loss: 683.3780\n",
      "Epoch 1211/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.1362 - val_loss: 682.7126\n",
      "Epoch 1212/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.1811 - val_loss: 642.6357\n",
      "Epoch 1213/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 460.7723 - val_loss: 658.2797\n",
      "Epoch 1214/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 465.3243 - val_loss: 691.3954\n",
      "Epoch 1215/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.0776 - val_loss: 674.8856\n",
      "Epoch 1216/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.4930 - val_loss: 703.3641\n",
      "Epoch 1217/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.1279 - val_loss: 683.1301\n",
      "Epoch 1218/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.8614 - val_loss: 710.0359\n",
      "Epoch 1219/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.8595 - val_loss: 674.8503\n",
      "Epoch 1220/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.4172 - val_loss: 664.2767\n",
      "Epoch 1221/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.9313 - val_loss: 656.7095\n",
      "Epoch 1222/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.6328 - val_loss: 666.0730\n",
      "Epoch 1223/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.9737 - val_loss: 678.9593\n",
      "Epoch 1224/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.2047 - val_loss: 686.1175\n",
      "Epoch 1225/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.3689 - val_loss: 685.4728\n",
      "Epoch 1226/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.3629 - val_loss: 671.9502\n",
      "Epoch 1227/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.4256 - val_loss: 708.5160\n",
      "Epoch 1228/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 429.4961 - val_loss: 683.1069\n",
      "Epoch 1229/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 435.1871 - val_loss: 681.7894\n",
      "Epoch 1230/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 449.9892 - val_loss: 654.5222\n",
      "Epoch 1231/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 526.9340 - val_loss: 647.0705\n",
      "Epoch 1232/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.8702 - val_loss: 669.5274\n",
      "Epoch 1233/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.4036 - val_loss: 677.6742\n",
      "Epoch 1234/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 455.6400 - val_loss: 684.2517\n",
      "Epoch 1235/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.9550 - val_loss: 699.5841\n",
      "Epoch 1236/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.2254 - val_loss: 680.9839\n",
      "Epoch 1237/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.6279 - val_loss: 691.3673\n",
      "Epoch 1238/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.6809 - val_loss: 679.2259\n",
      "Epoch 1239/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.1779 - val_loss: 665.2541\n",
      "Epoch 1240/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.0739 - val_loss: 679.6043\n",
      "Epoch 1241/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.4878 - val_loss: 701.2191\n",
      "Epoch 1242/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.0876 - val_loss: 678.4128\n",
      "Epoch 1243/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.3643 - val_loss: 708.7172\n",
      "Epoch 1244/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.1235 - val_loss: 700.6179\n",
      "Epoch 1245/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.8041 - val_loss: 693.0464\n",
      "Epoch 1246/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.0548 - val_loss: 646.3348\n",
      "Epoch 1247/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 467.6529 - val_loss: 636.2989\n",
      "Epoch 1248/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.1515 - val_loss: 700.7124\n",
      "Epoch 1249/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 428.5627 - val_loss: 669.2694\n",
      "Epoch 1250/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 417.5136 - val_loss: 674.6870\n",
      "Epoch 1251/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.4403 - val_loss: 698.4313\n",
      "Epoch 1252/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 396.3202 - val_loss: 678.3935\n",
      "Epoch 1253/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 432.3335 - val_loss: 667.5328\n",
      "Epoch 1254/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.7078 - val_loss: 698.7093\n",
      "Epoch 1255/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 441.3098 - val_loss: 694.2943\n",
      "Epoch 1256/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 466.2581 - val_loss: 663.6749\n",
      "Epoch 1257/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.2422 - val_loss: 683.7993\n",
      "Epoch 1258/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.2621 - val_loss: 697.8574\n",
      "Epoch 1259/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 445.3774 - val_loss: 688.5557\n",
      "Epoch 1260/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 474.3469 - val_loss: 705.8545\n",
      "Epoch 1261/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.9722 - val_loss: 654.3307\n",
      "Epoch 1262/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 499.2820 - val_loss: 666.4569\n",
      "Epoch 1263/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.2773 - val_loss: 681.2587\n",
      "Epoch 1264/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.2377 - val_loss: 688.1370\n",
      "Epoch 1265/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.6170 - val_loss: 686.8156\n",
      "Epoch 1266/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 425.3063 - val_loss: 692.8733\n",
      "Epoch 1267/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.9373 - val_loss: 687.9465\n",
      "Epoch 1268/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 452.5084 - val_loss: 690.3475\n",
      "Epoch 1269/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 477.5494 - val_loss: 665.5909\n",
      "Epoch 1270/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.1126 - val_loss: 689.6212\n",
      "Epoch 1271/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.5611 - val_loss: 641.7509\n",
      "Epoch 1272/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 481.3161 - val_loss: 662.3246\n",
      "Epoch 1273/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 354.2465 - val_loss: 665.1088\n",
      "Epoch 1274/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 346.4248 - val_loss: 675.8719\n",
      "Epoch 1275/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 464.6053 - val_loss: 685.5794\n",
      "Epoch 1276/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.9691 - val_loss: 682.0221\n",
      "Epoch 1277/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 499.0213 - val_loss: 698.4061\n",
      "Epoch 1278/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.1863 - val_loss: 684.6954\n",
      "Epoch 1279/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 456.5037 - val_loss: 700.2230\n",
      "Epoch 1280/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.0829 - val_loss: 707.5146\n",
      "Epoch 1281/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 472.0042 - val_loss: 679.3242\n",
      "Epoch 1282/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.7872 - val_loss: 687.8985\n",
      "Epoch 1283/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.1068 - val_loss: 677.2229\n",
      "Epoch 1284/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 437.8686 - val_loss: 700.5660\n",
      "Epoch 1285/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.3357 - val_loss: 695.3294\n",
      "Epoch 1286/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.5166 - val_loss: 695.6651\n",
      "Epoch 1287/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 363.0463 - val_loss: 692.0670\n",
      "Epoch 1288/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 476.8030 - val_loss: 696.5305\n",
      "Epoch 1289/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.5190 - val_loss: 695.4070\n",
      "Epoch 1290/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.1948 - val_loss: 667.4599\n",
      "Epoch 1291/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.5571 - val_loss: 691.2629\n",
      "Epoch 1292/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 447.9998 - val_loss: 690.1035\n",
      "Epoch 1293/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 459.9653 - val_loss: 707.0904\n",
      "Epoch 1294/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.6293 - val_loss: 682.4135\n",
      "Epoch 1295/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 478.3971 - val_loss: 687.2658\n",
      "Epoch 1296/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.3426 - val_loss: 705.3542\n",
      "Epoch 1297/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 388.2388 - val_loss: 694.9186\n",
      "Epoch 1298/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.3558 - val_loss: 653.3960\n",
      "Epoch 1299/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.4349 - val_loss: 708.6167\n",
      "Epoch 1300/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 429.0834 - val_loss: 645.2459\n",
      "Epoch 1301/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.9556 - val_loss: 696.8019\n",
      "Epoch 1302/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 457.8140 - val_loss: 672.4528\n",
      "Epoch 1303/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.4174 - val_loss: 703.6235\n",
      "Epoch 1304/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.9259 - val_loss: 713.1149\n",
      "Epoch 1305/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.0516 - val_loss: 681.9575\n",
      "Epoch 1306/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 455.5667 - val_loss: 692.8558\n",
      "Epoch 1307/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 14s 1s/step - loss: 471.2817 - val_loss: 676.0169\n",
      "Epoch 1308/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.4329 - val_loss: 670.5135\n",
      "Epoch 1309/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.2229 - val_loss: 677.0926\n",
      "Epoch 1310/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.6072 - val_loss: 689.4582\n",
      "Epoch 1311/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.1410 - val_loss: 686.3717\n",
      "Epoch 1312/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.0426 - val_loss: 688.4585\n",
      "Epoch 1313/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 431.2712 - val_loss: 683.1784\n",
      "Epoch 1314/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.2505 - val_loss: 713.8351\n",
      "Epoch 1315/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.3115 - val_loss: 692.7494\n",
      "Epoch 1316/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.8201 - val_loss: 692.5076\n",
      "Epoch 1317/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.1719 - val_loss: 691.4169\n",
      "Epoch 1318/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.8229 - val_loss: 648.4125\n",
      "Epoch 1319/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.0403 - val_loss: 691.4803\n",
      "Epoch 1320/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 445.7351 - val_loss: 648.9770\n",
      "Epoch 1321/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 425.4701 - val_loss: 688.7474\n",
      "Epoch 1322/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 386.1478 - val_loss: 681.0780\n",
      "Epoch 1323/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.5129 - val_loss: 719.1136\n",
      "Epoch 1324/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.2899 - val_loss: 688.1911\n",
      "Epoch 1325/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.0730 - val_loss: 684.7753\n",
      "Epoch 1326/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 497.3969 - val_loss: 688.8973\n",
      "Epoch 1327/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.9705 - val_loss: 688.4830\n",
      "Epoch 1328/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.2071 - val_loss: 689.4709\n",
      "Epoch 1329/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.1863 - val_loss: 705.5800\n",
      "Epoch 1330/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 465.3138 - val_loss: 700.0489\n",
      "Epoch 1331/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.6015 - val_loss: 702.7430\n",
      "Epoch 1332/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.3846 - val_loss: 694.3410\n",
      "Epoch 1333/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 461.5138 - val_loss: 674.0684\n",
      "Epoch 1334/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.2390 - val_loss: 703.2401\n",
      "Epoch 1335/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.5241 - val_loss: 729.6455\n",
      "Epoch 1336/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.5456 - val_loss: 670.2088\n",
      "Epoch 1337/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.9234 - val_loss: 666.2474\n",
      "Epoch 1338/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.2284 - val_loss: 685.7736\n",
      "Epoch 1339/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.9987 - val_loss: 698.4079\n",
      "Epoch 1340/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.8887 - val_loss: 678.7061\n",
      "Epoch 1341/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 481.6200 - val_loss: 682.1729\n",
      "Epoch 1342/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.0614 - val_loss: 697.9667\n",
      "Epoch 1343/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.4791 - val_loss: 704.3313\n",
      "Epoch 1344/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 449.9327 - val_loss: 708.5668\n",
      "Epoch 1345/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.6762 - val_loss: 671.4403\n",
      "Epoch 1346/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.6868 - val_loss: 673.9182\n",
      "Epoch 1347/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.1464 - val_loss: 694.8349\n",
      "Epoch 1348/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.8782 - val_loss: 666.4217\n",
      "Epoch 1349/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 450.4444 - val_loss: 675.1586\n",
      "Epoch 1350/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 424.4418 - val_loss: 691.3748\n",
      "Epoch 1351/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 449.8422 - val_loss: 672.5749\n",
      "Epoch 1352/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.5510 - val_loss: 685.6295\n",
      "Epoch 1353/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.3736 - val_loss: 695.4316\n",
      "Epoch 1354/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.6630 - val_loss: 690.4934\n",
      "Epoch 1355/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.6539 - val_loss: 711.3590\n",
      "Epoch 1356/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.3029 - val_loss: 713.2364\n",
      "Epoch 1357/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.4161 - val_loss: 688.6118\n",
      "Epoch 1358/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.0307 - val_loss: 655.0150\n",
      "Epoch 1359/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.4134 - val_loss: 704.3805\n",
      "Epoch 1360/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.7450 - val_loss: 690.5262\n",
      "Epoch 1361/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.4769 - val_loss: 701.9787\n",
      "Epoch 1362/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.9753 - val_loss: 679.8442\n",
      "Epoch 1363/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 425.2254 - val_loss: 696.9558\n",
      "Epoch 1364/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 454.9740 - val_loss: 678.8562\n",
      "Epoch 1365/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.0063 - val_loss: 685.0582\n",
      "Epoch 1366/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.2724 - val_loss: 692.7775\n",
      "Epoch 1367/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.8880 - val_loss: 676.0650\n",
      "Epoch 1368/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.6306 - val_loss: 698.0859\n",
      "Epoch 1369/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.2813 - val_loss: 689.2345\n",
      "Epoch 1370/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.4013 - val_loss: 703.9302\n",
      "Epoch 1371/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.6814 - val_loss: 678.4872\n",
      "Epoch 1372/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 364.6958 - val_loss: 704.2653\n",
      "Epoch 1373/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.4494 - val_loss: 654.2675\n",
      "Epoch 1374/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.2602 - val_loss: 678.0243\n",
      "Epoch 1375/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.6061 - val_loss: 667.2784\n",
      "Epoch 1376/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.3130 - val_loss: 686.3020\n",
      "Epoch 1377/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.7747 - val_loss: 650.4726\n",
      "Epoch 1378/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.0360 - val_loss: 712.2953\n",
      "Epoch 1379/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.8358 - val_loss: 670.3905\n",
      "Epoch 1380/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 420.4610 - val_loss: 670.9341\n",
      "Epoch 1381/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.7368 - val_loss: 696.3834\n",
      "Epoch 1382/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 409.2094 - val_loss: 700.7388\n",
      "Epoch 1383/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 442.8794 - val_loss: 683.6942\n",
      "Epoch 1384/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 488.8602 - val_loss: 678.3701\n",
      "Epoch 1385/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.8078 - val_loss: 680.8294\n",
      "Epoch 1386/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.5251 - val_loss: 694.6874\n",
      "Epoch 1387/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.5587 - val_loss: 696.5772\n",
      "Epoch 1388/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.9680 - val_loss: 688.3820\n",
      "Epoch 1389/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 427.1763 - val_loss: 667.5609\n",
      "Epoch 1390/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.4588 - val_loss: 629.2274\n",
      "Epoch 1391/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.4278 - val_loss: 677.3528\n",
      "Epoch 1392/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.7120 - val_loss: 700.3399\n",
      "Epoch 1393/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.8888 - val_loss: 696.9821\n",
      "Epoch 1394/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.8457 - val_loss: 709.0868\n",
      "Epoch 1395/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 468.7145 - val_loss: 682.6258\n",
      "Epoch 1396/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.3415 - val_loss: 694.8998\n",
      "Epoch 1397/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 368.9363 - val_loss: 688.5962\n",
      "Epoch 1398/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.8087 - val_loss: 717.1107\n",
      "Epoch 1399/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 350.2479 - val_loss: 697.1017\n",
      "Epoch 1400/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.5315 - val_loss: 703.6568\n",
      "Epoch 1401/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 491.2247 - val_loss: 689.3354\n",
      "Epoch 1402/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.9169 - val_loss: 678.6986\n",
      "Epoch 1403/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.5151 - val_loss: 680.1460\n",
      "Epoch 1404/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.9554 - val_loss: 676.0123\n",
      "Epoch 1405/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.1053 - val_loss: 685.0256\n",
      "Epoch 1406/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 396.6723 - val_loss: 718.7671\n",
      "Epoch 1407/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 435.7247 - val_loss: 710.9903\n",
      "Epoch 1408/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.3899 - val_loss: 682.7619\n",
      "Epoch 1409/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.8126 - val_loss: 723.7981\n",
      "Epoch 1410/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.7777 - val_loss: 716.8562\n",
      "Epoch 1411/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.2111 - val_loss: 665.1022\n",
      "Epoch 1412/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 387.8586 - val_loss: 695.2546\n",
      "Epoch 1413/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.0718 - val_loss: 683.1410\n",
      "Epoch 1414/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.8211 - val_loss: 701.0980\n",
      "Epoch 1415/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.8753 - val_loss: 712.1046\n",
      "Epoch 1416/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.4260 - val_loss: 671.5400\n",
      "Epoch 1417/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.1481 - val_loss: 685.7877\n",
      "Epoch 1418/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 417.5421 - val_loss: 706.8379\n",
      "Epoch 1419/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.2697 - val_loss: 712.7304\n",
      "Epoch 1420/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 443.9445 - val_loss: 715.1880\n",
      "Epoch 1421/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.7715 - val_loss: 693.3918\n",
      "Epoch 1422/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 410.9332 - val_loss: 668.0609\n",
      "Epoch 1423/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 401.4001 - val_loss: 727.0039\n",
      "Epoch 1424/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.7895 - val_loss: 717.3019\n",
      "Epoch 1425/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.8784 - val_loss: 710.1412\n",
      "Epoch 1426/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 363.1211 - val_loss: 705.8939\n",
      "Epoch 1427/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.2111 - val_loss: 691.1704\n",
      "Epoch 1428/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 396.5571 - val_loss: 680.6847\n",
      "Epoch 1429/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 453.9421 - val_loss: 689.4538\n",
      "Epoch 1430/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 367.9230 - val_loss: 676.3575\n",
      "Epoch 1431/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.8092 - val_loss: 704.7397\n",
      "Epoch 1432/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 451.7915 - val_loss: 715.2914\n",
      "Epoch 1433/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.5121 - val_loss: 693.0129\n",
      "Epoch 1434/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 437.8989 - val_loss: 681.0227\n",
      "Epoch 1435/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.5612 - val_loss: 692.8790\n",
      "Epoch 1436/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.3082 - val_loss: 728.7219\n",
      "Epoch 1437/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.6896 - val_loss: 704.3136\n",
      "Epoch 1438/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 485.6453 - val_loss: 706.5966\n",
      "Epoch 1439/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.9691 - val_loss: 709.1450\n",
      "Epoch 1440/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.4817 - val_loss: 695.4248\n",
      "Epoch 1441/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 445.1078 - val_loss: 689.4874\n",
      "Epoch 1442/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.9032 - val_loss: 684.3564\n",
      "Epoch 1443/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.5862 - val_loss: 699.9636\n",
      "Epoch 1444/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 386.6092 - val_loss: 677.5582\n",
      "Epoch 1445/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.8478 - val_loss: 690.9405\n",
      "Epoch 1446/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.2409 - val_loss: 685.7050\n",
      "Epoch 1447/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.4564 - val_loss: 723.9175\n",
      "Epoch 1448/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 422.2222 - val_loss: 691.9134\n",
      "Epoch 1449/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 434.7628 - val_loss: 696.4348\n",
      "Epoch 1450/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 441.7896 - val_loss: 689.1028\n",
      "Epoch 1451/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 374.9445 - val_loss: 705.1165\n",
      "Epoch 1452/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.0149 - val_loss: 689.2980\n",
      "Epoch 1453/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 428.3450 - val_loss: 712.8744\n",
      "Epoch 1454/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.9096 - val_loss: 699.6301\n",
      "Epoch 1455/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 442.4202 - val_loss: 696.6875\n",
      "Epoch 1456/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.5855 - val_loss: 683.9959\n",
      "Epoch 1457/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 391.8113 - val_loss: 715.2350\n",
      "Epoch 1458/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.4516 - val_loss: 687.4684\n",
      "Epoch 1459/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 417.9023 - val_loss: 709.4319\n",
      "Epoch 1460/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.1571 - val_loss: 674.6516\n",
      "Epoch 1461/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.6049 - val_loss: 681.8456\n",
      "Epoch 1462/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.8671 - val_loss: 702.2079\n",
      "Epoch 1463/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.9143 - val_loss: 714.4580\n",
      "Epoch 1464/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.2920 - val_loss: 719.2376\n",
      "Epoch 1465/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.9522 - val_loss: 713.7342\n",
      "Epoch 1466/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.8374 - val_loss: 700.9410\n",
      "Epoch 1467/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 328.4475 - val_loss: 667.9972\n",
      "Epoch 1468/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 438.0123 - val_loss: 670.8956\n",
      "Epoch 1469/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 367.3693 - val_loss: 718.0675\n",
      "Epoch 1470/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 446.5572 - val_loss: 678.3691\n",
      "Epoch 1471/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.7857 - val_loss: 698.9849\n",
      "Epoch 1472/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.2726 - val_loss: 698.7638\n",
      "Epoch 1473/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.7715 - val_loss: 697.1106\n",
      "Epoch 1474/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.5415 - val_loss: 705.7489\n",
      "Epoch 1475/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.4362 - val_loss: 683.4895\n",
      "Epoch 1476/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.2025 - val_loss: 686.0060\n",
      "Epoch 1477/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.0254 - val_loss: 709.3379\n",
      "Epoch 1478/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.6949 - val_loss: 733.5452\n",
      "Epoch 1479/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.3172 - val_loss: 678.6150\n",
      "Epoch 1480/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 382.8283 - val_loss: 731.2432\n",
      "Epoch 1481/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 449.8281 - val_loss: 706.6847\n",
      "Epoch 1482/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 459.8121 - val_loss: 697.2095\n",
      "Epoch 1483/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.5551 - val_loss: 694.4055\n",
      "Epoch 1484/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.6189 - val_loss: 691.7311\n",
      "Epoch 1485/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 423.1392 - val_loss: 687.7843\n",
      "Epoch 1486/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.0843 - val_loss: 700.6285\n",
      "Epoch 1487/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.5928 - val_loss: 665.8714\n",
      "Epoch 1488/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.9249 - val_loss: 700.0555\n",
      "Epoch 1489/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.0492 - val_loss: 717.4606\n",
      "Epoch 1490/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.0761 - val_loss: 686.6807\n",
      "Epoch 1491/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.2554 - val_loss: 673.3586\n",
      "Epoch 1492/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 367.9367 - val_loss: 697.7058\n",
      "Epoch 1493/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 386.0241 - val_loss: 703.3922\n",
      "Epoch 1494/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.7731 - val_loss: 703.4062\n",
      "Epoch 1495/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 381.7223 - val_loss: 704.9096\n",
      "Epoch 1496/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 469.9146 - val_loss: 706.8708\n",
      "Epoch 1497/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 414.0372 - val_loss: 730.3524\n",
      "Epoch 1498/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.0982 - val_loss: 716.5769\n",
      "Epoch 1499/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 424.2261 - val_loss: 679.2309\n",
      "Epoch 1500/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.7277 - val_loss: 722.9520\n",
      "Epoch 1501/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 464.3131 - val_loss: 689.0618\n",
      "Epoch 1502/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.7105 - val_loss: 698.2538\n",
      "Epoch 1503/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.8766 - val_loss: 702.2053\n",
      "Epoch 1504/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.8509 - val_loss: 686.1999\n",
      "Epoch 1505/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.9974 - val_loss: 679.7406\n",
      "Epoch 1506/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.6093 - val_loss: 715.9636\n",
      "Epoch 1507/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.6088 - val_loss: 727.5195\n",
      "Epoch 1508/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.2583 - val_loss: 724.1196\n",
      "Epoch 1509/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.1314 - val_loss: 668.8124\n",
      "Epoch 1510/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 378.5499 - val_loss: 707.5255\n",
      "Epoch 1511/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.1744 - val_loss: 663.7311\n",
      "Epoch 1512/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 368.7929 - val_loss: 697.5078\n",
      "Epoch 1513/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.6838 - val_loss: 690.1765\n",
      "Epoch 1514/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.8998 - val_loss: 669.6652\n",
      "Epoch 1515/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.4260 - val_loss: 713.9593\n",
      "Epoch 1516/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.4377 - val_loss: 711.4094\n",
      "Epoch 1517/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.1654 - val_loss: 708.5148\n",
      "Epoch 1518/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 388.6071 - val_loss: 697.9621\n",
      "Epoch 1519/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.7065 - val_loss: 677.9032\n",
      "Epoch 1520/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.4924 - val_loss: 683.8038\n",
      "Epoch 1521/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.0954 - val_loss: 701.9367\n",
      "Epoch 1522/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.7885 - val_loss: 694.7642\n",
      "Epoch 1523/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 463.9478 - val_loss: 663.2803\n",
      "Epoch 1524/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 462.3989 - val_loss: 711.9977\n",
      "Epoch 1525/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.5512 - val_loss: 732.7158\n",
      "Epoch 1526/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.1681 - val_loss: 713.6540\n",
      "Epoch 1527/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.0211 - val_loss: 703.4635\n",
      "Epoch 1528/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 334.7412 - val_loss: 715.9975\n",
      "Epoch 1529/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.1453 - val_loss: 721.3499\n",
      "Epoch 1530/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.0870 - val_loss: 721.2299\n",
      "Epoch 1531/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.4113 - val_loss: 700.8839\n",
      "Epoch 1532/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.2527 - val_loss: 699.9631\n",
      "Epoch 1533/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.6974 - val_loss: 709.2717\n",
      "Epoch 1534/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 337.7312 - val_loss: 694.5238\n",
      "Epoch 1535/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 408.3073 - val_loss: 668.8893\n",
      "Epoch 1536/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.1662 - val_loss: 702.5786\n",
      "Epoch 1537/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.6440 - val_loss: 691.4415\n",
      "Epoch 1538/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 422.7326 - val_loss: 697.4435\n",
      "Epoch 1539/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.2094 - val_loss: 687.5534\n",
      "Epoch 1540/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 396.2387 - val_loss: 693.9436\n",
      "Epoch 1541/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.2331 - val_loss: 723.4207\n",
      "Epoch 1542/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 338.0346 - val_loss: 711.0762\n",
      "Epoch 1543/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.8153 - val_loss: 709.5378\n",
      "Epoch 1544/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.3167 - val_loss: 706.7196\n",
      "Epoch 1545/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.7484 - val_loss: 673.9529\n",
      "Epoch 1546/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 388.1764 - val_loss: 704.9141\n",
      "Epoch 1547/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.6680 - val_loss: 708.5386\n",
      "Epoch 1548/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 463.3176 - val_loss: 701.0422\n",
      "Epoch 1549/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.6325 - val_loss: 722.0872\n",
      "Epoch 1550/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.7661 - val_loss: 718.7236\n",
      "Epoch 1551/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 347.7010 - val_loss: 726.1529\n",
      "Epoch 1552/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 360.5050 - val_loss: 717.8741\n",
      "Epoch 1553/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.8959 - val_loss: 695.9076\n",
      "Epoch 1554/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.5482 - val_loss: 699.4716\n",
      "Epoch 1555/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.9755 - val_loss: 731.6813\n",
      "Epoch 1556/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 386.0909 - val_loss: 701.9158\n",
      "Epoch 1557/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.1499 - val_loss: 678.0837\n",
      "Epoch 1558/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 445.5585 - val_loss: 697.7424\n",
      "Epoch 1559/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.7214 - val_loss: 709.7431\n",
      "Epoch 1560/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.5914 - val_loss: 703.8500\n",
      "Epoch 1561/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.3498 - val_loss: 708.5166\n",
      "Epoch 1562/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 428.3290 - val_loss: 734.4508\n",
      "Epoch 1563/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.7042 - val_loss: 704.4802\n",
      "Epoch 1564/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.9324 - val_loss: 717.2121\n",
      "Epoch 1565/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.8527 - val_loss: 667.7399\n",
      "Epoch 1566/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.9372 - val_loss: 712.7460\n",
      "Epoch 1567/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 347.6112 - val_loss: 692.8162\n",
      "Epoch 1568/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.2144 - val_loss: 712.6990\n",
      "Epoch 1569/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 414.7227 - val_loss: 692.3862\n",
      "Epoch 1570/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.4399 - val_loss: 711.7710\n",
      "Epoch 1571/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.8672 - val_loss: 666.6330\n",
      "Epoch 1572/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 350.0243 - val_loss: 713.2602\n",
      "Epoch 1573/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.4002 - val_loss: 719.6819\n",
      "Epoch 1574/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.9451 - val_loss: 723.2463\n",
      "Epoch 1575/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 436.5476 - val_loss: 674.3416\n",
      "Epoch 1576/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.2723 - val_loss: 723.2618\n",
      "Epoch 1577/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 352.9133 - val_loss: 697.0702\n",
      "Epoch 1578/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 340.2412 - val_loss: 732.8656\n",
      "Epoch 1579/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 401.1157 - val_loss: 689.5416\n",
      "Epoch 1580/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.7056 - val_loss: 694.4339\n",
      "Epoch 1581/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.7181 - val_loss: 707.3511\n",
      "Epoch 1582/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.7295 - val_loss: 704.0523\n",
      "Epoch 1583/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.4481 - val_loss: 721.0664\n",
      "Epoch 1584/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.8012 - val_loss: 703.6367\n",
      "Epoch 1585/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.8297 - val_loss: 717.8088\n",
      "Epoch 1586/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 398.4919 - val_loss: 702.4715\n",
      "Epoch 1587/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.0878 - val_loss: 723.5715\n",
      "Epoch 1588/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.8568 - val_loss: 728.9793\n",
      "Epoch 1589/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.3420 - val_loss: 718.0749\n",
      "Epoch 1590/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.5866 - val_loss: 718.4802\n",
      "Epoch 1591/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.1035 - val_loss: 728.9984\n",
      "Epoch 1592/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 337.3487 - val_loss: 698.1722\n",
      "Epoch 1593/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 338.4033 - val_loss: 704.4379\n",
      "Epoch 1594/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.5211 - val_loss: 714.8350\n",
      "Epoch 1595/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.3173 - val_loss: 694.6620\n",
      "Epoch 1596/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.1938 - val_loss: 725.5701\n",
      "Epoch 1597/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.5138 - val_loss: 698.9579\n",
      "Epoch 1598/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.7077 - val_loss: 673.6068\n",
      "Epoch 1599/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 411.4744 - val_loss: 679.7811\n",
      "Epoch 1600/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 415.3368 - val_loss: 655.3542\n",
      "Epoch 1601/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.2010 - val_loss: 727.3368\n",
      "Epoch 1602/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.9159 - val_loss: 713.5722\n",
      "Epoch 1603/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 403.4466 - val_loss: 709.2608\n",
      "Epoch 1604/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.2810 - val_loss: 720.2599\n",
      "Epoch 1605/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.7238 - val_loss: 720.2736\n",
      "Epoch 1606/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 304.2609 - val_loss: 703.7073\n",
      "Epoch 1607/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 326.8728 - val_loss: 705.1775\n",
      "Epoch 1608/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 426.5949 - val_loss: 697.7645\n",
      "Epoch 1609/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 366.8579 - val_loss: 725.7091\n",
      "Epoch 1610/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.9127 - val_loss: 686.3379\n",
      "Epoch 1611/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 399.1603 - val_loss: 708.1494\n",
      "Epoch 1612/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 370.8505 - val_loss: 701.7799\n",
      "Epoch 1613/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 431.0188 - val_loss: 705.4116\n",
      "Epoch 1614/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 384.9745 - val_loss: 707.7751\n",
      "Epoch 1615/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.5449 - val_loss: 700.4443\n",
      "Epoch 1616/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 419.1788 - val_loss: 655.4352\n",
      "Epoch 1617/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 440.6467 - val_loss: 710.4574\n",
      "Epoch 1618/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.9584 - val_loss: 700.5801\n",
      "Epoch 1619/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.7821 - val_loss: 726.4791\n",
      "Epoch 1620/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.2945 - val_loss: 677.3073\n",
      "Epoch 1621/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.7518 - val_loss: 734.7287\n",
      "Epoch 1622/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 342.8806 - val_loss: 707.8866\n",
      "Epoch 1623/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.1383 - val_loss: 712.3913\n",
      "Epoch 1624/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.5047 - val_loss: 694.3429\n",
      "Epoch 1625/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.9449 - val_loss: 693.6091\n",
      "Epoch 1626/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.0262 - val_loss: 699.6048\n",
      "Epoch 1627/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 381.4740 - val_loss: 730.9421\n",
      "Epoch 1628/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 429.0625 - val_loss: 696.7680\n",
      "Epoch 1629/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.9345 - val_loss: 683.3663\n",
      "Epoch 1630/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.9716 - val_loss: 692.4928\n",
      "Epoch 1631/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 317.0234 - val_loss: 693.0519\n",
      "Epoch 1632/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 428.4728 - val_loss: 702.4798\n",
      "Epoch 1633/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 368.4939 - val_loss: 691.7410\n",
      "Epoch 1634/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.3148 - val_loss: 695.1691\n",
      "Epoch 1635/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 347.3456 - val_loss: 717.7922\n",
      "Epoch 1636/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 325.6430 - val_loss: 703.4009\n",
      "Epoch 1637/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.9618 - val_loss: 709.4242\n",
      "Epoch 1638/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.2582 - val_loss: 717.3143\n",
      "Epoch 1639/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 394.1075 - val_loss: 731.4831\n",
      "Epoch 1640/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.3951 - val_loss: 714.1443\n",
      "Epoch 1641/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.6872 - val_loss: 714.4426\n",
      "Epoch 1642/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 420.5202 - val_loss: 716.9499\n",
      "Epoch 1643/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 407.4513 - val_loss: 683.0051\n",
      "Epoch 1644/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.4499 - val_loss: 708.9235\n",
      "Epoch 1645/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 413.7032 - val_loss: 714.0118\n",
      "Epoch 1646/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 406.6690 - val_loss: 716.2290\n",
      "Epoch 1647/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.0525 - val_loss: 714.2655\n",
      "Epoch 1648/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.3161 - val_loss: 709.7521\n",
      "Epoch 1649/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 427.0100 - val_loss: 694.2584\n",
      "Epoch 1650/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 337.7053 - val_loss: 686.0983\n",
      "Epoch 1651/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.2934 - val_loss: 718.4611\n",
      "Epoch 1652/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 354.9352 - val_loss: 705.0539\n",
      "Epoch 1653/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.2547 - val_loss: 674.1021\n",
      "Epoch 1654/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.5246 - val_loss: 679.3499\n",
      "Epoch 1655/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 444.1295 - val_loss: 682.2887\n",
      "Epoch 1656/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.9915 - val_loss: 715.3389\n",
      "Epoch 1657/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 333.3212 - val_loss: 734.2018\n",
      "Epoch 1658/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 388.9560 - val_loss: 680.8999\n",
      "Epoch 1659/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.6270 - val_loss: 705.3713\n",
      "Epoch 1660/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 365.1552 - val_loss: 703.4475\n",
      "Epoch 1661/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.4197 - val_loss: 711.5137\n",
      "Epoch 1662/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.3130 - val_loss: 695.2951\n",
      "Epoch 1663/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 396.3355 - val_loss: 715.9527\n",
      "Epoch 1664/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.5301 - val_loss: 721.6598\n",
      "Epoch 1665/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.6442 - val_loss: 735.9901\n",
      "Epoch 1666/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.7292 - val_loss: 701.3855\n",
      "Epoch 1667/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.5431 - val_loss: 714.2422\n",
      "Epoch 1668/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.8649 - val_loss: 735.6426\n",
      "Epoch 1669/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.5423 - val_loss: 684.3530\n",
      "Epoch 1670/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 350.2143 - val_loss: 705.8547\n",
      "Epoch 1671/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.8890 - val_loss: 712.9525\n",
      "Epoch 1672/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 477.6939 - val_loss: 676.2091\n",
      "Epoch 1673/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.4991 - val_loss: 705.7190\n",
      "Epoch 1674/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 436.2430 - val_loss: 710.5905\n",
      "Epoch 1675/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.1015 - val_loss: 696.6015\n",
      "Epoch 1676/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.4901 - val_loss: 703.3380\n",
      "Epoch 1677/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.2349 - val_loss: 723.1361\n",
      "Epoch 1678/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 357.4168 - val_loss: 696.5022\n",
      "Epoch 1679/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.0407 - val_loss: 711.1093\n",
      "Epoch 1680/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.4799 - val_loss: 743.0421\n",
      "Epoch 1681/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.6528 - val_loss: 718.3400\n",
      "Epoch 1682/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.9309 - val_loss: 696.1619\n",
      "Epoch 1683/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 391.0569 - val_loss: 715.8896\n",
      "Epoch 1684/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.9728 - val_loss: 709.5182\n",
      "Epoch 1685/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.3911 - val_loss: 716.5958\n",
      "Epoch 1686/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 319.2695 - val_loss: 716.2390\n",
      "Epoch 1687/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 378.3991 - val_loss: 719.0991\n",
      "Epoch 1688/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 353.7115 - val_loss: 718.5172\n",
      "Epoch 1689/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.6423 - val_loss: 683.4529\n",
      "Epoch 1690/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.2212 - val_loss: 715.9777\n",
      "Epoch 1691/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.4185 - val_loss: 678.6434\n",
      "Epoch 1692/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.5195 - val_loss: 717.2688\n",
      "Epoch 1693/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.7166 - val_loss: 712.4623\n",
      "Epoch 1694/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.9247 - val_loss: 695.0277\n",
      "Epoch 1695/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 414.5541 - val_loss: 702.5464\n",
      "Epoch 1696/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 339.8689 - val_loss: 694.7238\n",
      "Epoch 1697/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.6154 - val_loss: 728.3012\n",
      "Epoch 1698/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 340.7888 - val_loss: 722.1942\n",
      "Epoch 1699/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.8809 - val_loss: 704.3868\n",
      "Epoch 1700/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.7781 - val_loss: 698.0663\n",
      "Epoch 1701/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.1759 - val_loss: 719.8431\n",
      "Epoch 1702/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.7734 - val_loss: 709.3315\n",
      "Epoch 1703/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.8787 - val_loss: 724.0021\n",
      "Epoch 1704/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.7570 - val_loss: 723.3616\n",
      "Epoch 1705/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.9258 - val_loss: 740.9322\n",
      "Epoch 1706/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 353.1261 - val_loss: 719.7916\n",
      "Epoch 1707/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.1222 - val_loss: 682.2647\n",
      "Epoch 1708/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.0260 - val_loss: 687.4994\n",
      "Epoch 1709/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.9722 - val_loss: 690.6305\n",
      "Epoch 1710/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.7395 - val_loss: 696.1375\n",
      "Epoch 1711/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.4822 - val_loss: 728.9983\n",
      "Epoch 1712/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.0423 - val_loss: 738.7287\n",
      "Epoch 1713/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 386.4963 - val_loss: 703.4434\n",
      "Epoch 1714/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 407.8456 - val_loss: 717.1051\n",
      "Epoch 1715/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.1767 - val_loss: 715.3799\n",
      "Epoch 1716/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.8201 - val_loss: 737.9183\n",
      "Epoch 1717/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 343.6296 - val_loss: 729.0359\n",
      "Epoch 1718/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 336.6722 - val_loss: 707.1184\n",
      "Epoch 1719/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.5278 - val_loss: 711.1697\n",
      "Epoch 1720/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.9140 - val_loss: 695.4697\n",
      "Epoch 1721/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.1512 - val_loss: 694.2090\n",
      "Epoch 1722/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.4793 - val_loss: 685.6857\n",
      "Epoch 1723/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.1288 - val_loss: 676.6775\n",
      "Epoch 1724/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 416.1116 - val_loss: 698.4724\n",
      "Epoch 1725/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.9027 - val_loss: 716.7471\n",
      "Epoch 1726/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.0612 - val_loss: 730.2084\n",
      "Epoch 1727/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.2624 - val_loss: 699.3669\n",
      "Epoch 1728/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 421.6490 - val_loss: 716.2795\n",
      "Epoch 1729/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 383.4983 - val_loss: 722.6948\n",
      "Epoch 1730/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.3678 - val_loss: 737.6744\n",
      "Epoch 1731/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.6216 - val_loss: 724.8455\n",
      "Epoch 1732/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 388.6522 - val_loss: 691.4799\n",
      "Epoch 1733/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.7813 - val_loss: 716.2512\n",
      "Epoch 1734/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 326.2017 - val_loss: 715.6931\n",
      "Epoch 1735/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 460.1047 - val_loss: 700.8026\n",
      "Epoch 1736/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 352.1976 - val_loss: 706.0810\n",
      "Epoch 1737/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.1213 - val_loss: 705.6395\n",
      "Epoch 1738/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.3352 - val_loss: 722.3999\n",
      "Epoch 1739/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 342.5970 - val_loss: 716.4805\n",
      "Epoch 1740/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.1176 - val_loss: 697.0577\n",
      "Epoch 1741/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.2432 - val_loss: 739.7922\n",
      "Epoch 1742/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.2040 - val_loss: 729.2499\n",
      "Epoch 1743/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.0355 - val_loss: 702.7495\n",
      "Epoch 1744/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.2972 - val_loss: 714.3299\n",
      "Epoch 1745/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 398.7238 - val_loss: 714.1464\n",
      "Epoch 1746/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.8055 - val_loss: 728.5901\n",
      "Epoch 1747/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.9572 - val_loss: 698.7700\n",
      "Epoch 1748/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 403.1434 - val_loss: 717.3503\n",
      "Epoch 1749/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.9252 - val_loss: 732.9701\n",
      "Epoch 1750/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 402.8519 - val_loss: 682.1505\n",
      "Epoch 1751/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.0198 - val_loss: 726.5717\n",
      "Epoch 1752/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.9945 - val_loss: 701.3826\n",
      "Epoch 1753/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.9440 - val_loss: 731.5670\n",
      "Epoch 1754/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 412.0159 - val_loss: 689.9143\n",
      "Epoch 1755/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 332.6950 - val_loss: 710.8706\n",
      "Epoch 1756/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 364.6365 - val_loss: 710.8874\n",
      "Epoch 1757/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 313.5459 - val_loss: 705.7128\n",
      "Epoch 1758/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 364.1993 - val_loss: 714.6569\n",
      "Epoch 1759/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 415.7221 - val_loss: 708.7137\n",
      "Epoch 1760/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.8565 - val_loss: 716.1932\n",
      "Epoch 1761/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 379.0183 - val_loss: 690.1949\n",
      "Epoch 1762/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 381.3897 - val_loss: 705.5512\n",
      "Epoch 1763/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 347.1513 - val_loss: 711.8886\n",
      "Epoch 1764/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.8776 - val_loss: 712.4757\n",
      "Epoch 1765/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 330.0448 - val_loss: 706.6600\n",
      "Epoch 1766/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 427.5855 - val_loss: 700.2415\n",
      "Epoch 1767/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.0503 - val_loss: 727.6794\n",
      "Epoch 1768/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 318.7054 - val_loss: 668.6379\n",
      "Epoch 1769/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 399.9066 - val_loss: 720.4631\n",
      "Epoch 1770/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 433.8477 - val_loss: 689.8827\n",
      "Epoch 1771/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 386.2783 - val_loss: 702.3675\n",
      "Epoch 1772/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 342.8442 - val_loss: 715.5143\n",
      "Epoch 1773/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 367.2504 - val_loss: 696.9968\n",
      "Epoch 1774/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.3517 - val_loss: 704.4544\n",
      "Epoch 1775/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.7304 - val_loss: 718.0186\n",
      "Epoch 1776/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 321.0034 - val_loss: 697.3311\n",
      "Epoch 1777/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.1255 - val_loss: 709.4198\n",
      "Epoch 1778/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 392.1982 - val_loss: 717.3512\n",
      "Epoch 1779/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.2472 - val_loss: 675.7764\n",
      "Epoch 1780/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.2340 - val_loss: 727.4580\n",
      "Epoch 1781/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 352.1740 - val_loss: 687.2246\n",
      "Epoch 1782/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.3799 - val_loss: 679.4097\n",
      "Epoch 1783/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 343.3983 - val_loss: 729.1880\n",
      "Epoch 1784/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.3282 - val_loss: 710.5929\n",
      "Epoch 1785/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 407.3028 - val_loss: 734.5750\n",
      "Epoch 1786/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.7463 - val_loss: 722.1725\n",
      "Epoch 1787/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.0787 - val_loss: 711.5571\n",
      "Epoch 1788/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.4384 - val_loss: 723.2783\n",
      "Epoch 1789/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 343.9484 - val_loss: 685.5243\n",
      "Epoch 1790/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.4112 - val_loss: 723.6896\n",
      "Epoch 1791/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.9775 - val_loss: 717.4801\n",
      "Epoch 1792/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.2520 - val_loss: 724.4639\n",
      "Epoch 1793/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 335.3120 - val_loss: 726.3325\n",
      "Epoch 1794/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 330.2444 - val_loss: 744.0249\n",
      "Epoch 1795/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.8170 - val_loss: 720.6095\n",
      "Epoch 1796/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 397.8839 - val_loss: 723.6274\n",
      "Epoch 1797/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 353.3766 - val_loss: 695.3020\n",
      "Epoch 1798/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.9055 - val_loss: 694.9870\n",
      "Epoch 1799/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.6687 - val_loss: 701.0389\n",
      "Epoch 1800/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.8321 - val_loss: 695.6382\n",
      "Epoch 1801/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.3076 - val_loss: 727.3976\n",
      "Epoch 1802/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 354.2357 - val_loss: 729.5350\n",
      "Epoch 1803/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 333.6140 - val_loss: 702.4148\n",
      "Epoch 1804/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.7487 - val_loss: 734.5935\n",
      "Epoch 1805/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 395.3528 - val_loss: 721.7762\n",
      "Epoch 1806/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.3835 - val_loss: 726.2472\n",
      "Epoch 1807/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 395.8863 - val_loss: 718.2757\n",
      "Epoch 1808/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 346.3964 - val_loss: 686.7738\n",
      "Epoch 1809/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.4841 - val_loss: 715.2202\n",
      "Epoch 1810/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.0730 - val_loss: 709.9254\n",
      "Epoch 1811/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.3055 - val_loss: 700.9053\n",
      "Epoch 1812/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.8743 - val_loss: 731.1473\n",
      "Epoch 1813/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 357.0041 - val_loss: 725.4230\n",
      "Epoch 1814/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.6343 - val_loss: 732.8015\n",
      "Epoch 1815/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 335.8531 - val_loss: 750.2094\n",
      "Epoch 1816/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 393.4189 - val_loss: 721.9865\n",
      "Epoch 1817/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.3055 - val_loss: 742.6338\n",
      "Epoch 1818/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.9721 - val_loss: 702.9240\n",
      "Epoch 1819/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 363.0382 - val_loss: 705.0033\n",
      "Epoch 1820/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.9926 - val_loss: 715.1410\n",
      "Epoch 1821/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.1415 - val_loss: 694.1347\n",
      "Epoch 1822/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.5508 - val_loss: 717.2515\n",
      "Epoch 1823/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 403.3968 - val_loss: 734.2354\n",
      "Epoch 1824/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.7658 - val_loss: 701.3752\n",
      "Epoch 1825/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.0849 - val_loss: 719.3944\n",
      "Epoch 1826/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 336.0241 - val_loss: 705.9991\n",
      "Epoch 1827/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.8288 - val_loss: 692.2789\n",
      "Epoch 1828/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 391.1810 - val_loss: 713.9222\n",
      "Epoch 1829/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.6776 - val_loss: 700.3551\n",
      "Epoch 1830/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 340.3730 - val_loss: 684.1608\n",
      "Epoch 1831/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 364.3234 - val_loss: 693.4780\n",
      "Epoch 1832/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 418.5915 - val_loss: 708.5901\n",
      "Epoch 1833/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 371.6701 - val_loss: 721.4350\n",
      "Epoch 1834/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 346.1662 - val_loss: 692.7300\n",
      "Epoch 1835/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.3941 - val_loss: 714.0720\n",
      "Epoch 1836/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.8175 - val_loss: 702.5428\n",
      "Epoch 1837/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.3848 - val_loss: 719.8338\n",
      "Epoch 1838/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 294.3854 - val_loss: 696.6949\n",
      "Epoch 1839/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 393.3338 - val_loss: 724.4729\n",
      "Epoch 1840/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 334.9359 - val_loss: 708.6045\n",
      "Epoch 1841/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.4858 - val_loss: 693.3301\n",
      "Epoch 1842/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.1230 - val_loss: 727.5148\n",
      "Epoch 1843/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 340.1889 - val_loss: 724.9173\n",
      "Epoch 1844/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.3375 - val_loss: 720.4525\n",
      "Epoch 1845/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.7235 - val_loss: 731.9176\n",
      "Epoch 1846/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.3841 - val_loss: 713.3202\n",
      "Epoch 1847/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 317.0488 - val_loss: 720.3420\n",
      "Epoch 1848/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 363.0748 - val_loss: 737.4128\n",
      "Epoch 1849/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.7936 - val_loss: 698.5121\n",
      "Epoch 1850/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 403.5214 - val_loss: 749.6061\n",
      "Epoch 1851/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.6617 - val_loss: 728.7858\n",
      "Epoch 1852/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.0496 - val_loss: 749.2333\n",
      "Epoch 1853/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.7539 - val_loss: 714.8183\n",
      "Epoch 1854/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 293.9481 - val_loss: 713.0301\n",
      "Epoch 1855/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 337.5874 - val_loss: 713.0627\n",
      "Epoch 1856/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.0804 - val_loss: 716.2856\n",
      "Epoch 1857/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.6542 - val_loss: 709.2978\n",
      "Epoch 1858/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 339.2325 - val_loss: 705.8125\n",
      "Epoch 1859/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 352.1020 - val_loss: 720.1398\n",
      "Epoch 1860/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.8780 - val_loss: 723.9058\n",
      "Epoch 1861/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 314.4828 - val_loss: 742.7092\n",
      "Epoch 1862/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.5033 - val_loss: 742.1705\n",
      "Epoch 1863/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 408.9531 - val_loss: 719.7327\n",
      "Epoch 1864/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 410.6599 - val_loss: 728.9783\n",
      "Epoch 1865/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 333.5238 - val_loss: 706.8073\n",
      "Epoch 1866/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 348.6450 - val_loss: 735.1269\n",
      "Epoch 1867/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 354.2331 - val_loss: 728.3890\n",
      "Epoch 1868/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.9942 - val_loss: 753.4775\n",
      "Epoch 1869/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 327.6478 - val_loss: 726.5691\n",
      "Epoch 1870/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.7253 - val_loss: 720.4892\n",
      "Epoch 1871/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 365.0739 - val_loss: 715.8623\n",
      "Epoch 1872/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.5559 - val_loss: 708.6266\n",
      "Epoch 1873/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.6080 - val_loss: 716.8835\n",
      "Epoch 1874/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.9347 - val_loss: 698.3094\n",
      "Epoch 1875/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 352.1593 - val_loss: 722.8200\n",
      "Epoch 1876/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 335.3377 - val_loss: 721.2617\n",
      "Epoch 1877/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.6932 - val_loss: 711.8879\n",
      "Epoch 1878/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 381.5731 - val_loss: 722.2086\n",
      "Epoch 1879/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 327.3849 - val_loss: 739.8111\n",
      "Epoch 1880/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 409.9009 - val_loss: 739.2307\n",
      "Epoch 1881/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 389.5385 - val_loss: 721.7723\n",
      "Epoch 1882/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.4992 - val_loss: 702.3973\n",
      "Epoch 1883/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 367.3776 - val_loss: 726.0586\n",
      "Epoch 1884/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 343.5236 - val_loss: 729.0352\n",
      "Epoch 1885/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 337.2179 - val_loss: 730.7001\n",
      "Epoch 1886/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.0723 - val_loss: 724.7486\n",
      "Epoch 1887/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.0050 - val_loss: 711.7395\n",
      "Epoch 1888/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.1306 - val_loss: 740.5897\n",
      "Epoch 1889/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.7695 - val_loss: 707.2215\n",
      "Epoch 1890/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 321.0666 - val_loss: 702.2135\n",
      "Epoch 1891/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 330.6777 - val_loss: 728.6498\n",
      "Epoch 1892/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 357.8058 - val_loss: 719.2942\n",
      "Epoch 1893/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 381.7640 - val_loss: 688.7394\n",
      "Epoch 1894/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.8736 - val_loss: 704.1441\n",
      "Epoch 1895/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.3511 - val_loss: 736.8440\n",
      "Epoch 1896/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.5818 - val_loss: 734.3619\n",
      "Epoch 1897/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 387.4825 - val_loss: 728.2328\n",
      "Epoch 1898/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.4863 - val_loss: 725.2256\n",
      "Epoch 1899/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.6546 - val_loss: 720.5577\n",
      "Epoch 1900/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 314.5407 - val_loss: 736.0644\n",
      "Epoch 1901/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.0168 - val_loss: 737.0793\n",
      "Epoch 1902/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.7408 - val_loss: 712.1527\n",
      "Epoch 1903/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.0670 - val_loss: 674.3967\n",
      "Epoch 1904/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 343.9870 - val_loss: 694.2145\n",
      "Epoch 1905/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 328.4559 - val_loss: 699.3302\n",
      "Epoch 1906/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 397.5837 - val_loss: 733.0144\n",
      "Epoch 1907/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 353.0100 - val_loss: 715.2666\n",
      "Epoch 1908/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.0130 - val_loss: 735.0586\n",
      "Epoch 1909/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 349.3009 - val_loss: 687.6489\n",
      "Epoch 1910/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 292.2182 - val_loss: 703.7848\n",
      "Epoch 1911/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 322.0457 - val_loss: 709.2025\n",
      "Epoch 1912/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 429.1851 - val_loss: 717.8039\n",
      "Epoch 1913/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 404.8918 - val_loss: 744.2799\n",
      "Epoch 1914/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 368.1041 - val_loss: 722.5812\n",
      "Epoch 1915/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 356.0577 - val_loss: 731.0696\n",
      "Epoch 1916/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.3416 - val_loss: 748.1440\n",
      "Epoch 1917/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.4740 - val_loss: 746.0415\n",
      "Epoch 1918/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 405.7216 - val_loss: 689.5438\n",
      "Epoch 1919/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 328.9762 - val_loss: 728.3312\n",
      "Epoch 1920/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 354.0646 - val_loss: 748.2859\n",
      "Epoch 1921/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.4892 - val_loss: 714.7488\n",
      "Epoch 1922/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.0321 - val_loss: 717.7955\n",
      "Epoch 1923/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.6274 - val_loss: 705.0010\n",
      "Epoch 1924/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.9216 - val_loss: 722.4901\n",
      "Epoch 1925/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 357.4355 - val_loss: 742.8243\n",
      "Epoch 1926/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.2733 - val_loss: 725.7545\n",
      "Epoch 1927/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 308.8290 - val_loss: 731.7246\n",
      "Epoch 1928/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 370.3555 - val_loss: 712.3673\n",
      "Epoch 1929/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 376.1614 - val_loss: 695.8720\n",
      "Epoch 1930/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 392.0511 - val_loss: 728.0763\n",
      "Epoch 1931/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 320.6891 - val_loss: 664.8406\n",
      "Epoch 1932/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 361.2026 - val_loss: 716.0952\n",
      "Epoch 1933/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 342.8749 - val_loss: 663.9513\n",
      "Epoch 1934/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.9069 - val_loss: 729.0145\n",
      "Epoch 1935/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 351.3775 - val_loss: 715.2702\n",
      "Epoch 1936/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.7930 - val_loss: 738.2648\n",
      "Epoch 1937/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.4557 - val_loss: 725.2636\n",
      "Epoch 1938/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 378.2090 - val_loss: 723.6169\n",
      "Epoch 1939/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.3943 - val_loss: 732.5276\n",
      "Epoch 1940/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 328.7565 - val_loss: 725.9528\n",
      "Epoch 1941/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 341.7714 - val_loss: 719.1534\n",
      "Epoch 1942/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.7536 - val_loss: 746.0982\n",
      "Epoch 1943/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.0220 - val_loss: 696.1202\n",
      "Epoch 1944/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 377.0612 - val_loss: 734.5267\n",
      "Epoch 1945/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.7323 - val_loss: 741.1552\n",
      "Epoch 1946/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 382.9733 - val_loss: 719.3043\n",
      "Epoch 1947/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 398.8078 - val_loss: 697.3487\n",
      "Epoch 1948/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.0164 - val_loss: 745.7132\n",
      "Epoch 1949/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.2354 - val_loss: 720.3560\n",
      "Epoch 1950/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 360.3961 - val_loss: 741.7099\n",
      "Epoch 1951/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 346.3370 - val_loss: 731.3133\n",
      "Epoch 1952/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.1735 - val_loss: 739.4641\n",
      "Epoch 1953/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 397.9256 - val_loss: 720.2903\n",
      "Epoch 1954/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 334.3314 - val_loss: 733.4678\n",
      "Epoch 1955/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 326.2465 - val_loss: 727.8582\n",
      "Epoch 1956/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.7831 - val_loss: 731.9518\n",
      "Epoch 1957/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 390.1634 - val_loss: 711.3590\n",
      "Epoch 1958/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 400.2007 - val_loss: 706.1086\n",
      "Epoch 1959/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 380.5000 - val_loss: 738.3130\n",
      "Epoch 1960/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 333.7977 - val_loss: 710.9991\n",
      "Epoch 1961/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 345.8617 - val_loss: 740.2043\n",
      "Epoch 1962/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 390.6226 - val_loss: 738.8249\n",
      "Epoch 1963/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 311.4579 - val_loss: 738.4394\n",
      "Epoch 1964/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 325.3512 - val_loss: 703.1681\n",
      "Epoch 1965/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.2663 - val_loss: 749.2601\n",
      "Epoch 1966/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.5275 - val_loss: 730.3733\n",
      "Epoch 1967/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.4939 - val_loss: 724.4097\n",
      "Epoch 1968/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 325.2057 - val_loss: 723.6875\n",
      "Epoch 1969/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 344.9081 - val_loss: 714.7504\n",
      "Epoch 1970/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 321.7997 - val_loss: 728.4715\n",
      "Epoch 1971/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 314.1073 - val_loss: 748.9007\n",
      "Epoch 1972/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.5746 - val_loss: 696.9755\n",
      "Epoch 1973/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 417.8804 - val_loss: 709.5809\n",
      "Epoch 1974/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 335.6122 - val_loss: 717.4630\n",
      "Epoch 1975/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.3607 - val_loss: 751.4446\n",
      "Epoch 1976/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 347.9952 - val_loss: 711.8856\n",
      "Epoch 1977/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.4573 - val_loss: 726.2523\n",
      "Epoch 1978/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 398.4310 - val_loss: 723.6406\n",
      "Epoch 1979/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 384.9925 - val_loss: 730.5002\n",
      "Epoch 1980/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 305.3766 - val_loss: 716.5622\n",
      "Epoch 1981/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.3274 - val_loss: 695.1795\n",
      "Epoch 1982/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 356.5339 - val_loss: 732.2386\n",
      "Epoch 1983/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 328.0455 - val_loss: 746.7330\n",
      "Epoch 1984/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 357.3724 - val_loss: 735.2937\n",
      "Epoch 1985/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 332.0555 - val_loss: 708.2491\n",
      "Epoch 1986/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 383.8970 - val_loss: 734.0263\n",
      "Epoch 1987/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 339.4130 - val_loss: 695.7876\n",
      "Epoch 1988/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 394.7023 - val_loss: 739.3010\n",
      "Epoch 1989/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 306.2375 - val_loss: 716.2977\n",
      "Epoch 1990/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 375.3518 - val_loss: 724.1225\n",
      "Epoch 1991/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 333.0521 - val_loss: 711.3828\n",
      "Epoch 1992/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 329.6766 - val_loss: 715.8348\n",
      "Epoch 1993/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 366.3095 - val_loss: 704.7808\n",
      "Epoch 1994/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.8008 - val_loss: 714.4815\n",
      "Epoch 1995/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 369.7674 - val_loss: 747.1713\n",
      "Epoch 1996/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 385.9553 - val_loss: 726.0700\n",
      "Epoch 1997/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 331.7130 - val_loss: 703.0634\n",
      "Epoch 1998/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 359.4348 - val_loss: 725.2732\n",
      "Epoch 1999/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.7994 - val_loss: 735.4062\n",
      "Epoch 2000/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 347.4979 - val_loss: 720.2610\n",
      "Epoch 2001/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 358.3093 - val_loss: 740.4062\n",
      "Epoch 2002/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 372.7518 - val_loss: 750.6103\n",
      "Epoch 2003/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 321.3134 - val_loss: 745.7041\n",
      "Epoch 2004/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 362.1283 - val_loss: 750.2368\n",
      "Epoch 2005/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 342.2816 - val_loss: 730.4014\n",
      "Epoch 2006/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 355.9544 - val_loss: 732.2621\n",
      "Epoch 2007/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 373.5369 - val_loss: 710.2411\n",
      "Epoch 2008/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 364.3982 - val_loss: 718.9649\n",
      "Epoch 2009/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 320.1837 - val_loss: 729.2578\n",
      "Epoch 2010/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 335.2832 - val_loss: 721.0834\n",
      "Epoch 2011/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 430.4746 - val_loss: 711.4036\n",
      "Epoch 2012/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 374.8928 - val_loss: 701.8178\n",
      "Epoch 2013/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 299.8703 - val_loss: 756.2443\n",
      "Epoch 2014/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 319.4695 - val_loss: 705.5257\n",
      "Epoch 2015/5000\n",
      "10/10 [==============================] - 14s 1s/step - loss: 398.1984 - val_loss: 716.5791\n",
      "Epoch 2016/5000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 333.7741 - val_loss: 707.0557\n",
      "Epoch 2017/5000\n",
      " 9/10 [==========================>...] - ETA: 1s - loss: 380.0353"
     ]
    }
   ],
   "source": [
    "train_generator = myGenerator(list_IDs=RAD_id_list[:1600], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=10)\n",
    "valid_generator = myGenerator(list_IDs=RAD_id_list[1800:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=10)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=30, epochs=5000, validation_data=valid_generator, validation_steps=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.on_epoch_end()\n",
    "valid_generator.on_epoch_end()\n",
    "for data in [train_generator, valid_generator][0]:\n",
    "    x, y_ = data\n",
    "    break\n",
    "y = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓↓↓下面的是真实值，上面的是上一张↑↑↑\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓↓↓下面的是模型的输出，上面的是真实值↑↑↑\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是真实值，上面的是上一张↑↑↑')\n",
    "plt.imshow(y_[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是模型的输出，上面的是真实值↑↑↑')\n",
    "plt.imshow(y[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-6cd13d6a221b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_id = RAD_id_list[3]\n",
    "x_matrix = np.empty((nt, image_size, image_size, 1))\n",
    "for i in range(nt):\n",
    "    x_matrix[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, i)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size, 1)) / SCALAR\n",
    "x_matrix = x_matrix.reshape((1, nt, image_size, image_size, 1))\n",
    "y_matrix = np.empty((nt, image_size, image_size, 1))\n",
    "for i in range(nt):\n",
    "    y_matrix[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, i + 10)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size, 1)) / SCALAR\n",
    "y_matrix = y_matrix.reshape((1, nt, image_size, image_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.reshape((image_size, image_size)) * SCALAR, cmap=cm.gist_ncar_r)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是模型的%d输出，上面的是%d真实值↑↑↑' % (1, 1))\n",
    "plt.imshow(b.reshape((image_size, image_size)) * SCALAR, cmap=cm.gist_ncar_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = nt\n",
    "inputs = Input(shape=tuple(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_matrix.shape)\n",
    "print(y_matrix.shape)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_input_shape_at(0))\n",
    "print(model.get_output_shape_at(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%quickref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
