{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Load or Download MNIST > data/mnist\n",
      "[TL] Downloading train-images-idx3-ubyte.gz...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1211 of 1211) |####################| Elapsed Time: 0:00:02 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "[TL] data/mnist/train-images-idx3-ubyte.gz\n",
      "[TL] Downloading train-labels-idx1-ubyte.gz...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4 of 4) |##########################| Elapsed Time: 0:00:01 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "[TL] Downloading t10k-images-idx3-ubyte.gz...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (202 of 202) |######################| Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "[TL] data/mnist/t10k-images-idx3-ubyte.gz\n",
      "[TL] Downloading t10k-labels-idx1-ubyte.gz...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1 of 1) |##########################| Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "[TL] InputLayer  input_layer: (?, 784)\n",
      "[TL] DropoutLayer drop1: keep: 0.800000 is_fix: False\n",
      "[TL] DenseLayer  relu1: 800 relu\n",
      "[TL] DropoutLayer drop2: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  relu2: 800 relu\n",
      "[TL] DropoutLayer drop3: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  output_layer: 10 No Activation\n",
      "[TL] WARNING: From <ipython-input-2-4fbef2f4505d>:39: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "[TL]   param   0: relu1/W:0            (784, 800)         float32_ref (mean: 7.393644409603439e-06, median: 4.336699203122407e-05, std: 0.08797957748174667)   \n",
      "[TL]   param   1: relu1/b:0            (800,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (800, 800)         float32_ref (mean: -6.774395296815783e-05, median: -2.737323120527435e-05, std: 0.08792266249656677)   \n",
      "[TL]   param   3: relu2/b:0            (800,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: output_layer/W:0     (800, 10)          float32_ref (mean: 0.001085353665985167, median: 0.00047939957585185766, std: 0.08772309869527817)   \n",
      "[TL]   param   5: output_layer/b:0     (10,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 1276810\n",
      "[TL]   layer   0: x:0                  (?, 784)           float32\n",
      "[TL]   layer   1: drop1/mul:0          (?, 784)           float32\n",
      "[TL]   layer   2: relu1/Relu:0         (?, 800)           float32\n",
      "[TL]   layer   3: drop2/mul:0          (?, 800)           float32\n",
      "[TL]   layer   4: relu2/Relu:0         (?, 800)           float32\n",
      "[TL]   layer   5: drop3/mul:0          (?, 800)           float32\n",
      "[TL]   layer   6: output_layer/bias_add:0 (?, 10)            float32\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 2.431199s\n",
      "[TL]    val loss: 0.603053\n",
      "[TL]    val acc: 0.809900\n",
      "[TL] Epoch 5 of 500 took 2.340481s\n",
      "[TL]    val loss: 0.285048\n",
      "[TL]    val acc: 0.914100\n",
      "[TL] Epoch 10 of 500 took 2.333789s\n",
      "[TL]    val loss: 0.216515\n",
      "[TL]    val acc: 0.940900\n",
      "[TL] Epoch 15 of 500 took 2.339107s\n",
      "[TL]    val loss: 0.184898\n",
      "[TL]    val acc: 0.951900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4fbef2f4505d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_,\n\u001b[1;32m     47\u001b[0m             \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             X_val=X_val, y_val=y_val, eval_train=False)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# 评估模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorlayer/utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(sess, network, train_op, cost, X_train, y_train, x, y_, acc, batch_size, n_epoch, print_freq, X_val, y_val, eval_train, tensorboard, tensorboard_epoch_freq, tensorboard_weight_histograms, tensorboard_graph_vis)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train_a\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_drop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# enable noise layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mloss_ep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mn_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 准备数据\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = \\\n",
    "                                tl.files.load_mnist_dataset(shape=(-1,784))\n",
    "\n",
    "# 定义 placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[None, ], name='y_')\n",
    "\n",
    "# 定义模型\n",
    "network = tl.layers.InputLayer(x, name='input_layer')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, n_units=800,\n",
    "                                act = tf.nn.relu, name='relu1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, n_units=800,\n",
    "                                act = tf.nn.relu, name='relu2')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "network = tl.layers.DenseLayer(network, n_units=10,\n",
    "                                act = tf.identity,\n",
    "                                name='output_layer')\n",
    "# 定义损失函数和衡量指标\n",
    "# tl.cost.cross_entropy 在内部使用 tf.nn.sparse_softmax_cross_entropy_with_logits() 实现 softmax\n",
    "y = network.outputs\n",
    "cost = tl.cost.cross_entropy(y, y_, name = 'cost')\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "y_op = tf.argmax(tf.nn.softmax(y), 1)\n",
    "\n",
    "# 定义 optimizer\n",
    "train_params = network.all_params\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.9, beta2=0.999,\n",
    "                            epsilon=1e-08, use_locking=False).minimize(cost, var_list=train_params)\n",
    "\n",
    "# 初始化 session 中的所有参数\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "\n",
    "# 列出模型信息\n",
    "network.print_params()\n",
    "network.print_layers()\n",
    "\n",
    "# 训练模型\n",
    "tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_,\n",
    "            acc=acc, batch_size=500, n_epoch=500, print_freq=5,\n",
    "            X_val=X_val, y_val=y_val, eval_train=False)\n",
    "\n",
    "# 评估模型\n",
    "tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)\n",
    "\n",
    "# 把模型保存成 .npz 文件\n",
    "tl.files.save_npz(network.all_params , name='model.npz')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Load or Download MNIST > data/mnist\n",
      "[TL] data/mnist/train-images-idx3-ubyte.gz\n",
      "[TL] data/mnist/t10k-images-idx3-ubyte.gz\n",
      "[TL] InputLayer  input_layer: (?, 784)\n",
      "[TL] DropoutLayer drop1: keep: 0.800000 is_fix: False\n",
      "[TL] DenseLayer  relu1: 800 relu\n",
      "[TL] DropoutLayer drop2: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  relu2: 800 relu\n",
      "[TL] DropoutLayer drop3: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  output_layer: 10 No Activation\n",
      "[TL] WARNING: From <ipython-input-3-1e2010b60ca2>:39: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "[TL]   param   0: relu1/W:0            (784, 800)         float32_ref (mean: 0.00010131789167644456, median: 9.449438221054152e-05, std: 0.08800118416547775)   \n",
      "[TL]   param   1: relu1/b:0            (800,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   2: relu2/W:0            (800, 800)         float32_ref (mean: -3.460704829194583e-05, median: 8.992430230136961e-05, std: 0.08798909187316895)   \n",
      "[TL]   param   3: relu2/b:0            (800,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   param   4: output_layer/W:0     (800, 10)          float32_ref (mean: 0.0009359878022223711, median: 0.0014417563797906041, std: 0.08697746694087982)   \n",
      "[TL]   param   5: output_layer/b:0     (10,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
      "[TL]   num of params: 1276810\n",
      "[TL]   layer   0: x:0                  (?, 784)           float32\n",
      "[TL]   layer   1: drop1/mul:0          (?, 784)           float32\n",
      "[TL]   layer   2: relu1/Relu:0         (?, 800)           float32\n",
      "[TL]   layer   3: drop2/mul:0          (?, 800)           float32\n",
      "[TL]   layer   4: relu2/Relu:0         (?, 800)           float32\n",
      "[TL]   layer   5: drop3/mul:0          (?, 800)           float32\n",
      "[TL]   layer   6: output_layer/bias_add:0 (?, 10)            float32\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 500 took 0.536116s\n",
      "[TL]    val loss: 0.506810\n",
      "[TL]    val acc: 0.836500\n",
      "[TL] Epoch 5 of 500 took 0.389230s\n",
      "[TL]    val loss: 0.276236\n",
      "[TL]    val acc: 0.920600\n",
      "[TL] Epoch 10 of 500 took 0.396046s\n",
      "[TL]    val loss: 0.216794\n",
      "[TL]    val acc: 0.939600\n",
      "[TL] Epoch 15 of 500 took 0.388830s\n",
      "[TL]    val loss: 0.183348\n",
      "[TL]    val acc: 0.948100\n",
      "[TL] Epoch 20 of 500 took 0.399944s\n",
      "[TL]    val loss: 0.160117\n",
      "[TL]    val acc: 0.955700\n",
      "[TL] Epoch 25 of 500 took 0.399657s\n",
      "[TL]    val loss: 0.142705\n",
      "[TL]    val acc: 0.961100\n",
      "[TL] Epoch 30 of 500 took 0.393090s\n",
      "[TL]    val loss: 0.130537\n",
      "[TL]    val acc: 0.964600\n",
      "[TL] Epoch 35 of 500 took 0.386311s\n",
      "[TL]    val loss: 0.119189\n",
      "[TL]    val acc: 0.966200\n",
      "[TL] Epoch 40 of 500 took 0.396079s\n",
      "[TL]    val loss: 0.110398\n",
      "[TL]    val acc: 0.969500\n",
      "[TL] Epoch 45 of 500 took 0.391614s\n",
      "[TL]    val loss: 0.102804\n",
      "[TL]    val acc: 0.971800\n",
      "[TL] Epoch 50 of 500 took 0.389846s\n",
      "[TL]    val loss: 0.097608\n",
      "[TL]    val acc: 0.972100\n",
      "[TL] Epoch 55 of 500 took 0.386802s\n",
      "[TL]    val loss: 0.091516\n",
      "[TL]    val acc: 0.973200\n",
      "[TL] Epoch 60 of 500 took 0.392372s\n",
      "[TL]    val loss: 0.088116\n",
      "[TL]    val acc: 0.974800\n",
      "[TL] Epoch 65 of 500 took 0.393632s\n",
      "[TL]    val loss: 0.084066\n",
      "[TL]    val acc: 0.975400\n",
      "[TL] Epoch 70 of 500 took 0.390727s\n",
      "[TL]    val loss: 0.080457\n",
      "[TL]    val acc: 0.976600\n",
      "[TL] Epoch 75 of 500 took 0.396242s\n",
      "[TL]    val loss: 0.077868\n",
      "[TL]    val acc: 0.977300\n",
      "[TL] Epoch 80 of 500 took 0.387246s\n",
      "[TL]    val loss: 0.075575\n",
      "[TL]    val acc: 0.977700\n",
      "[TL] Epoch 85 of 500 took 0.391587s\n",
      "[TL]    val loss: 0.074088\n",
      "[TL]    val acc: 0.978500\n",
      "[TL] Epoch 90 of 500 took 0.381978s\n",
      "[TL]    val loss: 0.070794\n",
      "[TL]    val acc: 0.979200\n",
      "[TL] Epoch 95 of 500 took 0.393882s\n",
      "[TL]    val loss: 0.068699\n",
      "[TL]    val acc: 0.979300\n",
      "[TL] Epoch 100 of 500 took 0.389292s\n",
      "[TL]    val loss: 0.067723\n",
      "[TL]    val acc: 0.978900\n",
      "[TL] Epoch 105 of 500 took 0.396816s\n",
      "[TL]    val loss: 0.066106\n",
      "[TL]    val acc: 0.979900\n",
      "[TL] Epoch 110 of 500 took 0.388631s\n",
      "[TL]    val loss: 0.064514\n",
      "[TL]    val acc: 0.980700\n",
      "[TL] Epoch 115 of 500 took 0.399698s\n",
      "[TL]    val loss: 0.063740\n",
      "[TL]    val acc: 0.981100\n",
      "[TL] Epoch 120 of 500 took 0.388920s\n",
      "[TL]    val loss: 0.061574\n",
      "[TL]    val acc: 0.982000\n",
      "[TL] Epoch 125 of 500 took 0.390055s\n",
      "[TL]    val loss: 0.062017\n",
      "[TL]    val acc: 0.982400\n",
      "[TL] Epoch 130 of 500 took 0.387613s\n",
      "[TL]    val loss: 0.061214\n",
      "[TL]    val acc: 0.982500\n",
      "[TL] Epoch 135 of 500 took 0.393147s\n",
      "[TL]    val loss: 0.059993\n",
      "[TL]    val acc: 0.983600\n",
      "[TL] Epoch 140 of 500 took 0.393164s\n",
      "[TL]    val loss: 0.059276\n",
      "[TL]    val acc: 0.983700\n",
      "[TL] Epoch 145 of 500 took 0.390060s\n",
      "[TL]    val loss: 0.058765\n",
      "[TL]    val acc: 0.983600\n",
      "[TL] Epoch 150 of 500 took 0.389700s\n",
      "[TL]    val loss: 0.057702\n",
      "[TL]    val acc: 0.984200\n",
      "[TL] Epoch 155 of 500 took 0.415538s\n",
      "[TL]    val loss: 0.057826\n",
      "[TL]    val acc: 0.983300\n",
      "[TL] Epoch 160 of 500 took 0.417522s\n",
      "[TL]    val loss: 0.057840\n",
      "[TL]    val acc: 0.983100\n",
      "[TL] Epoch 165 of 500 took 0.396466s\n",
      "[TL]    val loss: 0.057457\n",
      "[TL]    val acc: 0.983000\n",
      "[TL] Epoch 170 of 500 took 0.396834s\n",
      "[TL]    val loss: 0.056367\n",
      "[TL]    val acc: 0.983300\n",
      "[TL] Epoch 175 of 500 took 0.394123s\n",
      "[TL]    val loss: 0.056326\n",
      "[TL]    val acc: 0.982500\n",
      "[TL] Epoch 180 of 500 took 0.394338s\n",
      "[TL]    val loss: 0.054836\n",
      "[TL]    val acc: 0.983700\n",
      "[TL] Epoch 185 of 500 took 0.393330s\n",
      "[TL]    val loss: 0.055078\n",
      "[TL]    val acc: 0.984500\n",
      "[TL] Epoch 190 of 500 took 0.393288s\n",
      "[TL]    val loss: 0.055019\n",
      "[TL]    val acc: 0.983900\n",
      "[TL] Epoch 195 of 500 took 0.399077s\n",
      "[TL]    val loss: 0.054300\n",
      "[TL]    val acc: 0.984300\n",
      "[TL] Epoch 200 of 500 took 0.396155s\n",
      "[TL]    val loss: 0.055062\n",
      "[TL]    val acc: 0.985100\n",
      "[TL] Epoch 205 of 500 took 0.392300s\n",
      "[TL]    val loss: 0.054175\n",
      "[TL]    val acc: 0.984600\n",
      "[TL] Epoch 210 of 500 took 0.397395s\n",
      "[TL]    val loss: 0.054208\n",
      "[TL]    val acc: 0.984600\n",
      "[TL] Epoch 215 of 500 took 0.392342s\n",
      "[TL]    val loss: 0.054236\n",
      "[TL]    val acc: 0.984800\n",
      "[TL] Epoch 220 of 500 took 0.382827s\n",
      "[TL]    val loss: 0.053929\n",
      "[TL]    val acc: 0.985200\n",
      "[TL] Epoch 225 of 500 took 0.391011s\n",
      "[TL]    val loss: 0.053456\n",
      "[TL]    val acc: 0.985100\n",
      "[TL] Epoch 230 of 500 took 0.393448s\n",
      "[TL]    val loss: 0.053723\n",
      "[TL]    val acc: 0.985200\n",
      "[TL] Epoch 235 of 500 took 0.389823s\n",
      "[TL]    val loss: 0.052634\n",
      "[TL]    val acc: 0.985500\n",
      "[TL] Epoch 240 of 500 took 0.391018s\n",
      "[TL]    val loss: 0.053180\n",
      "[TL]    val acc: 0.985300\n",
      "[TL] Epoch 245 of 500 took 0.401096s\n",
      "[TL]    val loss: 0.054511\n",
      "[TL]    val acc: 0.984900\n",
      "[TL] Epoch 250 of 500 took 0.411428s\n",
      "[TL]    val loss: 0.052734\n",
      "[TL]    val acc: 0.985000\n",
      "[TL] Epoch 255 of 500 took 0.414082s\n",
      "[TL]    val loss: 0.053025\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 260 of 500 took 0.411103s\n",
      "[TL]    val loss: 0.053576\n",
      "[TL]    val acc: 0.985500\n",
      "[TL] Epoch 265 of 500 took 0.396353s\n",
      "[TL]    val loss: 0.053334\n",
      "[TL]    val acc: 0.984800\n",
      "[TL] Epoch 270 of 500 took 0.395922s\n",
      "[TL]    val loss: 0.053850\n",
      "[TL]    val acc: 0.985300\n",
      "[TL] Epoch 275 of 500 took 0.403293s\n",
      "[TL]    val loss: 0.053479\n",
      "[TL]    val acc: 0.985000\n",
      "[TL] Epoch 280 of 500 took 0.403741s\n",
      "[TL]    val loss: 0.055250\n",
      "[TL]    val acc: 0.985400\n",
      "[TL] Epoch 285 of 500 took 0.396753s\n",
      "[TL]    val loss: 0.054806\n",
      "[TL]    val acc: 0.985900\n",
      "[TL] Epoch 290 of 500 took 0.392855s\n",
      "[TL]    val loss: 0.054057\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 295 of 500 took 0.397030s\n",
      "[TL]    val loss: 0.054874\n",
      "[TL]    val acc: 0.985100\n",
      "[TL] Epoch 300 of 500 took 0.410975s\n",
      "[TL]    val loss: 0.053763\n",
      "[TL]    val acc: 0.985200\n",
      "[TL] Epoch 305 of 500 took 0.387222s\n",
      "[TL]    val loss: 0.052701\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 310 of 500 took 0.389714s\n",
      "[TL]    val loss: 0.052959\n",
      "[TL]    val acc: 0.985800\n",
      "[TL] Epoch 315 of 500 took 0.401373s\n",
      "[TL]    val loss: 0.054194\n",
      "[TL]    val acc: 0.985500\n",
      "[TL] Epoch 320 of 500 took 0.387561s\n",
      "[TL]    val loss: 0.052346\n",
      "[TL]    val acc: 0.985800\n",
      "[TL] Epoch 325 of 500 took 0.405390s\n",
      "[TL]    val loss: 0.051624\n",
      "[TL]    val acc: 0.986100\n",
      "[TL] Epoch 330 of 500 took 0.396918s\n",
      "[TL]    val loss: 0.053083\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 335 of 500 took 0.391438s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL]    val loss: 0.052205\n",
      "[TL]    val acc: 0.985500\n",
      "[TL] Epoch 340 of 500 took 0.405348s\n",
      "[TL]    val loss: 0.053775\n",
      "[TL]    val acc: 0.985200\n",
      "[TL] Epoch 345 of 500 took 0.392449s\n",
      "[TL]    val loss: 0.053872\n",
      "[TL]    val acc: 0.985700\n",
      "[TL] Epoch 350 of 500 took 0.405190s\n",
      "[TL]    val loss: 0.054922\n",
      "[TL]    val acc: 0.985800\n",
      "[TL] Epoch 355 of 500 took 0.398686s\n",
      "[TL]    val loss: 0.055578\n",
      "[TL]    val acc: 0.985100\n",
      "[TL] Epoch 360 of 500 took 0.389674s\n",
      "[TL]    val loss: 0.053899\n",
      "[TL]    val acc: 0.986200\n",
      "[TL] Epoch 365 of 500 took 0.392821s\n",
      "[TL]    val loss: 0.053832\n",
      "[TL]    val acc: 0.985700\n",
      "[TL] Epoch 370 of 500 took 0.398455s\n",
      "[TL]    val loss: 0.054463\n",
      "[TL]    val acc: 0.985700\n",
      "[TL] Epoch 375 of 500 took 0.405023s\n",
      "[TL]    val loss: 0.054976\n",
      "[TL]    val acc: 0.986000\n",
      "[TL] Epoch 380 of 500 took 0.396073s\n",
      "[TL]    val loss: 0.054163\n",
      "[TL]    val acc: 0.986300\n",
      "[TL] Epoch 385 of 500 took 0.385749s\n",
      "[TL]    val loss: 0.054368\n",
      "[TL]    val acc: 0.986000\n",
      "[TL] Epoch 390 of 500 took 0.412045s\n",
      "[TL]    val loss: 0.054000\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 395 of 500 took 0.389319s\n",
      "[TL]    val loss: 0.055449\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 400 of 500 took 0.402774s\n",
      "[TL]    val loss: 0.055053\n",
      "[TL]    val acc: 0.985900\n",
      "[TL] Epoch 405 of 500 took 0.401125s\n",
      "[TL]    val loss: 0.054339\n",
      "[TL]    val acc: 0.985400\n",
      "[TL] Epoch 410 of 500 took 0.393036s\n",
      "[TL]    val loss: 0.054275\n",
      "[TL]    val acc: 0.985700\n",
      "[TL] Epoch 415 of 500 took 0.404570s\n",
      "[TL]    val loss: 0.053083\n",
      "[TL]    val acc: 0.986600\n",
      "[TL] Epoch 420 of 500 took 0.421302s\n",
      "[TL]    val loss: 0.053818\n",
      "[TL]    val acc: 0.986000\n",
      "[TL] Epoch 425 of 500 took 0.404748s\n",
      "[TL]    val loss: 0.055146\n",
      "[TL]    val acc: 0.986000\n",
      "[TL] Epoch 430 of 500 took 0.413491s\n",
      "[TL]    val loss: 0.055860\n",
      "[TL]    val acc: 0.986300\n",
      "[TL] Epoch 435 of 500 took 0.394579s\n",
      "[TL]    val loss: 0.055456\n",
      "[TL]    val acc: 0.986100\n",
      "[TL] Epoch 440 of 500 took 0.396789s\n",
      "[TL]    val loss: 0.054348\n",
      "[TL]    val acc: 0.986200\n",
      "[TL] Epoch 445 of 500 took 0.398080s\n",
      "[TL]    val loss: 0.055754\n",
      "[TL]    val acc: 0.985600\n",
      "[TL] Epoch 450 of 500 took 0.410334s\n",
      "[TL]    val loss: 0.055462\n",
      "[TL]    val acc: 0.986200\n",
      "[TL] Epoch 455 of 500 took 0.398621s\n",
      "[TL]    val loss: 0.055237\n",
      "[TL]    val acc: 0.986000\n",
      "[TL] Epoch 460 of 500 took 0.393936s\n",
      "[TL]    val loss: 0.055523\n",
      "[TL]    val acc: 0.986100\n",
      "[TL] Epoch 465 of 500 took 0.437469s\n",
      "[TL]    val loss: 0.054626\n",
      "[TL]    val acc: 0.986400\n",
      "[TL] Epoch 470 of 500 took 0.398964s\n",
      "[TL]    val loss: 0.054909\n",
      "[TL]    val acc: 0.986300\n",
      "[TL] Epoch 475 of 500 took 0.397421s\n",
      "[TL]    val loss: 0.055187\n",
      "[TL]    val acc: 0.986300\n",
      "[TL] Epoch 480 of 500 took 0.396766s\n",
      "[TL]    val loss: 0.054274\n",
      "[TL]    val acc: 0.986600\n",
      "[TL] Epoch 485 of 500 took 0.394537s\n",
      "[TL]    val loss: 0.054985\n",
      "[TL]    val acc: 0.986900\n",
      "[TL] Epoch 490 of 500 took 0.397935s\n",
      "[TL]    val loss: 0.054692\n",
      "[TL]    val acc: 0.986700\n",
      "[TL] Epoch 495 of 500 took 0.394073s\n",
      "[TL]    val loss: 0.054895\n",
      "[TL]    val acc: 0.986900\n",
      "[TL] Epoch 500 of 500 took 0.406322s\n",
      "[TL]    val loss: 0.054809\n",
      "[TL]    val acc: 0.986600\n",
      "[TL] Total training time: 204.453351s\n",
      "[TL] Start testing the network ...\n",
      "[TL]    test loss: 0.052282\n",
      "[TL]    test acc: 0.986900\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.device('/gpu:0'):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    # 准备数据\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = \\\n",
    "                                    tl.files.load_mnist_dataset(shape=(-1,784))\n",
    "\n",
    "    # 定义 placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y_ = tf.placeholder(tf.int64, shape=[None, ], name='y_')\n",
    "\n",
    "    # 定义模型\n",
    "    network = tl.layers.InputLayer(x, name='input_layer')\n",
    "    network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "    network = tl.layers.DenseLayer(network, n_units=800,\n",
    "                                    act = tf.nn.relu, name='relu1')\n",
    "    network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "    network = tl.layers.DenseLayer(network, n_units=800,\n",
    "                                    act = tf.nn.relu, name='relu2')\n",
    "    network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "    network = tl.layers.DenseLayer(network, n_units=10,\n",
    "                                    act = tf.identity,\n",
    "                                    name='output_layer')\n",
    "    # 定义损失函数和衡量指标\n",
    "    # tl.cost.cross_entropy 在内部使用 tf.nn.sparse_softmax_cross_entropy_with_logits() 实现 softmax\n",
    "    y = network.outputs\n",
    "    cost = tl.cost.cross_entropy(y, y_, name = 'cost')\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    y_op = tf.argmax(tf.nn.softmax(y), 1)\n",
    "\n",
    "    # 定义 optimizer\n",
    "    train_params = network.all_params\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.9, beta2=0.999,\n",
    "                                epsilon=1e-08, use_locking=False).minimize(cost, var_list=train_params)\n",
    "\n",
    "    # 初始化 session 中的所有参数\n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "\n",
    "    # 列出模型信息\n",
    "    network.print_params()\n",
    "    network.print_layers()\n",
    "\n",
    "    # 训练模型\n",
    "    tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_,\n",
    "                acc=acc, batch_size=500, n_epoch=500, print_freq=5,\n",
    "                X_val=X_val, y_val=y_val, eval_train=False)\n",
    "\n",
    "    # 评估模型\n",
    "    tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)\n",
    "\n",
    "    # 把模型保存成 .npz 文件\n",
    "#     tl.files.save_npz(network.all_params , name='model.npz')\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
