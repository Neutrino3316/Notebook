{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "from six.moves import cPickle\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "# from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from prednet import PredNet\n",
    "# # from data_utils import SequenceGenerator\n",
    "# from kitti_settings import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build time: 2018-09-01 00:24:58\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras.layers import Recurrent\n",
    "from keras.layers import Conv2D, UpSampling2D, MaxPooling2D\n",
    "from keras.engine import InputSpec\n",
    "# from keras_utils import legacy_prednet_support\n",
    "\n",
    "class PredNet(Recurrent):\n",
    "    '''PredNet architecture - Lotter 2016.\n",
    "        Stacked convolutional LSTM inspired by predictive coding principles.\n",
    "\n",
    "    # Arguments\n",
    "        stack_sizes: number of channels in targets (A) and predictions (Ahat) in each layer of the architecture.\n",
    "            Length is the number of layers in the architecture.\n",
    "            First element is the number of channels in the input.\n",
    "            Ex. (3, 16, 32) would correspond to a 3 layer architecture that takes in RGB images and has 16 and 32\n",
    "                channels in the second and third layers, respectively.\n",
    "        R_stack_sizes: number of channels in the representation (R) modules.\n",
    "            Length must equal length of stack_sizes, but the number of channels per layer can be different.\n",
    "        A_filt_sizes: filter sizes for the target (A) modules.\n",
    "            Has length of 1 - len(stack_sizes).\n",
    "            Ex. (3, 3) would mean that targets for layers 2 and 3 are computed by a 3x3 convolution of the errors (E)\n",
    "                from the layer below (followed by max-pooling)\n",
    "        Ahat_filt_sizes: filter sizes for the prediction (Ahat) modules.\n",
    "            Has length equal to length of stack_sizes.\n",
    "            Ex. (3, 3, 3) would mean that the predictions for each layer are computed by a 3x3 convolution of the\n",
    "                representation (R) modules at each layer.\n",
    "        R_filt_sizes: filter sizes for the representation (R) modules.\n",
    "            Has length equal to length of stack_sizes.\n",
    "            Corresponds to the filter sizes for all convolutions in the LSTM.\n",
    "        pixel_max: the maximum pixel value.\n",
    "            Used to clip the pixel-layer prediction.\n",
    "        error_activation: activation function for the error (E) units.\n",
    "        A_activation: activation function for the target (A) and prediction (A_hat) units.\n",
    "        LSTM_activation: activation function for the cell and hidden states of the LSTM.\n",
    "        LSTM_inner_activation: activation function for the gates in the LSTM.\n",
    "        output_mode: either 'error', 'prediction', 'all' or layer specification (ex. R2, see below).\n",
    "            Controls what is outputted by the PredNet.\n",
    "            If 'error', the mean response of the error (E) units of each layer will be outputted.\n",
    "                That is, the output shape will be (batch_size, nb_layers).\n",
    "            If 'prediction', the frame prediction will be outputted.\n",
    "            If 'all', the output will be the frame prediction concatenated with the mean layer errors.\n",
    "                The frame prediction is flattened before concatenation.\n",
    "                Nomenclature of 'all' is kept for backwards compatibility, but should not be confused with returning all of the layers of the model\n",
    "            For returning the features of a particular layer, output_mode should be of the form unit_type + layer_number.\n",
    "                For instance, to return the features of the LSTM \"representational\" units in the lowest layer, output_mode should be specificied as 'R0'.\n",
    "                The possible unit types are 'R', 'Ahat', 'A', and 'E' corresponding to the 'representation', 'prediction', 'target', and 'error' units respectively.\n",
    "        extrap_start_time: time step for which model will start extrapolating.\n",
    "            Starting at this time step, the prediction from the previous time step will be treated as the \"actual\"\n",
    "        data_format: 'channels_first' or 'channels_last'.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "\n",
    "    # References\n",
    "        - [Deep predictive coding networks for video prediction and unsupervised learning](https://arxiv.org/abs/1605.08104)\n",
    "        - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "        - [Convolutional LSTM network: a machine learning approach for precipitation nowcasting](http://arxiv.org/abs/1506.04214)\n",
    "        - [Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects](http://www.nature.com/neuro/journal/v2/n1/pdf/nn0199_79.pdf)\n",
    "    '''\n",
    "#     @legacy_prednet_support\n",
    "    def __init__(self, stack_sizes, R_stack_sizes,\n",
    "                 A_filt_sizes, Ahat_filt_sizes, R_filt_sizes,\n",
    "                 pixel_max=1., error_activation='relu', A_activation='relu',\n",
    "                 LSTM_activation='tanh', LSTM_inner_activation='hard_sigmoid',\n",
    "                 conv_dropout=0.8,\n",
    "                 output_mode='error', extrap_start_time=None,\n",
    "                 data_format=K.image_data_format(), **kwargs):\n",
    "        self.stack_sizes = stack_sizes\n",
    "        self.nb_layers = len(stack_sizes)\n",
    "        assert len(R_stack_sizes) == self.nb_layers, 'len(R_stack_sizes) must equal len(stack_sizes)'\n",
    "        self.R_stack_sizes = R_stack_sizes\n",
    "        assert len(A_filt_sizes) == (self.nb_layers - 1), 'len(A_filt_sizes) must equal len(stack_sizes) - 1'\n",
    "        self.A_filt_sizes = A_filt_sizes\n",
    "        assert len(Ahat_filt_sizes) == self.nb_layers, 'len(Ahat_filt_sizes) must equal len(stack_sizes)'\n",
    "        self.Ahat_filt_sizes = Ahat_filt_sizes\n",
    "        assert len(R_filt_sizes) == (self.nb_layers), 'len(R_filt_sizes) must equal len(stack_sizes)'\n",
    "        self.R_filt_sizes = R_filt_sizes\n",
    "\n",
    "        self.pixel_max = pixel_max\n",
    "        self.error_activation = activations.get(error_activation)\n",
    "        self.A_activation = activations.get(A_activation)\n",
    "        self.LSTM_activation = activations.get(LSTM_activation)\n",
    "        self.LSTM_inner_activation = activations.get(LSTM_inner_activation)\n",
    "        self.conv_dropout = conv_dropout\n",
    "\n",
    "        default_output_modes = ['prediction', 'error', 'all']\n",
    "        layer_output_modes = [layer + str(n) for n in range(self.nb_layers) for layer in ['R', 'E', 'A', 'Ahat']]\n",
    "        assert output_mode in default_output_modes + layer_output_modes, 'Invalid output_mode: ' + str(output_mode)\n",
    "        self.output_mode = output_mode\n",
    "        if self.output_mode in layer_output_modes:\n",
    "            self.output_layer_type = self.output_mode[:-1]\n",
    "            self.output_layer_num = int(self.output_mode[-1])\n",
    "        else:\n",
    "            self.output_layer_type = None\n",
    "            self.output_layer_num = None\n",
    "        self.extrap_start_time = extrap_start_time\n",
    "\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {channels_last, channels_first}'\n",
    "        self.data_format = data_format\n",
    "        self.channel_axis = -3 if data_format == 'channels_first' else -1\n",
    "        self.row_axis = -2 if data_format == 'channels_first' else -3\n",
    "        self.column_axis = -1 if data_format == 'channels_first' else -2\n",
    "        super(PredNet, self).__init__(**kwargs)\n",
    "        self.input_spec = [InputSpec(ndim=5)]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.output_mode == 'prediction':\n",
    "            out_shape = input_shape[2:]\n",
    "        elif self.output_mode == 'error':\n",
    "            out_shape = (self.nb_layers,)\n",
    "        elif self.output_mode == 'all':\n",
    "            out_shape = (np.prod(input_shape[2:]) + self.nb_layers,)\n",
    "        else:\n",
    "            stack_str = 'R_stack_sizes' if self.output_layer_type == 'R' else 'stack_sizes'\n",
    "            stack_mult = 2 if self.output_layer_type == 'E' else 1\n",
    "            out_stack_size = stack_mult * getattr(self, stack_str)[self.output_layer_num]\n",
    "            out_nb_row = input_shape[self.row_axis] / 2**self.output_layer_num\n",
    "            out_nb_col = input_shape[self.column_axis] / 2**self.output_layer_num\n",
    "            if self.data_format == 'channels_first':\n",
    "                out_shape = (out_stack_size, out_nb_row, out_nb_col)\n",
    "            else:\n",
    "                out_shape = (out_nb_row, out_nb_col, out_stack_size)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return (input_shape[0], input_shape[1]) + out_shape\n",
    "        else:\n",
    "            return (input_shape[0],) + out_shape\n",
    "\n",
    "    def get_initial_state(self, x):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        init_nb_row = input_shape[self.row_axis]\n",
    "        init_nb_col = input_shape[self.column_axis]\n",
    "\n",
    "        base_initial_state = K.zeros_like(x)  # (samples, timesteps) + image_shape\n",
    "        non_channel_axis = -1 if self.data_format == 'channels_first' else -2\n",
    "        for _ in range(2):\n",
    "            base_initial_state = K.sum(base_initial_state, axis=non_channel_axis)\n",
    "        base_initial_state = K.sum(base_initial_state, axis=1)  # (samples, nb_channels)\n",
    "\n",
    "        initial_states = []\n",
    "        states_to_pass = ['r', 'c', 'e']\n",
    "        nlayers_to_pass = {u: self.nb_layers for u in states_to_pass}\n",
    "        if self.extrap_start_time is not None:\n",
    "            states_to_pass.append('ahat')  # pass prediction in states so can use as actual for t+1 when extrapolating\n",
    "            nlayers_to_pass['ahat'] = 1\n",
    "        for u in states_to_pass:\n",
    "            for l in range(nlayers_to_pass[u]):\n",
    "                ds_factor = 2 ** l\n",
    "                nb_row = init_nb_row // ds_factor\n",
    "                nb_col = init_nb_col // ds_factor\n",
    "                if u in ['r', 'c']:\n",
    "                    stack_size = self.R_stack_sizes[l]\n",
    "                elif u == 'e':\n",
    "                    stack_size = 2 * self.stack_sizes[l]\n",
    "                elif u == 'ahat':\n",
    "                    stack_size = self.stack_sizes[l]\n",
    "                output_size = stack_size * nb_row * nb_col  # flattened size\n",
    "\n",
    "                reducer = K.zeros((input_shape[self.channel_axis], output_size)) # (nb_channels, output_size)\n",
    "                initial_state = K.dot(base_initial_state, reducer) # (samples, output_size)\n",
    "                if self.data_format == 'channels_first':\n",
    "                    output_shp = (-1, stack_size, nb_row, nb_col)\n",
    "                else:\n",
    "                    output_shp = (-1, nb_row, nb_col, stack_size)\n",
    "                initial_state = K.reshape(initial_state, output_shp)\n",
    "                initial_states += [initial_state]\n",
    "\n",
    "        if K._BACKEND == 'theano':\n",
    "            from theano import tensor as T\n",
    "            # There is a known issue in the Theano scan op when dealing with inputs whose shape is 1 along a dimension.\n",
    "            # In our case, this is a problem when training on grayscale images, and the below line fixes it.\n",
    "            initial_states = [T.unbroadcast(init_state, 0, 1) for init_state in initial_states]\n",
    "\n",
    "        if self.extrap_start_time is not None:\n",
    "            initial_states += [K.variable(0, int if K.backend() != 'tensorflow' else 'int32')]  # the last state will correspond to the current timestep\n",
    "        return initial_states\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.conv_layers = {c: [] for c in ['i', 'f', 'c', 'o', 'a', 'ahat']}\n",
    "\n",
    "        for l in range(self.nb_layers):\n",
    "            for c in ['i', 'f', 'c', 'o']:\n",
    "                act = self.LSTM_activation if c == 'c' else self.LSTM_inner_activation\n",
    "                self.conv_layers[c].append(Conv2D(self.R_stack_sizes[l], self.R_filt_sizes[l], padding='same', activation=act, data_format=self.data_format))\n",
    "#                 self.conv_layers[c].append(keras.layers.Dropout(self.conv_dropout))\n",
    "\n",
    "            act = 'relu' if l == 0 else self.A_activation\n",
    "            self.conv_layers['ahat'].append(Conv2D(self.stack_sizes[l], self.Ahat_filt_sizes[l], padding='same', activation=act, data_format=self.data_format))\n",
    "\n",
    "            if l < self.nb_layers - 1:\n",
    "                self.conv_layers['a'].append(Conv2D(self.stack_sizes[l+1], self.A_filt_sizes[l], padding='same', activation=self.A_activation, data_format=self.data_format))\n",
    "\n",
    "        self.upsample = UpSampling2D(data_format=self.data_format)\n",
    "        self.pool = MaxPooling2D(data_format=self.data_format)\n",
    "\n",
    "        self.trainable_weights = []\n",
    "        nb_row, nb_col = (input_shape[-2], input_shape[-1]) if self.data_format == 'channels_first' else (input_shape[-3], input_shape[-2])\n",
    "        for c in sorted(self.conv_layers.keys()):\n",
    "            for l in range(len(self.conv_layers[c])):\n",
    "                ds_factor = 2 ** l\n",
    "                if c == 'ahat':\n",
    "                    nb_channels = self.R_stack_sizes[l]\n",
    "                elif c == 'a':\n",
    "                    nb_channels = 2 * self.R_stack_sizes[l]\n",
    "                else:\n",
    "                    nb_channels = self.stack_sizes[l] * 2 + self.R_stack_sizes[l]\n",
    "                    if l < self.nb_layers - 1:\n",
    "                        nb_channels += self.R_stack_sizes[l+1]\n",
    "                in_shape = (input_shape[0], nb_channels, nb_row // ds_factor, nb_col // ds_factor)\n",
    "                if self.data_format == 'channels_last': in_shape = (in_shape[0], in_shape[2], in_shape[3], in_shape[1])\n",
    "                with K.name_scope('layer_' + c + '_' + str(l)):\n",
    "                    self.conv_layers[c][l].build(in_shape)\n",
    "                self.trainable_weights += self.conv_layers[c][l].trainable_weights\n",
    "\n",
    "        self.states = [None] * self.nb_layers*3\n",
    "\n",
    "        if self.extrap_start_time is not None:\n",
    "            self.t_extrap = K.variable(self.extrap_start_time, int if K.backend() != 'tensorflow' else 'int32')\n",
    "            self.states += [None] * 2  # [previous frame prediction, timestep]\n",
    "\n",
    "    def step(self, a, states):\n",
    "        r_tm1 = states[:self.nb_layers]\n",
    "        c_tm1 = states[self.nb_layers:2*self.nb_layers]\n",
    "        e_tm1 = states[2*self.nb_layers:3*self.nb_layers]\n",
    "\n",
    "        if self.extrap_start_time is not None:\n",
    "            t = states[-1]\n",
    "            a = K.switch(t >= self.t_extrap, states[-2], a)  # if past self.extrap_start_time, the previous prediction will be treated as the actual\n",
    "\n",
    "        c = []\n",
    "        r = []\n",
    "        e = []\n",
    "\n",
    "        # Update R units starting from the top\n",
    "        for l in reversed(range(self.nb_layers)):\n",
    "            inputs = [r_tm1[l], e_tm1[l]]\n",
    "            if l < self.nb_layers - 1:\n",
    "                inputs.append(r_up)\n",
    "\n",
    "            inputs = K.concatenate(inputs, axis=self.channel_axis)\n",
    "            i = self.conv_layers['i'][l].call(inputs)\n",
    "            f = self.conv_layers['f'][l].call(inputs)\n",
    "            o = self.conv_layers['o'][l].call(inputs)\n",
    "            _c = f * c_tm1[l] + i * self.conv_layers['c'][l].call(inputs)\n",
    "            _r = o * self.LSTM_activation(_c)\n",
    "            c.insert(0, _c)\n",
    "            r.insert(0, _r)\n",
    "\n",
    "            if l > 0:\n",
    "                r_up = self.upsample.call(_r)\n",
    "\n",
    "        # Update feedforward path starting from the bottom\n",
    "        for l in range(self.nb_layers):\n",
    "            ahat = self.conv_layers['ahat'][l].call(r[l])\n",
    "            if l == 0:\n",
    "                ahat = K.minimum(ahat, self.pixel_max)\n",
    "                frame_prediction = ahat\n",
    "\n",
    "            # compute errors\n",
    "            e_up = self.error_activation(ahat - a)\n",
    "            e_down = self.error_activation(a - ahat)\n",
    "\n",
    "            e.append(K.concatenate((e_up, e_down), axis=self.channel_axis))\n",
    "\n",
    "            if self.output_layer_num == l:\n",
    "                if self.output_layer_type == 'A':\n",
    "                    output = a\n",
    "                elif self.output_layer_type == 'Ahat':\n",
    "                    output = ahat\n",
    "                elif self.output_layer_type == 'R':\n",
    "                    output = r[l]\n",
    "                elif self.output_layer_type == 'E':\n",
    "                    output = e[l]\n",
    "\n",
    "            if l < self.nb_layers - 1:\n",
    "                a = self.conv_layers['a'][l].call(e[l])\n",
    "                a = self.pool.call(a)  # target for next layer\n",
    "\n",
    "        if self.output_layer_type is None:\n",
    "            if self.output_mode == 'prediction':\n",
    "                output = frame_prediction\n",
    "            else:\n",
    "                for l in range(self.nb_layers):\n",
    "                    layer_error = K.mean(K.batch_flatten(e[l]), axis=-1, keepdims=True)\n",
    "                    all_error = layer_error if l == 0 else K.concatenate((all_error, layer_error), axis=-1)\n",
    "                if self.output_mode == 'error':\n",
    "                    output = all_error\n",
    "                else:\n",
    "                    output = K.concatenate((K.batch_flatten(frame_prediction), all_error), axis=-1)\n",
    "\n",
    "        states = r + c + e\n",
    "        if self.extrap_start_time is not None:\n",
    "            states += [frame_prediction, t + 1]\n",
    "        return output, states\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'stack_sizes': self.stack_sizes,\n",
    "                  'R_stack_sizes': self.R_stack_sizes,\n",
    "                  'A_filt_sizes': self.A_filt_sizes,\n",
    "                  'Ahat_filt_sizes': self.Ahat_filt_sizes,\n",
    "                  'R_filt_sizes': self.R_filt_sizes,\n",
    "                  'pixel_max': self.pixel_max,\n",
    "                  'error_activation': self.error_activation.__name__,\n",
    "                  'A_activation': self.A_activation.__name__,\n",
    "                  'LSTM_activation': self.LSTM_activation.__name__,\n",
    "                  'LSTM_inner_activation': self.LSTM_inner_activation.__name__,\n",
    "                  'data_format': self.data_format,\n",
    "                  'extrap_start_time': self.extrap_start_time,\n",
    "                  'output_mode': self.output_mode}\n",
    "        base_config = super(PredNet, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "raw_RAD_id_list = os.listdir('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/')\n",
    "print(len(raw_RAD_id_list))\n",
    "RAD_id_list = raw_RAD_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RAD_id(RAD_id):\n",
    "    mean_list = []\n",
    "    for k in range(61):\n",
    "        mean_list.append(np.array(PIL.Image.open('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png'\n",
    "                         % (RAD_id, RAD_id,\n",
    "                        k))).astype(np.int8).ravel().mean())\n",
    "    mean_list = np.array(mean_list)\n",
    "    if mean_list.mean() < -0.5:\n",
    "        return None\n",
    "    for k in range(59):\n",
    "        if abs(mean_list[k] + mean_list[k + 2] - 2 * mean_list[k + 1]) > 2:\n",
    "            return None\n",
    "    return RAD_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2018-09-01 00:25:04\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "start_time = time.time()\n",
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "# map(check_RAD_id, raw_RAD_id_list[:100])\n",
    "# print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "RAD_id_list = list(pool.map(check_RAD_id, raw_RAD_id_list))\n",
    "RAD_id_list = [x for x in RAD_id_list if x is not None]\n",
    "print(time.strftime('end time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(len(RAD_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, nt, image_size, image_scalar, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.nt = nt\n",
    "        self.image_size = image_size\n",
    "        self.image_scalar = image_scalar\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = np.empty((self.batch_size, self.nt, self.image_size, self.image_size, 1))\n",
    "        y = np.empty((self.batch_size, self.image_size, self.image_size, 1))\n",
    "        # Generate data\n",
    "#         print(list_IDs_temp)\n",
    "        for i, RAD_id in enumerate(list_IDs_temp):\n",
    "            for j in range(self.nt):\n",
    "                X[i][j] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * 1)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "            y[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, (self.nt) * 1)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "#         y = np.zeros(self.batch_size, np.float32)\n",
    "        return X, y\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "image_size = 512\n",
    "nt = 10 # number of timesteps used for sequences in training\n",
    "image_scalar = 80\n",
    "vmin = -0.01 * image_scalar\n",
    "vmax = 0.6 * image_scalar\n",
    "n_channels, im_height, im_width = (1, image_size, image_size)  # (3, 128, 160)\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (3, 3, 3)\n",
    "Ahat_filt_sizes = (3, 3, 3, 3)\n",
    "R_filt_sizes = (3, 3, 3, 3)\n",
    "layer_loss_weights = np.array([1, 0, 0, 0])  # weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "time_loss_weights = 1./ (nt - 1) * np.ones((nt,1))  # equally weight all timesteps except the first\n",
    "time_loss_weights[0] = 0\n",
    "\n",
    "\n",
    "prednet = PredNet(stack_sizes, R_stack_sizes,\n",
    "                  A_filt_sizes, Ahat_filt_sizes, R_filt_sizes,\n",
    "                  A_activation='elu', error_activation='elu',\n",
    "                  LSTM_inner_activation='sigmoid',\n",
    "                  output_mode='error', return_sequences=True)\n",
    "\n",
    "inputs = Input(shape=(nt,) + input_shape)\n",
    "errors = prednet(inputs)  # errors will be (batch_size, nt, nb_layers)\n",
    "errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "outputs = final_errors\n",
    "# outputs = np.empty(shape=(nt,) + input_shape)\n",
    "# for i in range(nt):\n",
    "#     temp_outputs = prednet(inputs)\n",
    "#     outputs[i] = temp_outputs\n",
    "#     for j in range(nt - 1):\n",
    "#         inputs[j] = inputs[j + 1]\n",
    "#     inputs[-1] = temp_outputs\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "#     w = tf.add(y_true, tf.constant(0.8))\n",
    "#     w = tf.add(y_pred, w)\n",
    "#     loss = tf.losses.mean_squared_error(y_true, y_pred, weights=w)\n",
    "    loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = tf.multiply(loss, tf.constant(10000000.0))\n",
    "    return loss\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=my_loss, optimizer=keras.optimizers.Adam())\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to use tensorboard\n",
    "\n",
    "```bash\n",
    "jupyter notebook --ip=192.168.2.101\n",
    "python3 /usr/local/lib/python3.5/dist-packages/tensorboard/main.py --logdir='/home/hadoop/Documents/Neutrino/tensorboard_logs' --host=192.168.2.101 --port=8900\n",
    "rm -rf /home/hadoop/Documents/Neutrino/tensorboard_logs\n",
    "scp \"C:/Users/Administrator/Downloads/SRAD2018_Test_1.zip\" hadoop@192.168.1.115:~/Documents/Neutrino/SRAD2018/SRAD2018_test\n",
    "mv -v ~/Documents/Neutrino/SRAD2018/SRAD2018_test/SRAD2018_Test_1* ~/Documents/Neutrino/SRAD2018/SRAD2018_test\n",
    "lsof /dev/nvidia0\n",
    "lsof -n -i4TCP:8888\n",
    "kill -9 -[PID]\n",
    "```\n",
    "\n",
    "`http://222.200.177.32:8900/#scalars&run=.&_smoothingWeight=0.8`\n",
    "\n",
    "`http://222.200.177.32:8888`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda epoch: 0.001 if epoch < 3 else 0.0003    # start with lr of 0.001 and then drop to 0.0001 after 75 epochs\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='/home/hadoop/Documents/Neutrino/tensorboard_logs', histogram_freq=0, write_graph=False)\n",
    "callbacks = [LearningRateScheduler(lr_schedule), tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_generator = trainGenerator(list_IDs=RAD_id_list[:120], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=1)\n",
    "valid_generator = trainGenerator(list_IDs=RAD_id_list[-12:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=1, shuffle=False)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=10, epochs=36, validation_data=valid_generator, validation_steps=1, use_multiprocessing=True, max_queue_size=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda epoch: 0.001 if epoch < 3 else 0.0001    # start with lr of 0.001 and then drop to 0.0001 after 75 epochs\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='/home/hadoop/Documents/Neutrino/tensorboard_logs', histogram_freq=0, write_graph=False)\n",
    "callbacks = [LearningRateScheduler(lr_schedule), tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_generator = trainGenerator(list_IDs=RAD_id_list[:6000], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=1)\n",
    "valid_generator = trainGenerator(list_IDs=RAD_id_list[-20:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=1)\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100, validation_data=valid_generator, validation_steps=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试验证\n",
    "\n",
    "## `return_sequences=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model\n",
    "layer_config = train_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=train_model.layers[1].get_weights(), **layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = Input(shape=(nt,) + input_shape)\n",
    "test_outputs = test_prednet(test_inputs)\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "#     w = tf.add(y_true, tf.constant(0.8))\n",
    "#     w = tf.add(y_pred, w)\n",
    "#     loss = tf.losses.mean_squared_error(y_true, y_pred, weights=w)\n",
    "    loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = tf.multiply(loss, tf.constant(10000000.0))\n",
    "    return loss\n",
    "\n",
    "test_model = keras.models.Model(inputs=test_inputs, outputs=test_outputs)\n",
    "test_model.compile(loss=my_loss, optimizer=keras.optimizers.Adam())\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, nt, image_size, image_scalar, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.nt = nt\n",
    "        self.image_size = image_size\n",
    "        self.image_scalar = image_scalar\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = np.empty((self.batch_size, self.nt, self.image_size, self.image_size, 1))\n",
    "        y = np.empty((self.batch_size, self.image_size, self.image_size, 1))\n",
    "        # Generate data\n",
    "#         print(list_IDs_temp)\n",
    "        for i, RAD_id in enumerate(list_IDs_temp):\n",
    "            for j in range(self.nt):\n",
    "                X[i][j] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "            y[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, (self.nt))).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "#         y = np.zeros(self.batch_size, np.float32)\n",
    "        return X, y\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_generator = testGenerator(list_IDs=RAD_id_list[:6000], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=2)\n",
    "valid_generator = testGenerator(list_IDs=RAD_id_list[6000:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.on_epoch_end()\n",
    "valid_generator.on_epoch_end()\n",
    "for data in [train_generator, valid_generator][1]:\n",
    "    x, y_ = data\n",
    "    break\n",
    "y = test_model.predict(x)\n",
    "\n",
    "plt.imshow(x[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是真实值，上面的是上一张↑↑↑')\n",
    "plt.imshow(y_[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是模型的输出，上面的是真实值↑↑↑')\n",
    "plt.imshow(y[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是模型一整段的输出，上面的是最后一张输出↑↑↑')\n",
    "for i in range(y.shape[1]):\n",
    "    plt.imshow(y[0][i].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator.on_epoch_end()\n",
    "valid_generator.on_epoch_end()\n",
    "for data in [train_generator, valid_generator][1]:\n",
    "    x, y_ = data\n",
    "    break\n",
    "for i in range(30):\n",
    "    y = test_model.predict(x)\n",
    "    y = np.where(y<0.01, -0.01, y)\n",
    "    for j in range(nt - 1):\n",
    "        x[0][j] = x[0][j + 1]\n",
    "    x[0][-1] = y[0][-1]\n",
    "    print('%2d:' % i)\n",
    "    plt.imshow(y[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "\n",
    "# plt.imshow(x[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "# plt.show()\n",
    "# print('↓↓↓下面的是真实值，上面的是上一张↑↑↑')\n",
    "# plt.imshow(y_[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "# plt.show()\n",
    "# print('↓↓↓下面的是模型的输出，上面的是真实值↑↑↑')\n",
    "# plt.imshow(y[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "# plt.show()\n",
    "# print('↓↓↓下面的是模型一整段的输出，上面的是最后一张输出↑↑↑')\n",
    "# for i in range(y.shape[1]):\n",
    "#     plt.imshow(y[0][i].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/hadoop/Documents/Neutrino/prednet/prednet_v0.2.8.hdf5')\n",
    "model.save_weights('/home/hadoop/Documents/Neutrino/prednet/prednet_v0.2.8_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `return_sequences=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = model\n",
    "layer_config = train_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "layer_config['return_sequences'] = False\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=train_model.layers[1].get_weights(), **layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = Input(shape=(nt,) + input_shape)\n",
    "test_outputs = test_prednet(test_inputs)\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "#     w = tf.add(y_true, tf.constant(0.8))\n",
    "#     w = tf.add(y_pred, w)\n",
    "#     loss = tf.losses.mean_squared_error(y_true, y_pred, weights=w)\n",
    "    loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = tf.multiply(loss, tf.constant(10000000.0))\n",
    "    return loss\n",
    "\n",
    "test_model = keras.models.Model(inputs=test_inputs, outputs=test_outputs)\n",
    "test_model.compile(loss=my_loss, optimizer=keras.optimizers.Adam())\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, nt, image_size, image_scalar, batch_size=32, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.nt = nt\n",
    "        self.image_size = image_size\n",
    "        self.image_scalar = image_scalar\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = np.empty((self.batch_size, self.nt, self.image_size, self.image_size, 1))\n",
    "        y = np.empty((self.batch_size, self.image_size, self.image_size, 1))\n",
    "        # Generate data\n",
    "#         print(list_IDs_temp)\n",
    "        for i, RAD_id in enumerate(list_IDs_temp):\n",
    "            for j in range(self.nt):\n",
    "                X[i][j] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * 5)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "            y[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, (self.nt) * 5)).resize((self.image_size, self.image_size))).astype(np.int8).reshape((self.image_size, self.image_size, 1)) / self.image_scalar\n",
    "#         y = np.zeros(self.batch_size, np.float32)\n",
    "        return X, y\n",
    "print(time.strftime('build time: %Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_generator = testGenerator(list_IDs=RAD_id_list[:6000], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=2)\n",
    "valid_generator = testGenerator(list_IDs=RAD_id_list[6000:], nt=nt, image_size=image_size, image_scalar=image_scalar, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator.on_epoch_end()\n",
    "valid_generator.on_epoch_end()\n",
    "for data in [train_generator, valid_generator][1]:\n",
    "    x, y_ = data\n",
    "    break\n",
    "y = test_model.predict(x)\n",
    "\n",
    "plt.imshow(x[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是真实值，上面的是上一张↑↑↑')\n",
    "plt.imshow(y_[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "print('↓↓↓下面的是模型的输出，上面的是真实值↑↑↑')\n",
    "plt.imshow(y[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_generator.on_epoch_end()\n",
    "# valid_generator.on_epoch_end()\n",
    "for data in [train_generator, valid_generator][1]:\n",
    "    x, y_ = data\n",
    "    break\n",
    "for i in range(30):\n",
    "    y = test_model.predict(x)\n",
    "    y = np.where(y<0.03, -0.01, y)\n",
    "#     y = np.where(y>0.6, 0.6, y)\n",
    "    for j in range(nt - 1):\n",
    "        x[0][j] = x[0][j + 1]\n",
    "    x[0][-1] = y[0]\n",
    "    print('%2d:' % i)\n",
    "    plt.imshow(y[0].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用模型预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_id = RAD_id_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((nt, image_size, image_size, 1))\n",
    "y = np.empty((image_size, image_size, 1))\n",
    "for i in range(nt):\n",
    "    X[i] = np.array(PIL.Image.open(\"/home/aisalon/HZZ/Neutrino/SRAD2018/SRAD2018_train_data/%s/%s_%03d.png\" % (RAD_id, RAD_id, i * 5)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size, 1)) / image_scalar\n",
    "y = np.array(PIL.Image.open(\"/home/aisalon/HZZ/Neutrino/SRAD2018/SRAD2018_train_data/%s/%s_%03d.png\" % (RAD_id, RAD_id, nt * 5)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size, 1)) / image_scalar\n",
    "\n",
    "for i in range(30):\n",
    "    y = test_model.predict(x)\n",
    "    y = np.where(y<0.03, -0.01, y)\n",
    "    for j in range(nt - 1):\n",
    "        x[0][j] = x[0][j + 1]\n",
    "    x[0][-1] = y[0][-1]\n",
    "    print('%2d:' % i)\n",
    "    plt.imshow(y[0][-1].reshape((image_size, image_size)) * image_scalar, cmap=cm.gist_ncar_r)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
