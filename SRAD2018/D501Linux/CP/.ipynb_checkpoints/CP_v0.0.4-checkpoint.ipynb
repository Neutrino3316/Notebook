{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(123)\n",
    "from six.moves import cPickle\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "# from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from prednet import PredNet\n",
    "# # from data_utils import SequenceGenerator\n",
    "# from kitti_settings import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import time\n",
    "import multiprocessing\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import restoration\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "raw_RAD_id_list = os.listdir('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/')\n",
    "print(len(raw_RAD_id_list))\n",
    "RAD_id_list = raw_RAD_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RAD_id(RAD_id):\n",
    "#     return RAD_id\n",
    "    mean_list = []\n",
    "    for k in range(61):\n",
    "        mean_list.append(np.array(PIL.Image.open('/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png'\n",
    "                         % (RAD_id, RAD_id,\n",
    "                        k))).astype(np.int8).ravel().mean())\n",
    "    mean_list = np.array(mean_list)\n",
    "    if mean_list.mean() < -0.5:\n",
    "        return None\n",
    "    for k in range(59):\n",
    "        if abs(mean_list[k] + mean_list[k + 2] - 2 * mean_list[k + 1]) > 2:\n",
    "            return None\n",
    "    return RAD_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2018-09-24 23:01:39\n",
      "end time: 2018-09-24 23:02:42\n",
      "00:01:02\n",
      "6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "start_time = time.time()\n",
    "print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "# map(check_RAD_id, raw_RAD_id_list[:100])\n",
    "# print(time.strftime('start time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "RAD_id_list = list(pool.map(check_RAD_id, raw_RAD_id_list))\n",
    "RAD_id_list = [x for x in RAD_id_list if x is not None]\n",
    "print(time.strftime('end time: %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "print(time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(len(RAD_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(list_IDs_temp, batch_size, image_size, nt, step_size, image_scalar, offset=None, path='/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train'):\n",
    "    '''\n",
    "    nt * step_size + offset = 60\n",
    "    '''\n",
    "    X = np.empty((batch_size, nt, image_size, image_size, n_channels))\n",
    "    y = np.empty((batch_size, image_size, image_size, n_channels))\n",
    "    for i, RAD_id in enumerate(list_IDs_temp):\n",
    "#         offset = random.randint(0, 61 - nt * step_size)\n",
    "        if offset == None:\n",
    "            offset = random.randint(2, 59 - nt * step_size)\n",
    "        for j in range(nt):\n",
    "            temp_matrix = np.empty((n_channels, image_size, image_size))\n",
    "#             temp_matrix[0] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * step_size + offset - 1)).resize((image_size, image_size))).astype(np.int8) / image_scalar + \\\n",
    "#                              np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * step_size + offset - 2)).resize((image_size, image_size))).astype(np.int8) / image_scalar\n",
    "            temp_matrix[0] = np.array(PIL.Image.open(\"%s/%s/%s_%03d.png\" % (path, RAD_id, RAD_id, j * step_size + offset)).resize((image_size, image_size))).astype(np.int8) / image_scalar\n",
    "#             temp_matrix[2] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * step_size + offset + 1)).resize((image_size, image_size))).astype(np.int8) / image_scalar + \\\n",
    "#                              np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, j * step_size + offset + 2)).resize((image_size, image_size))).astype(np.int8) / image_scalar\n",
    "            temp_matrix[1] = cv2.GaussianBlur(temp_matrix[0], (5, 5), 0)\n",
    "            temp_matrix[2] = cv2.GaussianBlur(temp_matrix[0], (9, 9), 0)\n",
    "            temp_matrix[3] = cv2.GaussianBlur(temp_matrix[0], (13, 13), 0)\n",
    "            temp_matrix = np.rollaxis(temp_matrix, 0, 3)\n",
    "            X[i][j] = temp_matrix\n",
    "        temp_matrix = np.empty((n_channels, image_size, image_size))\n",
    "        temp_matrix[0] = np.array(PIL.Image.open(\"%s/%s/%s_%03d.png\" % (path, RAD_id, RAD_id, nt * step_size + offset)).resize((image_size, image_size))).astype(np.int8) / image_scalar\n",
    "        temp_matrix[1] = cv2.GaussianBlur(temp_matrix[0], (5, 5), 0)\n",
    "        temp_matrix[2] = cv2.GaussianBlur(temp_matrix[0], (9, 9), 0)\n",
    "        temp_matrix[3] = cv2.GaussianBlur(temp_matrix[0], (13, 13), 0)\n",
    "        temp_matrix = np.rollaxis(temp_matrix, 0, 3)\n",
    "        y[i] = temp_matrix\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30 // 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 30)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = sklearn.linear_model.LinearRegression()\n",
    "reg.fit([[0], [1], [2]], [0, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(x):\n",
    "    return cv2.GaussianBlur(x[-1], (5, 5), 0)\n",
    "    ans = np.empty((image_size, image_size))\n",
    "    for i in range(image_size):\n",
    "        for j in range(image_size):\n",
    "#             reg_x = []\n",
    "#             reg_y = []\n",
    "#             for k in range(nt):\n",
    "#                 reg_x.append([k])\n",
    "#                 reg_y.append(x[k][i][j])\n",
    "#             reg = sklearn.linear_model.LinearRegression()\n",
    "#             reg.fit(reg_x, reg_y)\n",
    "            k = (x[-1][i][j] - x[0][i][j]) / (nt - 1)\n",
    "            m = x[-1][i][j]\n",
    "            ans[i][j] = m + k\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "nt = 3\n",
    "kernel_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2018-09-25 00:33:26\n",
      "RAD_id_counter=    0\t\tIt takes 0.01\n",
      "RAD_id_counter=   10\t\tIt takes 0.14\n",
      "RAD_id_counter=   20\t\tIt takes 0.25\n",
      "RAD_id_counter=   30\t\tIt takes 0.37\n",
      "RAD_id_counter=   40\t\tIt takes 0.48\n",
      "     model_abs_loss=2.9634400\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=55.0416141\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:33:26\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(time.strftime(\"start time: %Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "model_abs_loss = []\n",
    "model_sqr_loss = []\n",
    "last_frame_abs_loss = []\n",
    "last_frame_sqr_loss = []\n",
    "for RAD_id_counter, RAD_id in enumerate(RAD_id_list[-50:]):\n",
    "    x = np.empty((nt, image_size, image_size))\n",
    "    for i in range(nt):\n",
    "        x[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 31 + i - nt)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "    x_last = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 30)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "    y_true_last = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 60)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "    for i in range(30 // 30):  # 30 // nt\n",
    "#         y = model_predict(x)\n",
    "        y = cv2.GaussianBlur(x[-1], (kernel_size, kernel_size), 0)\n",
    "        for j in range(nt - 1):\n",
    "            x[j] = x[j + 1]\n",
    "        x[-1] = y\n",
    "    y_pred_last = y\n",
    "    last_frame_abs_loss.append(sklearn.metrics.mean_absolute_error(y_true_last, x_last))\n",
    "    model_abs_loss.append(sklearn.metrics.mean_absolute_error(y_true_last, y_pred_last))\n",
    "    last_frame_sqr_loss.append(sklearn.metrics.mean_squared_error(y_true_last.astype(np.int), x_last.astype(np.int)))\n",
    "    model_sqr_loss.append(sklearn.metrics.mean_squared_error(y_true_last.astype(np.int), y_pred_last.astype(np.int)))\n",
    "    if RAD_id_counter % 10 == 0:\n",
    "        print('RAD_id_counter=%5d\\t\\tIt takes %.2f' % (RAD_id_counter, time.time() - start_time))\n",
    "model_abs_loss = np.array(model_abs_loss)\n",
    "last_frame_abs_loss = np.array(last_frame_abs_loss)\n",
    "model_sqr_loss = np.array(model_sqr_loss)\n",
    "last_frame_sqr_loss = np.array(last_frame_sqr_loss)\n",
    "print('     model_abs_loss=%.7f' % model_abs_loss.mean())\n",
    "print('last_frame_abs_loss=%.7f' % last_frame_abs_loss.mean())\n",
    "print('     model_sqr_loss=%.7f' % model_sqr_loss.mean())\n",
    "print('last_frame_sqr_loss=%.7f' % last_frame_sqr_loss.mean())\n",
    "print(time.strftime('It took  %H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(time.strftime(\"end time: %Y-%m-%d %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_size= 3\n",
      "start time: 2018-09-25 00:39:47\n",
      "     model_abs_loss=2.9936411\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=58.8740609\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:47\n",
      "kernel_size= 3\n",
      "kernel_size= 9\n",
      "start time: 2018-09-25 00:39:47\n",
      "     model_abs_loss=2.9624683\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=55.1349142\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:48\n",
      "kernel_size= 9\n",
      "kernel_size= 15\n",
      "start time: 2018-09-25 00:39:48\n",
      "     model_abs_loss=2.9432295\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=52.4270488\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:49\n",
      "kernel_size= 15\n",
      "kernel_size= 21\n",
      "start time: 2018-09-25 00:39:49\n",
      "     model_abs_loss=2.9309424\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=50.3546018\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:49\n",
      "kernel_size= 21\n",
      "kernel_size= 27\n",
      "start time: 2018-09-25 00:39:49\n",
      "     model_abs_loss=2.9231635\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=48.5986027\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:50\n",
      "kernel_size= 27\n",
      "kernel_size= 33\n",
      "start time: 2018-09-25 00:39:50\n",
      "     model_abs_loss=2.9180076\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=47.3359186\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:51\n",
      "kernel_size= 33\n",
      "kernel_size= 39\n",
      "start time: 2018-09-25 00:39:51\n",
      "     model_abs_loss=2.9145428\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=46.1932034\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:52\n",
      "kernel_size= 39\n",
      "kernel_size= 45\n",
      "start time: 2018-09-25 00:39:52\n",
      "     model_abs_loss=2.9123930\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=45.2107706\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:00\n",
      "end time: 2018-09-25 00:39:53\n",
      "kernel_size= 45\n",
      "kernel_size= 51\n",
      "start time: 2018-09-25 00:39:53\n",
      "     model_abs_loss=2.9114515\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=44.3773148\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:01\n",
      "end time: 2018-09-25 00:39:54\n",
      "kernel_size= 51\n",
      "kernel_size= 57\n",
      "start time: 2018-09-25 00:39:54\n",
      "     model_abs_loss=2.9116795\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=43.6458105\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:01\n",
      "end time: 2018-09-25 00:39:55\n",
      "kernel_size= 57\n",
      "kernel_size= 63\n",
      "start time: 2018-09-25 00:39:55\n",
      "     model_abs_loss=2.9130058\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=43.0003621\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:01\n",
      "end time: 2018-09-25 00:39:56\n",
      "kernel_size= 63\n",
      "kernel_size= 69\n",
      "start time: 2018-09-25 00:39:56\n",
      "     model_abs_loss=2.9153211\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=42.4445814\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:01\n",
      "end time: 2018-09-25 00:39:57\n",
      "kernel_size= 69\n",
      "kernel_size= 75\n",
      "start time: 2018-09-25 00:39:57\n",
      "     model_abs_loss=2.9185357\n",
      "last_frame_abs_loss=3.0182784\n",
      "     model_sqr_loss=42.2152339\n",
      "last_frame_sqr_loss=62.5443438\n",
      "It took  00:00:01\n",
      "end time: 2018-09-25 00:39:58\n",
      "kernel_size= 75\n"
     ]
    }
   ],
   "source": [
    "sigmaX = 100\n",
    "kernel_size = 51\n",
    "for kernel_size in range(3, 81, 6):\n",
    "    start_time = time.time()\n",
    "    print('kernel_size=', kernel_size)\n",
    "    print(time.strftime(\"start time: %Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "    model_abs_loss = []\n",
    "    model_sqr_loss = []\n",
    "    last_frame_abs_loss = []\n",
    "    last_frame_sqr_loss = []\n",
    "    for RAD_id_counter, RAD_id in enumerate(RAD_id_list[-50:]):\n",
    "        x = np.empty((nt, image_size, image_size))\n",
    "        for i in range(nt):\n",
    "            x[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 31 + i - nt)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "        x_last = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 30)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "        y_true_last = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_train/%s/%s_%03d.png\" % (RAD_id, RAD_id, 60)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size))\n",
    "        for i in range(30 // 30):  # 30 // nt\n",
    "    #         y = model_predict(x)\n",
    "            y = cv2.GaussianBlur(x[-1], (kernel_size, kernel_size), sigmaX)\n",
    "            for j in range(nt - 1):\n",
    "                x[j] = x[j + 1]\n",
    "            x[-1] = y\n",
    "        y_pred_last = y\n",
    "        last_frame_abs_loss.append(sklearn.metrics.mean_absolute_error(y_true_last, x_last))\n",
    "        model_abs_loss.append(sklearn.metrics.mean_absolute_error(y_true_last, y_pred_last))\n",
    "        last_frame_sqr_loss.append(sklearn.metrics.mean_squared_error(y_true_last.astype(np.int), x_last.astype(np.int)))\n",
    "        model_sqr_loss.append(sklearn.metrics.mean_squared_error(y_true_last.astype(np.int), y_pred_last.astype(np.int)))\n",
    "#         if RAD_id_counter % 10 == 0:\n",
    "#             print('RAD_id_counter=%5d\\t\\tIt takes %.2f' % (RAD_id_counter, time.time() - start_time))\n",
    "    model_abs_loss = np.array(model_abs_loss)\n",
    "    last_frame_abs_loss = np.array(last_frame_abs_loss)\n",
    "    model_sqr_loss = np.array(model_sqr_loss)\n",
    "    last_frame_sqr_loss = np.array(last_frame_sqr_loss)\n",
    "    print('     model_abs_loss=%.7f' % model_abs_loss.mean())\n",
    "    print('last_frame_abs_loss=%.7f' % last_frame_abs_loss.mean())\n",
    "    print('     model_sqr_loss=%.7f' % model_sqr_loss.mean())\n",
    "    print('last_frame_sqr_loss=%.7f' % last_frame_sqr_loss.mean())\n",
    "    print(time.strftime('It took  %H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "    print(time.strftime(\"end time: %Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "    print('kernel_size=', kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_last.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.82624435424805"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(x_last, y_true_last.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.82624435424805"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_pred_last, y_true_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3251228332519531"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_true_last, y_pred_last.astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abs_loss = np.array(model_abs_loss)\n",
    "last_frame_abs_loss = np.array(last_frame_abs_loss)\n",
    "model_sqr_loss = np.array(model_sqr_loss)\n",
    "last_frame_sqr_loss = np.array(last_frame_sqr_loss)\n",
    "print('     model_abs_loss=%.7f' % model_abs_loss.mean())\n",
    "print('last_frame_abs_loss=%.7f' % last_frame_abs_loss.mean())\n",
    "print('     model_sqr_loss=%.7f' % model_sqr_loss.mean())\n",
    "print('last_frame_sqr_loss=%.7f' % last_frame_sqr_loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqr:\n",
    "\n",
    "15.3290176 0\n",
    "15.3366709 1\n",
    "15.2775345 2\n",
    "15.2723169 average\n",
    "\n",
    "27.9708243 0\n",
    "24.8304856 0.1\n",
    "21.4680993 0.2\n",
    "21.1976629 0.25\n",
    "21.4486480 0.3\n",
    "23.0941604 0.4\n",
    "\n",
    "abs:\n",
    "\n",
    "1.4878454 average\n",
    "\n",
    "1.4255825 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_last = x_last.reshape(image_size, image_size)\n",
    "plt.imshow(x_last, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "y_true_last = y_true_last.reshape(image_size, image_size)\n",
    "plt.imshow(y_true_last, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "y_pred_last = y_pred_last.reshape(image_size, image_size)\n",
    "plt.imshow(y_pred_last, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()\n",
    "plt.imshow(rescale(x_last, y_pred_last), cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用模型预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_id_submit_list = os.listdir(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_test/\")\n",
    "print(len(RAD_id_submit_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD_id = RAD_id_submit_list[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = data_generation([RAD_id], batch_size=1, image_size=image_size, image_scalar=image_scalar, nt=nt, step_size=step_size, offset=0, path='/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_test')\n",
    "\n",
    "for i in range(30 // step_size):\n",
    "    y = test_model.predict(x)\n",
    "#     temp_matrix = np.rollaxis(y[0], 2, 0)\n",
    "#     for k in range(3):\n",
    "#         psf_size = 15\n",
    "#         psf = np.ones((psf_size, psf_size)) / psf_size ** 2\n",
    "#         temp_matrix[k] = restoration.wiener(temp_matrix[k], psf, 5)\n",
    "#     y[0] = np.rollaxis(temp_matrix, 0, 3)\n",
    "    y = np.where(y<0.03, -0.01, y)\n",
    "#     y = np.where(y>0.6, 0.6, y)\n",
    "    for j in range(nt - 1):\n",
    "        x[0][j] = x[0][j + 1]\n",
    "    x[0][-1] = y[0]\n",
    "    for k in range(n_channels):\n",
    "        print(i, k)\n",
    "        plt.imshow(np.rollaxis(y[0], 2, 0)[k] * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rollaxis(y[0], 2, 0)[k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "version = 'SRAD2018_submit_Neutrino_PredNet_v0.4.1.0_18.09.07.02.07'\n",
    "start_time = time.time()\n",
    "print(time.strftime(\"start time: %Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "for RAD_id_counter, RAD_id in enumerate(RAD_id_submit_list):\n",
    "    x, y = data_generation([RAD_id], batch_size=1, image_size=image_size, image_scalar=image_scalar, nt=nt, step_size=step_size, offset=0, path='/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_test')\n",
    "    if not os.path.exists(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s\" % (version, RAD_id)):\n",
    "        os.makedirs(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s\" % (version, RAD_id))\n",
    "    for i in range(30 // step_size):\n",
    "        y = test_model.predict(x)\n",
    "    #     temp_matrix = np.rollaxis(y[0], 2, 0)\n",
    "    #     for k in range(3):\n",
    "    #         psf_size = 15\n",
    "    #         psf = np.ones((psf_size, psf_size)) / psf_size ** 2\n",
    "    #         temp_matrix[k] = restoration.wiener(temp_matrix[k], psf, 5)\n",
    "    #     y[0] = np.rollaxis(temp_matrix, 0, 3)\n",
    "        y = np.where(y<0.03, -0.01, y)\n",
    "        y = np.where(y>0.33, 0.33, y)\n",
    "        for j in range(nt - 1):\n",
    "            x[0][j] = x[0][j + 1]\n",
    "        x[0][-1] = y[0]\n",
    "        result = np.empty((image_size, image_size))\n",
    "        for k in range(n_channels):\n",
    "#             print(i, k)\n",
    "            result = result + np.rollaxis(y[0], 2, 0)[k] * image_scalar\n",
    "#             plt.imshow(np.rollaxis(y[0], 2, 0)[k] * image_scalar, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "#             plt.show()\n",
    "        result = result / 3\n",
    "#         print(i)\n",
    "#         plt.imshow(result, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "#         plt.show()\n",
    "        result = result.astype(np.uint8)\n",
    "        result = np.where(result==0, 255, result)\n",
    "        result = PIL.Image.fromarray(result)\n",
    "        result = result.resize((501, 501))\n",
    "#         plt.imshow(result, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "#         plt.show()\n",
    "        result.save(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s/%s_f%03d.png\" % (version, RAD_id, RAD_id, i + 1))\n",
    "    if RAD_id_counter % 10 == 0:\n",
    "        print('RAD_id_counter=%5d\\t\\tIt takes %.2f' % (RAD_id_counter, time.time() - start_time))\n",
    "print(time.strftime('It took  %H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(time.strftime(\"end time: %Y-%m-%d %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "zip -r \"SRAD2018_submit_Neutrino_PredNet_v0.3.2.0_18.09.01.14.07.zip\" \"SRAD2018_submit_Neutrino_PredNet_v0.3.2.0_18.09.01.14.07\"\n",
    "ls | wc -l\n",
    "```\n",
    "18.09.02 15.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'SRAD2018_submit_Neutrino_PredNet_v0.3.1.0_18.09.01.13.38'\n",
    "start_time = time.time()\n",
    "print(time.strftime(\"start time: %Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "for RAD_id_counter, RAD_id in enumerate(RAD_id_submit_list[:1]):\n",
    "    x = np.empty((nt, image_size, image_size, 1))\n",
    "    y = np.empty((1, image_size, image_size, 1))\n",
    "    for i in range(nt):\n",
    "        x[i] = np.array(PIL.Image.open(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_test/%s/%s_%03d.png\" % (RAD_id, RAD_id, i + 31 - nt)).resize((image_size, image_size))).astype(np.int8).reshape((image_size, image_size, 1)) / image_scalar\n",
    "    x = x.reshape((1, nt, image_size, image_size, 1))\n",
    "    if not os.path.exists(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s\" % (version, RAD_id)):\n",
    "        os.makedirs(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s\" % (version, RAD_id))\n",
    "    for i in range(30):\n",
    "#         print('before predict %.2f' % (time.time() - start_time))\n",
    "        y = test_model.predict(x)  # takes 0.2s to predict\n",
    "#         print('after predict %.2f' % (time.time() - start_time))\n",
    "        y = np.where(y<0.03, -0.01, y)\n",
    "        for j in range(nt - 1):\n",
    "            x[0][j] = x[0][j + 1]\n",
    "        x[0][-1] = y[0]\n",
    "        if (31 + i) % 5 == 0:\n",
    "#             print('%2d:' % (31 + i))\n",
    "#             print(i // 5 + 1)\n",
    "            result = y[0].reshape((image_size, image_size)) * image_scalar\n",
    "#             plt.imshow(result, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "#             plt.show()\n",
    "            result = result.astype(np.uint8)\n",
    "            result = np.where(result==0, 255, result)\n",
    "            result = PIL.Image.fromarray(result)\n",
    "            result = result.resize((501, 501))\n",
    "#             plt.imshow(result, cmap=cm.gist_ncar_r, vmin=vmin, vmax=vmax)\n",
    "#             plt.show()\n",
    "            result.save(\"/home/hadoop/Documents/Neutrino/SRAD2018/SRAD2018_submit/%s/%s/%s_f%03d.png\" % (version, RAD_id, RAD_id, i // 5 + 1))\n",
    "    if RAD_id_counter % 10 == 0:\n",
    "        print('RAD_id_counter=%5d\\t\\tIt takes %.2f' % (RAD_id_counter, time.time() - start_time))\n",
    "print(time.strftime('It took  %H:%M:%S', time.gmtime(time.time() - start_time)))\n",
    "print(time.strftime(\"end time: %Y-%m-%d %H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
